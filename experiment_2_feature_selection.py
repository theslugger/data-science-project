#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®éªŒ2ï¼šç‰¹å¾é€‰æ‹©æ–¹æ³•æ¯”è¾ƒ (æˆå‘˜B)
CDS503 Group Project - é¦–å°”è‡ªè¡Œè½¦éœ€æ±‚é¢„æµ‹

ç›®æ ‡ï¼šæ¯”è¾ƒä¸åŒç‰¹å¾é€‰æ‹©æ–¹æ³•å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“
æ–¹æ³•ï¼šç›¸å…³æ€§åˆ†æã€RFEã€LASSOã€æ ‘æ¨¡å‹ç‰¹å¾é‡è¦æ€§ã€æ–¹å·®é€‰æ‹©
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_selection import (
    SelectKBest, f_regression, mutual_info_regression,
    RFE, SelectFromModel, VarianceThreshold
)
from sklearn.linear_model import Lasso, LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
import warnings
warnings.filterwarnings('ignore')

from data_preprocessing import BikeDataPreprocessor

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class FeatureSelectionExperiment:
    """ç‰¹å¾é€‰æ‹©å®éªŒç±»"""
    
    def __init__(self):
        self.results = {}
        self.feature_importance_scores = {}
        self.selected_features = {}
        self.preprocessor = BikeDataPreprocessor()
        
    def calculate_metrics(self, y_true, y_pred):
        """è®¡ç®—è¯„ä¼°æŒ‡æ ‡"""
        rmse = np.sqrt(mean_squared_error(y_true, y_pred))
        r2 = r2_score(y_true, y_pred)
        return {'RMSE': rmse, 'RÂ²': r2}
    
    def correlation_based_selection(self, X_train, y_train, threshold=0.1):
        """åŸºäºç›¸å…³æ€§çš„ç‰¹å¾é€‰æ‹©"""
        print("ğŸ” æ‰§è¡Œç›¸å…³æ€§åˆ†æç‰¹å¾é€‰æ‹©...")
        
        # è®¡ç®—ç‰¹å¾ä¸ç›®æ ‡å˜é‡çš„ç›¸å…³æ€§
        correlations = {}
        for col in X_train.columns:
            corr = np.abs(np.corrcoef(X_train[col], y_train)[0, 1])
            correlations[col] = corr if not np.isnan(corr) else 0
        
        # æŒ‰ç›¸å…³æ€§æ’åº
        sorted_features = sorted(correlations.items(), key=lambda x: x[1], reverse=True)
        
        # é€‰æ‹©é«˜ç›¸å…³æ€§ç‰¹å¾
        selected_features = [feat for feat, corr in sorted_features if corr >= threshold]
        
        print(f"  ç›¸å…³æ€§é˜ˆå€¼: {threshold}")
        print(f"  é€‰æ‹©ç‰¹å¾æ•°é‡: {len(selected_features)}/{len(X_train.columns)}")
        
        self.feature_importance_scores['Correlation'] = correlations
        return selected_features
    
    def mutual_info_selection(self, X_train, y_train, k=20):
        """åŸºäºäº’ä¿¡æ¯çš„ç‰¹å¾é€‰æ‹©"""
        print("ğŸ” æ‰§è¡Œäº’ä¿¡æ¯ç‰¹å¾é€‰æ‹©...")
        
        # è®¡ç®—äº’ä¿¡æ¯åˆ†æ•°
        mi_scores = mutual_info_regression(X_train, y_train, random_state=42)
        
        # åˆ›å»ºç‰¹å¾é‡è¦æ€§å­—å…¸
        mi_dict = dict(zip(X_train.columns, mi_scores))
        
        # é€‰æ‹©top-kç‰¹å¾
        selector = SelectKBest(score_func=mutual_info_regression, k=k)
        selector.fit(X_train, y_train)
        
        selected_features = X_train.columns[selector.get_support()].tolist()
        
        print(f"  é€‰æ‹©ç‰¹å¾æ•°é‡: {len(selected_features)}")
        
        self.feature_importance_scores['Mutual_Info'] = mi_dict
        return selected_features
    
    def rfe_selection(self, X_train, y_train, n_features=20):
        """é€’å½’ç‰¹å¾æ¶ˆé™¤(RFE)"""
        print("ğŸ” æ‰§è¡ŒRFEç‰¹å¾é€‰æ‹©...")
        
        # ä½¿ç”¨çº¿æ€§å›å½’ä½œä¸ºåŸºç¡€ä¼°è®¡å™¨
        estimator = LinearRegression()
        
        # RFEé€‰æ‹©å™¨
        rfe = RFE(estimator=estimator, n_features_to_select=n_features, step=1)
        rfe.fit(X_train, y_train)
        
        selected_features = X_train.columns[rfe.support_].tolist()
        
        # è·å–ç‰¹å¾æ’åï¼ˆ1æ˜¯æœ€é‡è¦çš„ï¼‰
        feature_ranking = dict(zip(X_train.columns, rfe.ranking_))
        
        print(f"  é€‰æ‹©ç‰¹å¾æ•°é‡: {len(selected_features)}")
        
        self.feature_importance_scores['RFE'] = feature_ranking
        return selected_features
    
    def lasso_selection(self, X_train, y_train, alpha=0.1):
        """LASSOç‰¹å¾é€‰æ‹©"""
        print("ğŸ” æ‰§è¡ŒLASSOç‰¹å¾é€‰æ‹©...")
        
        # LASSOå›å½’
        lasso = Lasso(alpha=alpha, random_state=42)
        lasso.fit(X_train, y_train)
        
        # è·å–éé›¶ç³»æ•°çš„ç‰¹å¾
        selected_features = X_train.columns[lasso.coef_ != 0].tolist()
        
        # ç‰¹å¾é‡è¦æ€§ï¼ˆç³»æ•°ç»å¯¹å€¼ï¼‰
        feature_importance = dict(zip(X_train.columns, np.abs(lasso.coef_)))
        
        print(f"  LASSO alpha: {alpha}")
        print(f"  é€‰æ‹©ç‰¹å¾æ•°é‡: {len(selected_features)}")
        
        self.feature_importance_scores['LASSO'] = feature_importance
        return selected_features
    
    def tree_based_selection(self, X_train, y_train, threshold='mean'):
        """åŸºäºæ ‘æ¨¡å‹çš„ç‰¹å¾é€‰æ‹©"""
        print("ğŸ” æ‰§è¡Œæ ‘æ¨¡å‹ç‰¹å¾é€‰æ‹©...")
        
        # éšæœºæ£®æ—
        rf = RandomForestRegressor(n_estimators=100, random_state=42)
        rf.fit(X_train, y_train)
        
        # ä½¿ç”¨SelectFromModelè¿›è¡Œç‰¹å¾é€‰æ‹©
        selector = SelectFromModel(rf, threshold=threshold)
        selector.fit(X_train, y_train)
        
        selected_features = X_train.columns[selector.get_support()].tolist()
        
        # ç‰¹å¾é‡è¦æ€§
        feature_importance = dict(zip(X_train.columns, rf.feature_importances_))
        
        print(f"  é€‰æ‹©é˜ˆå€¼: {threshold}")
        print(f"  é€‰æ‹©ç‰¹å¾æ•°é‡: {len(selected_features)}")
        
        self.feature_importance_scores['Tree_Based'] = feature_importance
        return selected_features
    
    def variance_threshold_selection(self, X_train, threshold=0.01):
        """æ–¹å·®é˜ˆå€¼ç‰¹å¾é€‰æ‹©"""
        print("ğŸ” æ‰§è¡Œæ–¹å·®é˜ˆå€¼ç‰¹å¾é€‰æ‹©...")
        
        # è®¡ç®—ç‰¹å¾æ–¹å·®
        variances = X_train.var()
        
        # é€‰æ‹©æ–¹å·®å¤§äºé˜ˆå€¼çš„ç‰¹å¾
        selected_features = X_train.columns[variances > threshold].tolist()
        
        print(f"  æ–¹å·®é˜ˆå€¼: {threshold}")
        print(f"  é€‰æ‹©ç‰¹å¾æ•°é‡: {len(selected_features)}")
        
        self.feature_importance_scores['Variance'] = variances.to_dict()
        return selected_features
    
    def evaluate_feature_set(self, X_train, X_val, X_test, y_train, y_val, y_test, 
                           selected_features, method_name):
        """è¯„ä¼°ç‰¹å¾é›†çš„æ€§èƒ½"""
        
        if not selected_features:
            print(f"  âš ï¸ {method_name}: æ²¡æœ‰é€‰æ‹©ä»»ä½•ç‰¹å¾")
            return None
        
        # é€‰æ‹©ç‰¹å¾å­é›†
        X_train_selected = X_train[selected_features]
        X_val_selected = X_val[selected_features]
        X_test_selected = X_test[selected_features]
        
        # è®­ç»ƒæ¨¡å‹ï¼ˆä½¿ç”¨éšæœºæ£®æ—ï¼‰
        model = RandomForestRegressor(n_estimators=100, random_state=42)
        model.fit(X_train_selected, y_train)
        
        # é¢„æµ‹
        y_train_pred = model.predict(X_train_selected)
        y_val_pred = model.predict(X_val_selected)
        y_test_pred = model.predict(X_test_selected)
        
        # è®¡ç®—æŒ‡æ ‡
        train_metrics = self.calculate_metrics(y_train, y_train_pred)
        val_metrics = self.calculate_metrics(y_val, y_val_pred)
        test_metrics = self.calculate_metrics(y_test, y_test_pred)
        
        print(f"  ğŸ“Š {method_name} æ€§èƒ½:")
        print(f"    ç‰¹å¾æ•°é‡: {len(selected_features)}")
        print(f"    éªŒè¯é›† RMSE: {val_metrics['RMSE']:.2f}")
        print(f"    æµ‹è¯•é›† RMSE: {test_metrics['RMSE']:.2f}")
        print(f"    æµ‹è¯•é›† RÂ²: {test_metrics['RÂ²']:.4f}")
        
        return {
            'method': method_name,
            'n_features': len(selected_features),
            'selected_features': selected_features,
            'train_metrics': train_metrics,
            'val_metrics': val_metrics,
            'test_metrics': test_metrics,
            'model': model
        }
    
    def run_experiment(self):
        """è¿è¡Œç‰¹å¾é€‰æ‹©å®éªŒ"""
        print("ğŸš€ å¼€å§‹å®éªŒ2ï¼šç‰¹å¾é€‰æ‹©æ–¹æ³•æ¯”è¾ƒ")
        print("="*50)
        
        # æ•°æ®é¢„å¤„ç†
        print("1. æ•°æ®é¢„å¤„ç†...")
        df = self.preprocessor.load_data()
        df_processed = self.preprocessor.prepare_features(df, use_lag_features=False)
        
        # æ•°æ®åˆ†å‰²
        X_train, X_val, X_test, y_train, y_val, y_test = \
            self.preprocessor.split_data_temporal(df_processed)
        
        # ç‰¹å¾æ ‡å‡†åŒ–
        X_train_scaled, X_val_scaled, X_test_scaled = \
            self.preprocessor.scale_features(X_train, X_val, X_test)
        
        print(f"\næ•°æ®æ¦‚è§ˆ:")
        print(f"  åŸå§‹ç‰¹å¾æ•°é‡: {X_train_scaled.shape[1]}")
        print(f"  è®­ç»ƒæ ·æœ¬: {X_train_scaled.shape[0]}")
        
        # åŸºå‡†æ¨¡å‹ï¼ˆä½¿ç”¨æ‰€æœ‰ç‰¹å¾ï¼‰
        print("\n2. è®­ç»ƒåŸºå‡†æ¨¡å‹ï¼ˆæ‰€æœ‰ç‰¹å¾ï¼‰...")
        baseline_result = self.evaluate_feature_set(
            X_train_scaled, X_val_scaled, X_test_scaled,
            y_train, y_val, y_test,
            X_train_scaled.columns.tolist(), 'Baseline (All Features)'
        )
        
        if baseline_result:
            self.results['Baseline'] = baseline_result
        
        print("\n3. æ‰§è¡Œç‰¹å¾é€‰æ‹©æ–¹æ³•...")
        
        # æ–¹æ³•1ï¼šç›¸å…³æ€§åˆ†æ
        corr_features = self.correlation_based_selection(X_train_scaled, y_train, threshold=0.1)
        corr_result = self.evaluate_feature_set(
            X_train_scaled, X_val_scaled, X_test_scaled,
            y_train, y_val, y_test, corr_features, 'Correlation Analysis'
        )
        if corr_result:
            self.results['Correlation'] = corr_result
        
        # æ–¹æ³•2ï¼šäº’ä¿¡æ¯
        mi_features = self.mutual_info_selection(X_train_scaled, y_train, k=20)
        mi_result = self.evaluate_feature_set(
            X_train_scaled, X_val_scaled, X_test_scaled,
            y_train, y_val, y_test, mi_features, 'Mutual Information'
        )
        if mi_result:
            self.results['Mutual_Info'] = mi_result
        
        # æ–¹æ³•3ï¼šRFE
        rfe_features = self.rfe_selection(X_train_scaled, y_train, n_features=20)
        rfe_result = self.evaluate_feature_set(
            X_train_scaled, X_val_scaled, X_test_scaled,
            y_train, y_val, y_test, rfe_features, 'RFE'
        )
        if rfe_result:
            self.results['RFE'] = rfe_result
        
        # æ–¹æ³•4ï¼šLASSO
        lasso_features = self.lasso_selection(X_train_scaled, y_train, alpha=0.1)
        lasso_result = self.evaluate_feature_set(
            X_train_scaled, X_val_scaled, X_test_scaled,
            y_train, y_val, y_test, lasso_features, 'LASSO'
        )
        if lasso_result:
            self.results['LASSO'] = lasso_result
        
        # æ–¹æ³•5ï¼šæ ‘æ¨¡å‹ç‰¹å¾é‡è¦æ€§
        tree_features = self.tree_based_selection(X_train_scaled, y_train, threshold='mean')
        tree_result = self.evaluate_feature_set(
            X_train_scaled, X_val_scaled, X_test_scaled,
            y_train, y_val, y_test, tree_features, 'Tree Based'
        )
        if tree_result:
            self.results['Tree_Based'] = tree_result
        
        print("\nâœ… ç‰¹å¾é€‰æ‹©å®éªŒå®Œæˆ!")
        
        # ç”ŸæˆæŠ¥å‘Š
        self.generate_comparison_report()
        
        # ä¿å­˜ç»“æœ
        self.save_results()
        
        return self.results
    
    def generate_comparison_report(self):
        """ç”Ÿæˆç‰¹å¾é€‰æ‹©æ¯”è¾ƒæŠ¥å‘Š"""
        print("\nğŸ“Š ç”Ÿæˆç‰¹å¾é€‰æ‹©æ¯”è¾ƒæŠ¥å‘Š...")
        
        # åˆ›å»ºç»“æœDataFrame
        comparison_data = []
        for method, result in self.results.items():
            row = {
                'Method': method,
                'N_Features': result['n_features'],
                'Train_RMSE': result['train_metrics']['RMSE'],
                'Val_RMSE': result['val_metrics']['RMSE'],
                'Test_RMSE': result['test_metrics']['RMSE'],
                'Test_RÂ²': result['test_metrics']['RÂ²'],
            }
            comparison_data.append(row)
        
        results_df = pd.DataFrame(comparison_data)
        results_df = results_df.sort_values('Test_RMSE')
        
        print("\nğŸ“ˆ ç‰¹å¾é€‰æ‹©æ–¹æ³•æ¯”è¾ƒ (æŒ‰æµ‹è¯•é›†RMSEæ’åº):")
        print("="*70)
        print(results_df.round(4).to_string(index=False))
        
        # ä¿å­˜ç»“æœè¡¨æ ¼
        results_df.to_csv('experiment_2_results.csv', index=False)
        
        # åˆ›å»ºå¯è§†åŒ–
        self.create_visualizations(results_df)
        
        # æ€§èƒ½åˆ†æ
        print(f"\nğŸ† æœ€ä½³ç‰¹å¾é€‰æ‹©æ–¹æ³•:")
        best_method = results_df.iloc[0]
        print(f"  æ–¹æ³•: {best_method['Method']}")
        print(f"  ç‰¹å¾æ•°é‡: {best_method['N_Features']}")
        print(f"  æµ‹è¯•é›†RMSE: {best_method['Test_RMSE']:.2f}")
        print(f"  æµ‹è¯•é›†RÂ²: {best_method['Test_RÂ²']:.4f}")
        
        # æ•ˆç‡åˆ†æ
        baseline_rmse = results_df[results_df['Method'] == 'Baseline']['Test_RMSE'].iloc[0]
        print(f"\nğŸ“Š ç›¸å¯¹åŸºå‡†æ¨¡å‹çš„æ”¹è¿›:")
        for _, row in results_df.iterrows():
            if row['Method'] != 'Baseline':
                improvement = (baseline_rmse - row['Test_RMSE']) / baseline_rmse * 100
                feature_reduction = (1 - row['N_Features'] / results_df[results_df['Method'] == 'Baseline']['N_Features'].iloc[0]) * 100
                print(f"  {row['Method']}: RMSEæ”¹è¿› {improvement:.1f}%, ç‰¹å¾å‡å°‘ {feature_reduction:.1f}%")
    
    def create_visualizations(self, results_df):
        """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
        
        plt.style.use('default')
        fig = plt.figure(figsize=(20, 15))
        
        # 1. ç‰¹å¾æ•°é‡ vs æ€§èƒ½
        plt.subplot(2, 3, 1)
        methods = results_df['Method']
        n_features = results_df['N_Features']
        test_rmse = results_df['Test_RMSE']
        
        colors = plt.cm.viridis(np.linspace(0, 1, len(methods)))
        
        for i, (method, n_feat, rmse) in enumerate(zip(methods, n_features, test_rmse)):
            plt.scatter(n_feat, rmse, s=100, c=[colors[i]], alpha=0.7, label=method)
        
        plt.xlabel('ç‰¹å¾æ•°é‡')
        plt.ylabel('æµ‹è¯•é›† RMSE')
        plt.title('ç‰¹å¾æ•°é‡ vs æ¨¡å‹æ€§èƒ½')
        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        plt.grid(True, alpha=0.3)
        
        # 2. æ–¹æ³•æ€§èƒ½æ¯”è¾ƒ
        plt.subplot(2, 3, 2)
        bars = plt.bar(range(len(methods)), test_rmse, color='lightcoral', alpha=0.7)
        plt.xlabel('ç‰¹å¾é€‰æ‹©æ–¹æ³•')
        plt.ylabel('æµ‹è¯•é›† RMSE')
        plt.title('ç‰¹å¾é€‰æ‹©æ–¹æ³•æ€§èƒ½æ¯”è¾ƒ')
        plt.xticks(range(len(methods)), methods, rotation=45, ha='right')
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, v in enumerate(test_rmse):
            plt.text(i, v + 5, f'{v:.1f}', ha='center', va='bottom')
        
        plt.grid(axis='y', alpha=0.3)
        
        # 3. RÂ²åˆ†æ•°æ¯”è¾ƒ
        plt.subplot(2, 3, 3)
        r2_values = results_df['Test_RÂ²']
        bars = plt.bar(range(len(methods)), r2_values, color='lightgreen', alpha=0.7)
        plt.xlabel('ç‰¹å¾é€‰æ‹©æ–¹æ³•')
        plt.ylabel('æµ‹è¯•é›† RÂ²')
        plt.title('ç‰¹å¾é€‰æ‹©æ–¹æ³• RÂ²æ¯”è¾ƒ')
        plt.xticks(range(len(methods)), methods, rotation=45, ha='right')
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, v in enumerate(r2_values):
            plt.text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')
        
        plt.grid(axis='y', alpha=0.3)
        
        # 4. ç‰¹å¾é‡è¦æ€§çƒ­å›¾ï¼ˆå¦‚æœæœ‰æ•°æ®ï¼‰
        plt.subplot(2, 3, 4)
        if self.feature_importance_scores:
            # é€‰æ‹©å‡ ä¸ªé‡è¦çš„ç‰¹å¾é€‰æ‹©æ–¹æ³•
            methods_to_show = ['Correlation', 'Tree_Based', 'LASSO']
            
            # è·å–æ‰€æœ‰ç‰¹å¾
            all_features = list(next(iter(self.feature_importance_scores.values())).keys())
            
            # åˆ›å»ºé‡è¦æ€§çŸ©é˜µ
            importance_matrix = []
            method_labels = []
            
            for method in methods_to_show:
                if method in self.feature_importance_scores:
                    scores = self.feature_importance_scores[method]
                    importance_row = [scores.get(feat, 0) for feat in all_features[:20]]  # åªæ˜¾ç¤ºå‰20ä¸ªç‰¹å¾
                    importance_matrix.append(importance_row)
                    method_labels.append(method)
            
            if importance_matrix:
                importance_matrix = np.array(importance_matrix)
                
                # æ ‡å‡†åŒ–åˆ°0-1èŒƒå›´
                for i in range(len(importance_matrix)):
                    row = importance_matrix[i]
                    if row.max() > 0:
                        importance_matrix[i] = row / row.max()
                
                im = plt.imshow(importance_matrix, cmap='YlOrRd', aspect='auto')
                plt.colorbar(im, shrink=0.8)
                plt.ylabel('ç‰¹å¾é€‰æ‹©æ–¹æ³•')
                plt.xlabel('ç‰¹å¾')
                plt.title('ç‰¹å¾é‡è¦æ€§çƒ­å›¾ (Top 20)')
                plt.yticks(range(len(method_labels)), method_labels)
                plt.xticks(range(min(20, len(all_features))), all_features[:20], rotation=90)
        
        # 5. æ¨¡å‹å¤æ‚åº¦åˆ†æ
        plt.subplot(2, 3, 5)
        plt.scatter(n_features, r2_values, s=100, alpha=0.7, c='purple')
        
        for i, method in enumerate(methods):
            plt.annotate(method, (n_features.iloc[i], r2_values.iloc[i]), 
                        xytext=(5, 5), textcoords='offset points', fontsize=8)
        
        plt.xlabel('ç‰¹å¾æ•°é‡')
        plt.ylabel('æµ‹è¯•é›† RÂ²')
        plt.title('æ¨¡å‹å¤æ‚åº¦ vs æ€§èƒ½')
        plt.grid(True, alpha=0.3)
        
        # 6. è®­ç»ƒé›† vs æµ‹è¯•é›†æ€§èƒ½
        plt.subplot(2, 3, 6)
        train_rmse = results_df['Train_RMSE']
        
        plt.scatter(train_rmse, test_rmse, s=100, alpha=0.7, c='orange')
        
        # æ·»åŠ å¯¹è§’çº¿ï¼ˆç†æƒ³æƒ…å†µï¼‰
        min_rmse = min(train_rmse.min(), test_rmse.min())
        max_rmse = max(train_rmse.max(), test_rmse.max())
        plt.plot([min_rmse, max_rmse], [min_rmse, max_rmse], 'r--', alpha=0.8, label='ç†æƒ³çº¿')
        
        for i, method in enumerate(methods):
            plt.annotate(method, (train_rmse.iloc[i], test_rmse.iloc[i]), 
                        xytext=(5, 5), textcoords='offset points', fontsize=8)
        
        plt.xlabel('è®­ç»ƒé›† RMSE')
        plt.ylabel('æµ‹è¯•é›† RMSE')
        plt.title('è®­ç»ƒé›† vs æµ‹è¯•é›†æ€§èƒ½')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('experiment_2_feature_selection.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        print("ğŸ“¸ å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜: experiment_2_feature_selection.png")
    
    def save_results(self):
        """ä¿å­˜å®éªŒç»“æœ"""
        # ä¿å­˜ç‰¹å¾é€‰æ‹©ç»“æœ
        feature_selection_summary = {}
        for method, result in self.results.items():
            feature_selection_summary[method] = {
                'n_features': result['n_features'],
                'selected_features': result['selected_features'],
                'test_rmse': result['test_metrics']['RMSE'],
                'test_r2': result['test_metrics']['RÂ²']
            }
        
        # ä¿å­˜ä¸ºJSON
        import json
        with open('experiment_2_summary.json', 'w', encoding='utf-8') as f:
            json.dump(feature_selection_summary, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜ç‰¹å¾é‡è¦æ€§åˆ†æ•°
        with open('feature_importance_scores.json', 'w', encoding='utf-8') as f:
            json.dump(self.feature_importance_scores, f, indent=2, ensure_ascii=False)
        
        print("ğŸ’¾ å®éªŒç»“æœå·²ä¿å­˜:")
        print("  - experiment_2_results.csv")
        print("  - experiment_2_summary.json")
        print("  - feature_importance_scores.json")
        print("  - experiment_2_feature_selection.png")

def main():
    """ä¸»å‡½æ•°"""
    
    # åˆ›å»ºå®éªŒå®ä¾‹
    experiment = FeatureSelectionExperiment()
    
    # è¿è¡Œå®éªŒ
    results = experiment.run_experiment()
    
    print("\nğŸ‰ å®éªŒ2å®Œæˆï¼")
    print(f"æ€»å…±æµ‹è¯•äº† {len(results)} ç§ç‰¹å¾é€‰æ‹©æ–¹æ³•")
    
    # è¾“å‡ºæœ€ç»ˆæ€»ç»“
    print("\nğŸ“‹ å®éªŒæ€»ç»“:")
    print("- å·²å®Œæˆç‰¹å¾é€‰æ‹©æ–¹æ³•æ¯”è¾ƒ")
    print("- è¯†åˆ«æœ€é‡è¦çš„ç‰¹å¾å­é›†")
    print("- åˆ†æç‰¹å¾æ•°é‡å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“")
    print("- ä¸ºæ¨¡å‹ä¼˜åŒ–æä¾›ç‰¹å¾é€‰æ‹©å»ºè®®")

if __name__ == "__main__":
    main() 