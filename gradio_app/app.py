#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é¦–å°”è‡ªè¡Œè½¦éœ€æ±‚é¢„æµ‹ - Gradioå¯è§†åŒ–åº”ç”¨
åŸºäºå…ˆè¿›è®¾è®¡ç†å¿µçš„æ•°æ®å¤„ç†å¹³å°
"""

import gradio as gr
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import warnings
from datetime import datetime
from scipy import stats

warnings.filterwarnings('ignore')
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei']
plt.rcParams['axes.unicode_minus'] = False

class DataProcessor:
    """æ•°æ®å¤„ç†æ ¸å¿ƒç±» - é›†æˆå®Œæ•´å¢å¼ºåŠŸèƒ½"""
    
    def __init__(self):
        self.df = None
        self.processed_data = None
        self.exploration_results = {}
        self.analysis_results = {}
        self.preprocessing_results = {}
        self.feature_names = []
        
        # æ•°æ®åˆ†æç»“æœå­˜å‚¨
        self.eda_results = {}
        self.deep_analysis_results = {}
        self.final_preprocessed_data = None
        
    def load_data(self, file):
        """åŠ è½½æ•°æ®æ–‡ä»¶"""
        try:
            if file is None:
                return "âŒ è¯·ä¸Šä¼ æ•°æ®æ–‡ä»¶", None, None
            
            # å°è¯•å¤šç§ç¼–ç æ–¹å¼
            encodings = ['utf-8', 'gbk', 'gb2312', 'cp936', 'iso-8859-1', 'latin1']
            
            for encoding in encodings:
                try:
                    self.df = pd.read_csv(file.name, encoding=encoding)
                    print(f"âœ… æˆåŠŸä½¿ç”¨ {encoding} ç¼–ç åŠ è½½æ–‡ä»¶")
                    break
                except UnicodeDecodeError:
                    continue
            else:
                # å¦‚æœæ‰€æœ‰ç¼–ç éƒ½å¤±è´¥ï¼Œä½¿ç”¨é”™è¯¯å¤„ç†æ¨¡å¼
                self.df = pd.read_csv(file.name, encoding='utf-8', errors='ignore')
                print("âš ï¸ ä½¿ç”¨UTF-8ç¼–ç å¿½ç•¥é”™è¯¯æ¨¡å¼åŠ è½½æ–‡ä»¶")
            
            info = f"""
            âœ… **æ•°æ®åŠ è½½æˆåŠŸï¼**
            
            ğŸ“Š **æ•°æ®æ¦‚è§ˆ:**
            - æ•°æ®å½¢çŠ¶: {self.df.shape[0]} è¡Œ Ã— {self.df.shape[1]} åˆ—
            - å†…å­˜ä½¿ç”¨: {self.df.memory_usage(deep=True).sum() / 1024**2:.2f} MB
            - æ•°å€¼åˆ—: {len(self.df.select_dtypes(include=[np.number]).columns)} ä¸ª
            - æ–‡æœ¬åˆ—: {len(self.df.select_dtypes(include=['object']).columns)} ä¸ª
            - ç¼ºå¤±å€¼: {self.df.isnull().sum().sum()} ä¸ª
            - é‡å¤è¡Œ: {self.df.duplicated().sum()} ä¸ª
            - å®Œæ•´åº¦: {(1 - self.df.isnull().sum().sum() / (self.df.shape[0] * self.df.shape[1])) * 100:.1f}%
            """
            
            preview_html = self.df.head(10).to_html(
                classes="table table-striped table-hover",
                table_id="data-preview-table",
                escape=False
            )
            
            overview_chart = self.create_overview_chart()
            
            return info, preview_html, overview_chart
            
        except Exception as e:
            return f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {str(e)}", None, None
    
    def comprehensive_eda_analysis(self):
        """å®Œæ•´çš„æ¢ç´¢æ€§æ•°æ®åˆ†æ"""
        if self.df is None:
            return "âŒ è¯·å…ˆåŠ è½½æ•°æ®", None
            
        try:
            eda_report = "ğŸ” **å®Œæ•´æ¢ç´¢æ€§æ•°æ®åˆ†ææŠ¥å‘Š**\n\n"
            
            # 1. åŸºç¡€æ•°æ®ä¿¡æ¯
            eda_report += f"ğŸ“Š **æ•°æ®åŸºæœ¬ä¿¡æ¯:**\n"
            eda_report += f"- æ•°æ®å½¢çŠ¶: {self.df.shape[0]} è¡Œ Ã— {self.df.shape[1]} åˆ—\n"
            eda_report += f"- å†…å­˜ä½¿ç”¨: {self.df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\n"
            eda_report += f"- æ•°å€¼åˆ—: {len(self.df.select_dtypes(include=[np.number]).columns)} ä¸ª\n"
            eda_report += f"- æ–‡æœ¬åˆ—: {len(self.df.select_dtypes(include=['object']).columns)} ä¸ª\n\n"
            
            # 2. ç›®æ ‡å˜é‡åˆ†æ
            target_col = 'Rented Bike Count'
            if target_col in self.df.columns:
                target_data = self.df[target_col]
                
                eda_report += f"ğŸ¯ **ç›®æ ‡å˜é‡ '{target_col}' åˆ†æ:**\n"
                eda_report += f"- å¹³å‡å€¼: {target_data.mean():.2f}\n"
                eda_report += f"- ä¸­ä½æ•°: {target_data.median():.2f}\n"
                eda_report += f"- æ ‡å‡†å·®: {target_data.std():.2f}\n"
                eda_report += f"- ååº¦: {target_data.skew():.4f}\n"
                eda_report += f"- å³°åº¦: {target_data.kurtosis():.4f}\n"
                eda_report += f"- é›¶å€¼æ•°é‡: {(target_data == 0).sum()} ({(target_data == 0).mean() * 100:.2f}%)\n"
                
                # å¼‚å¸¸å€¼åˆ†æ
                Q1 = target_data.quantile(0.25)
                Q3 = target_data.quantile(0.75)
                IQR = Q3 - Q1
                outliers = ((target_data < Q1 - 1.5 * IQR) | (target_data > Q3 + 1.5 * IQR)).sum()
                eda_report += f"- å¼‚å¸¸å€¼æ•°é‡: {outliers} ({outliers/len(target_data)*100:.2f}%)\n\n"
            
            # 3. æ•°å€¼ç‰¹å¾ç›¸å…³æ€§åˆ†æ
            numeric_cols = self.df.select_dtypes(include=[np.number]).columns.tolist()
            if len(numeric_cols) > 1 and target_col in numeric_cols:
                correlations = self.df[numeric_cols].corr()[target_col].abs().sort_values(ascending=False)
                strong_corr = correlations[correlations > 0.3]
                strong_corr = strong_corr[strong_corr.index != target_col]
                
                eda_report += f"ğŸ“Š **å¼ºç›¸å…³ç‰¹å¾ (|r| > 0.3):**\n"
                for feature, corr in strong_corr.items():
                    eda_report += f"- {feature}: {corr:.4f}\n"
                eda_report += "\n"
            
            # 4. æ—¶é—´æ¨¡å¼åˆ†æ
            if 'Hour' in self.df.columns:
                hourly_avg = self.df.groupby('Hour')[target_col].mean()
                peak_hours = hourly_avg.nlargest(3).index.tolist()
                low_hours = hourly_avg.nsmallest(3).index.tolist()
                
                eda_report += f"â° **æ—¶é—´æ¨¡å¼åˆ†æ:**\n"
                eda_report += f"- é«˜å³°æ—¶æ®µ: {', '.join(map(str, peak_hours))}æ—¶\n"
                eda_report += f"- ä½è°·æ—¶æ®µ: {', '.join(map(str, low_hours))}æ—¶\n"
                
                if 'Date' in self.df.columns:
                    try:
                        self.df['Date'] = pd.to_datetime(self.df['Date'], format='%d/%m/%Y')
                    except ValueError:
                        try:
                            self.df['Date'] = pd.to_datetime(self.df['Date'], dayfirst=True)
                        except ValueError:
                            self.df['Date'] = pd.to_datetime(self.df['Date'], format='mixed', dayfirst=True)
                    self.df['Weekday'] = self.df['Date'].dt.weekday
                    self.df['IsWeekend'] = (self.df['Weekday'] >= 5).astype(int)
                    
                    weekday_avg = self.df[self.df['IsWeekend'] == 0][target_col].mean()
                    weekend_avg = self.df[self.df['IsWeekend'] == 1][target_col].mean()
                    eda_report += f"- å·¥ä½œæ—¥å¹³å‡: {weekday_avg:.1f}ï¼Œå‘¨æœ«å¹³å‡: {weekend_avg:.1f}\n\n"
            
            # 5. å¤©æ°”å½±å“åˆ†æ
            weather_cols = ['Temperature(Â°C)', 'Humidity(%)', 'Wind speed (m/s)', 'Rainfall(mm)', 'Snowfall (cm)']
            available_weather = [col for col in weather_cols if col in self.df.columns]
            
            if available_weather:
                eda_report += f"ğŸŒ¤ï¸ **å¤©æ°”å½±å“åˆ†æ:**\n"
                
                if 'Temperature(Â°C)' in self.df.columns:
                    temp_corr = self.df['Temperature(Â°C)'].corr(self.df[target_col])
                    eda_report += f"- æ¸©åº¦ç›¸å…³æ€§: {temp_corr:.4f}\n"
                
                if 'Rainfall(mm)' in self.df.columns:
                    rain_days = (self.df['Rainfall(mm)'] > 0).sum()
                    rain_avg = self.df[self.df['Rainfall(mm)'] > 0][target_col].mean()
                    no_rain_avg = self.df[self.df['Rainfall(mm)'] == 0][target_col].mean()
                    eda_report += f"- é™é›¨å¤©æ•°: {rain_days} ({rain_days/len(self.df)*100:.1f}%)\n"
                    eda_report += f"- é™é›¨æ—¥å¹³å‡éœ€æ±‚: {rain_avg:.1f}ï¼Œæ— é›¨æ—¥: {no_rain_avg:.1f}\n"
                
                if 'Snowfall (cm)' in self.df.columns:
                    snow_days = (self.df['Snowfall (cm)'] > 0).sum()
                    eda_report += f"- é™é›ªå¤©æ•°: {snow_days} ({snow_days/len(self.df)*100:.1f}%)\n"
                eda_report += "\n"
            
            # 6. åˆ†ç±»ç‰¹å¾åˆ†æ
            categorical_cols = self.df.select_dtypes(include=['object']).columns.tolist()
            if categorical_cols:
                eda_report += f"ğŸ“‘ **åˆ†ç±»ç‰¹å¾åˆ†æ:**\n"
                for col in categorical_cols:
                    unique_count = self.df[col].nunique()
                    most_common = self.df[col].mode().iloc[0] if len(self.df[col].mode()) > 0 else "N/A"
                    eda_report += f"- {col}: {unique_count} ä¸ªç±»åˆ«ï¼Œæœ€å¸¸è§: {most_common}\n"
                eda_report += "\n"
            
            # ä¿å­˜EDAç»“æœ
            self.eda_results = {
                'basic_info': {
                    'shape': self.df.shape,
                    'numeric_features': len(numeric_cols),
                    'categorical_features': len(categorical_cols)
                },
                'target_analysis': {
                    'mean': target_data.mean() if target_col in self.df.columns else None,
                    'zero_percentage': (target_data == 0).mean() * 100 if target_col in self.df.columns else None
                },
                'correlations': strong_corr.to_dict() if 'strong_corr' in locals() else {},
                'time_patterns': {
                    'peak_hours': peak_hours if 'peak_hours' in locals() else [],
                    'low_hours': low_hours if 'low_hours' in locals() else []
                }
            }
            
            # åˆ›å»ºç»¼åˆå¯è§†åŒ–ï¼ˆç¡®ä¿åœ¨æœ€ååˆ›å»ºï¼‰
            comprehensive_plot = self.create_comprehensive_eda_plot()
            
            return eda_report, comprehensive_plot
            
        except Exception as e:
            return f"âŒ EDAåˆ†æå¤±è´¥: {str(e)}", None
    
    def create_comprehensive_eda_plot(self):
        """åˆ›å»ºç»¼åˆEDAå¯è§†åŒ–"""
        try:
            if self.df is None:
                return None
                
            target_col = 'Rented Bike Count'
            
            # ç¡®ä¿å¿…è¦çš„ç‰¹å¾å­˜åœ¨
            if 'IsWeekend' not in self.df.columns and 'Date' in self.df.columns:
                try:
                    try:
                        self.df['Date'] = pd.to_datetime(self.df['Date'], format='%d/%m/%Y')
                    except ValueError:
                        try:
                            self.df['Date'] = pd.to_datetime(self.df['Date'], dayfirst=True)
                        except ValueError:
                            self.df['Date'] = pd.to_datetime(self.df['Date'], format='mixed', dayfirst=True)
                    self.df['Weekday'] = self.df['Date'].dt.weekday
                    self.df['IsWeekend'] = (self.df['Weekday'] >= 5).astype(int)
                except:
                    pass
            
            # åˆ›å»ºç»¼åˆå›¾è¡¨
            fig = make_subplots(
                rows=3, cols=2,
                subplot_titles=(
                    'ç›®æ ‡å˜é‡åˆ†å¸ƒ', 
                    'æ—¶é—´è¶‹åŠ¿åˆ†æ',
                    'ç›¸å…³æ€§çƒ­åŠ›å›¾', 
                    'å¤©æ°”vséœ€æ±‚',
                    'å·¥ä½œæ—¥vså‘¨æœ«', 
                    'åˆ†ç±»ç‰¹å¾åˆ†å¸ƒ'
                ),
                specs=[
                    [{"type": "histogram"}, {"type": "scatter"}],
                    [{"type": "heatmap"}, {"type": "scatter"}],
                    [{"type": "box"}, {"type": "pie"}]
                ]
            )
            
            # 1. ç›®æ ‡å˜é‡åˆ†å¸ƒ
            if target_col in self.df.columns:
                fig.add_trace(
                    go.Histogram(
                        x=self.df[target_col],
                        nbinsx=50,
                        name="åˆ†å¸ƒ",
                        marker_color='#4ECDC4',
                        opacity=0.7
                    ),
                    row=1, col=1
                )
            
            # 2. æ—¶é—´è¶‹åŠ¿
            if 'Hour' in self.df.columns and target_col in self.df.columns:
                hourly_avg = self.df.groupby('Hour')[target_col].mean()
                fig.add_trace(
                    go.Scatter(
                        x=hourly_avg.index,
                        y=hourly_avg.values,
                        mode='lines+markers',
                        name='æ—¶é—´è¶‹åŠ¿',
                        line=dict(color='#e74c3c', width=3)
                    ),
                    row=1, col=2
                )
            
            # 3. ç›¸å…³æ€§çƒ­åŠ›å›¾
            numeric_cols = self.df.select_dtypes(include=[np.number]).columns[:6]  # å‰6ä¸ªæ•°å€¼åˆ—
            if len(numeric_cols) > 1:
                corr_matrix = self.df[numeric_cols].corr()
                fig.add_trace(
                    go.Heatmap(
                        z=corr_matrix.values,
                        x=corr_matrix.columns,
                        y=corr_matrix.columns,
                        colorscale='RdBu',
                        zmid=0,
                        name="ç›¸å…³æ€§"
                    ),
                    row=2, col=1
                )
            
            # 4. å¤©æ°”vséœ€æ±‚
            weather_data_available = False
            if 'Temperature(Â°C)' in self.df.columns and target_col in self.df.columns:
                # è¿‡æ»¤æ‰ç¼ºå¤±å€¼
                temp_demand_data = self.df[['Temperature(Â°C)', target_col]].dropna()
                if len(temp_demand_data) > 0:
                    fig.add_trace(
                        go.Scatter(
                            x=temp_demand_data['Temperature(Â°C)'],
                            y=temp_demand_data[target_col],
                            mode='markers',
                            name='æ¸©åº¦vséœ€æ±‚',
                            marker=dict(color='#f39c12', size=4, opacity=0.6),
                            hovertemplate='<b>æ¸©åº¦:</b> %{x}Â°C<br><b>éœ€æ±‚:</b> %{y}<extra></extra>'
                        ),
                        row=2, col=2
                    )
                    weather_data_available = True
            
            # å¦‚æœæ²¡æœ‰æ¸©åº¦æ•°æ®ï¼Œå°è¯•å…¶ä»–å¤©æ°”æ•°æ®
            if not weather_data_available:
                if 'Humidity(%)' in self.df.columns and target_col in self.df.columns:
                    humidity_demand_data = self.df[['Humidity(%)', target_col]].dropna()
                    if len(humidity_demand_data) > 0:
                        fig.add_trace(
                            go.Scatter(
                                x=humidity_demand_data['Humidity(%)'],
                                y=humidity_demand_data[target_col],
                                mode='markers',
                                name='æ¹¿åº¦vséœ€æ±‚',
                                marker=dict(color='#3498db', size=4, opacity=0.6),
                                hovertemplate='<b>æ¹¿åº¦:</b> %{x}%<br><b>éœ€æ±‚:</b> %{y}<extra></extra>'
                            ),
                            row=2, col=2
                        )
                        weather_data_available = True
            
            # å¦‚æœè¿˜æ˜¯æ²¡æœ‰æ•°æ®ï¼Œæ˜¾ç¤ºæç¤º
            if not weather_data_available:
                fig.add_trace(
                    go.Scatter(
                        x=[0], y=[0],
                        mode='text',
                        text=['å¤©æ°”æ•°æ®ä¸å¯ç”¨'],
                        textfont=dict(size=16, color='#7f8c8d'),
                        showlegend=False
                    ),
                    row=2, col=2
                )
            
            # 5. å·¥ä½œæ—¥vså‘¨æœ«
            if 'IsWeekend' in self.df.columns and target_col in self.df.columns:
                weekday_data = self.df[self.df['IsWeekend'] == 0][target_col]
                weekend_data = self.df[self.df['IsWeekend'] == 1][target_col]
                
                fig.add_trace(
                    go.Box(y=weekday_data, name="å·¥ä½œæ—¥", marker_color='#3498db'),
                    row=3, col=1
                )
                fig.add_trace(
                    go.Box(y=weekend_data, name="å‘¨æœ«", marker_color='#e74c3c'),
                    row=3, col=1
                )
            
            # 6. å­£èŠ‚åˆ†å¸ƒ
            if 'Seasons' in self.df.columns:
                season_counts = self.df['Seasons'].value_counts()
                fig.add_trace(
                    go.Pie(
                        labels=season_counts.index,
                        values=season_counts.values,
                        name="å­£èŠ‚åˆ†å¸ƒ",
                        marker_colors=['#3498db', '#e74c3c', '#f39c12', '#2ecc71']
                    ),
                    row=3, col=2
                )
            
            fig.update_layout(
                height=1200,
                title_text="ğŸ“Š å®Œæ•´æ¢ç´¢æ€§æ•°æ®åˆ†æä»ªè¡¨æ¿",
                title_x=0.5,
                showlegend=True,
                template="plotly_white"
            )
            
            return fig
            
        except Exception as e:
            print(f"åˆ›å»ºEDAå›¾è¡¨å¤±è´¥: {str(e)}")
            return None
    
    def create_overview_chart(self):
        """åˆ›å»ºæ•°æ®æ¦‚è§ˆå›¾è¡¨"""
        if self.df is None:
            return None
        
        try:
            fig = make_subplots(
                rows=2, cols=2,
                subplot_titles=('æ•°æ®ç±»å‹åˆ†å¸ƒ', 'ç¼ºå¤±å€¼ç»Ÿè®¡', 'æ•°å€¼åˆ†å¸ƒç¤ºä¾‹', 'ç›¸å…³æ€§çƒ­åŠ›å›¾'),
                specs=[[{"type": "pie"}, {"type": "bar"}],
                       [{"type": "histogram"}, {"type": "heatmap"}]]
            )
            
            # æ•°æ®ç±»å‹åˆ†å¸ƒ
            type_counts = self.df.dtypes.value_counts()
            fig.add_trace(
                go.Pie(
                    labels=type_counts.index.astype(str), 
                    values=type_counts.values,
                    name="æ•°æ®ç±»å‹",
                    marker_colors=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']
                ),
                row=1, col=1
            )
            
            # ç¼ºå¤±å€¼ç»Ÿè®¡
            missing_data = self.df.isnull().sum()
            missing_data = missing_data[missing_data > 0].head(10)
            if len(missing_data) > 0:
                fig.add_trace(
                    go.Bar(
                        x=missing_data.index, 
                        y=missing_data.values,
                        name="ç¼ºå¤±å€¼",
                        marker_color='#FF6B6B'
                    ),
                    row=1, col=2
                )
            else:
                fig.add_trace(
                    go.Bar(x=['æ— ç¼ºå¤±å€¼'], y=[0], marker_color='#4ECDC4'),
                    row=1, col=2
                )
            
            # æ•°å€¼åˆ†å¸ƒç¤ºä¾‹
            numeric_cols = self.df.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) > 0:
                first_numeric = numeric_cols[0]
                fig.add_trace(
                    go.Histogram(
                        x=self.df[first_numeric], 
                        name=first_numeric,
                        marker_color='#45B7D1',
                        opacity=0.7
                    ),
                    row=2, col=1
                )
            
            # ç›¸å…³æ€§çƒ­åŠ›å›¾
            if len(numeric_cols) > 1:
                sample_cols = numeric_cols[:6]  # æœ€å¤šæ˜¾ç¤º6åˆ—
                corr_matrix = self.df[sample_cols].corr()
                fig.add_trace(
                    go.Heatmap(
                        z=corr_matrix.values,
                        x=corr_matrix.columns,
                        y=corr_matrix.columns,
                        colorscale='RdBu',
                        zmid=0,
                        name="ç›¸å…³æ€§"
                    ),
                    row=2, col=2
                )
            
            fig.update_layout(
                height=800,
                title_text="ğŸ“Š æ•°æ®æ¦‚è§ˆä»ªè¡¨æ¿",
                title_x=0.5,
                showlegend=False,
                template="plotly_white"
            )
            
            return fig
            
        except Exception as e:
            print(f"åˆ›å»ºæ¦‚è§ˆå›¾è¡¨å¤±è´¥: {str(e)}")
            return None
    
    def analyze_target(self, target_column):
        """å¢å¼ºç‰ˆç›®æ ‡å˜é‡æ·±åº¦åˆ†æ"""
        if self.df is None or target_column not in self.df.columns:
            return "âŒ è¯·å…ˆåŠ è½½æ•°æ®å¹¶é€‰æ‹©æœ‰æ•ˆçš„ç›®æ ‡åˆ—", None
        
        try:
            target_data = self.df[target_column]
            
            # 1. åŸºç¡€ç»Ÿè®¡åˆ†æ
            stats_dict = {
                'æ•°æ®ç‚¹æ•°é‡': len(target_data),
                'å¹³å‡å€¼': target_data.mean(),
                'ä¸­ä½æ•°': target_data.median(),
                'æ ‡å‡†å·®': target_data.std(),
                'æ–¹å·®': target_data.var(),
                'æœ€å°å€¼': target_data.min(),
                'æœ€å¤§å€¼': target_data.max(),
                'ååº¦': target_data.skew(),
                'å³°åº¦': target_data.kurtosis(),
                'é›¶å€¼æ•°é‡': (target_data == 0).sum(),
                'é›¶å€¼æ¯”ä¾‹(%)': (target_data == 0).mean() * 100
            }
            
            # 2. æ­£æ€æ€§æ£€éªŒ
            try:
                from scipy import stats
                ks_stat, ks_p = stats.kstest(target_data, 'norm')
                stats_dict['æ­£æ€æ€§æ£€éªŒpå€¼'] = ks_p
                stats_dict['æ˜¯å¦æ­£æ€åˆ†å¸ƒ'] = "å¦" if ks_p < 0.05 else "å¯èƒ½æ˜¯"
            except:
                pass
            
            # 3. é›¶å€¼æ¨¡å¼åˆ†æ
            zero_analysis = ""
            if (target_data == 0).sum() > 0:
                zero_mask = target_data == 0
                zero_data = self.df[zero_mask]
                
                if 'Hour' in self.df.columns:
                    zero_hour_dist = zero_data['Hour'].value_counts().sort_index().head(5)
                    zero_analysis = f"\nğŸ•’ **é›¶å€¼é«˜å‘æ—¶æ®µ:** "
                    for hour, count in zero_hour_dist.items():
                        pct = count / (target_data == 0).sum() * 100
                        zero_analysis += f"{hour}æ—¶({pct:.1f}%) "
            
            # 4. å¤šå³°æ£€æµ‹
            try:
                hist, bin_edges = np.histogram(target_data, bins=50)
                peaks = []
                for i in range(1, len(hist)-1):
                    if hist[i] > hist[i-1] and hist[i] > hist[i+1]:
                        peak_value = (bin_edges[i] + bin_edges[i+1]) / 2
                        peaks.append(peak_value)
                
                peak_analysis = f"\nğŸ“Š **åˆ†å¸ƒç‰¹å¾:** æ£€æµ‹åˆ°{len(peaks)}ä¸ªå³°å€¼"
                if len(peaks) > 1:
                    peak_analysis += "ï¼Œå¤šå³°åˆ†å¸ƒï¼Œå­˜åœ¨ä¸åŒä½¿ç”¨æ¨¡å¼"
            except:
                peak_analysis = ""
            
            # 5. æå€¼åˆ†æ
            max_demand = target_data.max()
            max_indices = target_data[target_data == max_demand].index
            extreme_analysis = f"\nğŸ”ï¸ **æå€¼åˆ†æ:** æœ€é«˜éœ€æ±‚{max_demand}æ¬¡ï¼Œå‡ºç°{len(max_indices)}æ¬¡"
            
            # ç»„åˆæŠ¥å‘Š
            report = f"""
            ğŸ¯ **ç›®æ ‡å˜é‡ '{target_column}' æ·±åº¦æ´å¯Ÿåˆ†æ**
            
            ğŸ“ˆ **é«˜çº§ç»Ÿè®¡ç‰¹å¾:**
            """
            
            for key, value in stats_dict.items():
                if isinstance(value, (int, float)):
                    report += f"- {key}: {value:.2f}\n"
                else:
                    report += f"- {key}: {value}\n"
            
            # åˆ†ä½æ•°åˆ†æ
            quantiles = [0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99]
            report += f"\nğŸ“Š **åˆ†ä½æ•°åˆ†æ:**\n"
            for q in quantiles:
                report += f"- Q{q*100:5.1f}: {target_data.quantile(q):8.2f}\n"
            
            # å¼‚å¸¸å€¼åˆ†æ
            Q1 = target_data.quantile(0.25)
            Q3 = target_data.quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            outliers_count = ((target_data < lower_bound) | (target_data > upper_bound)).sum()
            
            report += f"\nğŸ” **å¼‚å¸¸å€¼åˆ†æ (IQRæ–¹æ³•):**\n"
            report += f"- ä¸‹ç•Œ: {lower_bound:.2f}\n"
            report += f"- ä¸Šç•Œ: {upper_bound:.2f}\n"
            report += f"- å¼‚å¸¸å€¼æ•°é‡: {outliers_count} ({outliers_count/len(target_data)*100:.2f}%)\n"
            
            # æ·»åŠ é¢å¤–åˆ†æ
            report += zero_analysis + peak_analysis + extreme_analysis
            
            # ä¿å­˜åˆ†æç»“æœ
            self.analysis_results['target_analysis'] = {
                'basic_stats': stats_dict,
                'outliers_count': outliers_count,
                'peaks': len(peaks) if 'peaks' in locals() else 0
            }
            
            # åˆ›å»ºåˆ†æå›¾è¡¨
            fig = self.create_target_chart(target_data, target_column)
            
            return report, fig
            
        except Exception as e:
            return f"âŒ ç›®æ ‡å˜é‡åˆ†æå¤±è´¥: {str(e)}", None
    
    def create_target_chart(self, target_data, target_column):
        """åˆ›å»ºç›®æ ‡å˜é‡åˆ†æå›¾è¡¨"""
        try:
            fig = make_subplots(
                rows=2, cols=2,
                subplot_titles=(
                    f'{target_column} åˆ†å¸ƒç›´æ–¹å›¾',
                    f'{target_column} ç®±çº¿å›¾',
                    f'{target_column} Q-Qå›¾',
                    f'{target_column} æ—¶é—´è¶‹åŠ¿'
                ),
                specs=[[{"type": "histogram"}, {"type": "box"}],
                       [{"type": "scatter"}, {"type": "scatter"}]]
            )
            
            # åˆ†å¸ƒç›´æ–¹å›¾
            fig.add_trace(
                go.Histogram(
                    x=target_data, 
                    nbinsx=50, 
                    name="åˆ†å¸ƒ",
                    marker_color='#4ECDC4',
                    opacity=0.7
                ),
                row=1, col=1
            )
            
            # ç®±çº¿å›¾
            fig.add_trace(
                go.Box(
                    y=target_data, 
                    name="ç®±çº¿å›¾",
                    marker_color='#45B7D1',
                    boxpoints='outliers'
                ),
                row=1, col=2
            )
            
            # Q-Qå›¾
            theoretical_quantiles = stats.norm.ppf(np.linspace(0.01, 0.99, len(target_data)))
            sample_quantiles = np.sort(target_data)
            
            fig.add_trace(
                go.Scatter(
                    x=theoretical_quantiles[:len(sample_quantiles)], 
                    y=sample_quantiles, 
                    mode='markers', 
                    name="å®é™…æ•°æ®",
                    marker=dict(color='#FF6B6B', size=4)
                ),
                row=2, col=1
            )
            
            # æ·»åŠ ç†è®ºçº¿
            fig.add_trace(
                go.Scatter(
                    x=theoretical_quantiles, 
                    y=theoretical_quantiles, 
                    mode='lines', 
                    name="ç†è®ºçº¿",
                    line=dict(color='red', dash='dash')
                ),
                row=2, col=1
            )
            
            # æ—¶é—´è¶‹åŠ¿
            fig.add_trace(
                go.Scatter(
                    x=list(range(len(target_data))), 
                    y=target_data, 
                    mode='lines', 
                    name="æ—¶é—´è¶‹åŠ¿",
                    line=dict(color='#96CEB4', width=2)
                ),
                row=2, col=2
            )
            
            fig.update_layout(
                height=800,
                title_text=f"ğŸ¯ ç›®æ ‡å˜é‡ '{target_column}' ç»¼åˆåˆ†æ",
                title_x=0.5,
                showlegend=True,
                template="plotly_white"
            )
            
            return fig
            
        except Exception as e:
            print(f"åˆ›å»ºç›®æ ‡åˆ†æå›¾è¡¨å¤±è´¥: {str(e)}")
            return None
    
    def feature_engineering(self, date_column, target_column):
        """å¢å¼ºç‰ˆæ™ºèƒ½ç‰¹å¾å·¥ç¨‹"""
        if self.df is None:
            return "âŒ è¯·å…ˆåŠ è½½æ•°æ®", None, None
        
        try:
            processed_df = self.df.copy()
            feature_count = 0
            progress_info = "ğŸ”§ **æ™ºèƒ½ç‰¹å¾å·¥ç¨‹è¿›è¡Œä¸­...**\n\n"
            
            # 1. é«˜çº§æ—¶é—´ç‰¹å¾å·¥ç¨‹
            if date_column and date_column in processed_df.columns:
                try:
                    # ä¿®å¤æ—¥æœŸæ ¼å¼è½¬æ¢
                    try:
                        processed_df[date_column] = pd.to_datetime(processed_df[date_column], format='%d/%m/%Y')
                    except ValueError:
                        try:
                            processed_df[date_column] = pd.to_datetime(processed_df[date_column], dayfirst=True)
                        except ValueError:
                            processed_df[date_column] = pd.to_datetime(processed_df[date_column], format='mixed', dayfirst=True)
                    
                    # åŸºç¡€æ—¶é—´ç‰¹å¾
                    processed_df['Year'] = processed_df[date_column].dt.year
                    processed_df['Month'] = processed_df[date_column].dt.month
                    processed_df['Day'] = processed_df[date_column].dt.day
                    processed_df['Weekday'] = processed_df[date_column].dt.weekday
                    processed_df['DayOfYear'] = processed_df[date_column].dt.dayofyear
                    processed_df['Quarter'] = processed_df[date_column].dt.quarter
                    processed_df['IsWeekend'] = (processed_df['Weekday'] >= 5).astype(int)
                    processed_df['IsWeekday'] = (processed_df['Weekday'] < 5).astype(int)
                    
                    # ç‰¹æ®Šæ—¥æœŸæ ‡è¯†
                    processed_df['IsMonday'] = (processed_df['Weekday'] == 0).astype(int)
                    processed_df['IsFriday'] = (processed_df['Weekday'] == 4).astype(int)
                    
                    time_basic_count = 10
                    feature_count += time_basic_count
                    progress_info += f"âœ… åˆ›å»ºäº† {time_basic_count} ä¸ªåŸºç¡€æ—¶é—´ç‰¹å¾\n"
                    
                    # å‘¨æœŸæ€§ç¼–ç ï¼ˆä¸‰è§’å‡½æ•°ï¼‰
                    processed_df['Hour_Sin'] = np.sin(2 * np.pi * processed_df['Hour'] / 24)
                    processed_df['Hour_Cos'] = np.cos(2 * np.pi * processed_df['Hour'] / 24)
                    processed_df['Month_Sin'] = np.sin(2 * np.pi * processed_df['Month'] / 12)
                    processed_df['Month_Cos'] = np.cos(2 * np.pi * processed_df['Month'] / 12)
                    processed_df['DayOfYear_Sin'] = np.sin(2 * np.pi * processed_df['DayOfYear'] / 365)
                    processed_df['DayOfYear_Cos'] = np.cos(2 * np.pi * processed_df['DayOfYear'] / 365)
                    
                    # é«˜çº§æ—¶é—´æ®µç‰¹å¾ï¼ˆåŸºäºåŒå³°æ¨¡å¼ï¼‰
                    processed_df['Hour_Deep_Night'] = (processed_df['Hour'].isin([0, 1, 2, 3, 4, 5])).astype(int)
                    processed_df['Hour_Morning_Peak'] = (processed_df['Hour'].isin([8, 9])).astype(int)
                    processed_df['Hour_Evening_Peak'] = (processed_df['Hour'].isin([17, 18, 19])).astype(int)
                    processed_df['Is_Rush_Hour'] = ((processed_df['Hour'].between(7, 9)) | 
                                                  (processed_df['Hour'].between(17, 19))).astype(int)
                    processed_df['Is_Peak_Hour'] = (processed_df['Hour'].isin([8, 17, 18, 19])).astype(int)
                    
                    time_advanced_count = 11
                    feature_count += time_advanced_count
                    progress_info += f"âœ… åˆ›å»ºäº† {time_advanced_count} ä¸ªé«˜çº§æ—¶é—´ç‰¹å¾\n"
                    
                except Exception as e:
                    progress_info += f"âš ï¸ æ—¥æœŸå¤„ç†å¤±è´¥: {str(e)}\n"
            
            # 2. æ™ºèƒ½å¤©æ°”ç‰¹å¾å·¥ç¨‹
            weather_count = 0
            
            # æ¸©åº¦åˆ†æ®µç‰¹å¾
            if 'Temperature(Â°C)' in processed_df.columns:
                temp_col = 'Temperature(Â°C)'
                processed_df['Temp_Severe_Cold'] = (processed_df[temp_col] < 0).astype(int)
                processed_df['Temp_Cold'] = ((processed_df[temp_col] >= 0) & (processed_df[temp_col] < 10)).astype(int)
                processed_df['Temp_Cool'] = ((processed_df[temp_col] >= 10) & (processed_df[temp_col] < 20)).astype(int)
                processed_df['Temp_Warm'] = ((processed_df[temp_col] >= 20) & (processed_df[temp_col] < 30)).astype(int)
                processed_df['Temp_Hot'] = (processed_df[temp_col] >= 30).astype(int)
                weather_count += 5
            
            # æ¹¿åº¦ç‰¹å¾
            if 'Humidity(%)' in processed_df.columns:
                humidity_col = 'Humidity(%)'
                processed_df['Humidity_Low'] = (processed_df[humidity_col] < 30).astype(int)
                processed_df['Humidity_Medium'] = ((processed_df[humidity_col] >= 30) & (processed_df[humidity_col] < 70)).astype(int)
                processed_df['Humidity_High'] = (processed_df[humidity_col] >= 70).astype(int)
                weather_count += 3
            
            # é™æ°´ç‰¹å¾
            if 'Rainfall(mm)' in processed_df.columns:
                processed_df['Has_Rain'] = (processed_df['Rainfall(mm)'] > 0).astype(int)
                processed_df['Heavy_Rain'] = (processed_df['Rainfall(mm)'] > 10).astype(int)
                weather_count += 2
            
            if 'Snowfall (cm)' in processed_df.columns:
                processed_df['Has_Snow'] = (processed_df['Snowfall (cm)'] > 0).astype(int)
                weather_count += 1
            
            feature_count += weather_count
            progress_info += f"âœ… åˆ›å»ºäº† {weather_count} ä¸ªå¤©æ°”åˆ†æ®µç‰¹å¾\n"
            
            # 3. èˆ’é€‚åº¦æŒ‡æ•°ç‰¹å¾
            comfort_count = 0
            if 'Temperature(Â°C)' in processed_df.columns and 'Humidity(%)' in processed_df.columns:
                temp_col = 'Temperature(Â°C)'
                humidity_col = 'Humidity(%)'
                
                # èˆ’é€‚åº¦æŒ‡æ•°
                processed_df['Comfort_Index'] = np.where(
                    (processed_df[temp_col].between(20, 30)) & (processed_df[humidity_col].between(30, 70)),
                    1.0,  # æœ€èˆ’é€‚
                    np.where(
                        (processed_df[temp_col].between(10, 35)) & (processed_df[humidity_col].between(20, 80)),
                        0.7,  # è¾ƒèˆ’é€‚
                        0.4   # ä¸€èˆ¬
                    )
                )
                
                # å®Œç¾å¤©æ°”æ ‡è¯†
                perfect_conditions = [
                    processed_df[temp_col].between(20, 28),
                    processed_df[humidity_col].between(40, 60)
                ]
                
                if 'Rainfall(mm)' in processed_df.columns:
                    perfect_conditions.append(processed_df['Rainfall(mm)'] == 0)
                if 'Snowfall (cm)' in processed_df.columns:
                    perfect_conditions.append(processed_df['Snowfall (cm)'] == 0)
                
                processed_df['Perfect_Weather'] = pd.concat(perfect_conditions, axis=1).all(axis=1).astype(int)
                comfort_count = 2
                
                feature_count += comfort_count
                progress_info += f"âœ… åˆ›å»ºäº† {comfort_count} ä¸ªèˆ’é€‚åº¦ç‰¹å¾\n"
            
            # 4. é«˜çº§äº¤äº’ç‰¹å¾
            interaction_count = 0
            
            # æ¸©åº¦Ã—æ—¶é—´äº¤äº’
            if 'Temperature(Â°C)' in processed_df.columns and 'Hour' in processed_df.columns:
                processed_df['Temp_Hour'] = processed_df['Temperature(Â°C)'] * processed_df['Hour']
                processed_df['Temp_Weekend'] = processed_df['Temperature(Â°C)'] * processed_df['IsWeekend']
                if 'Is_Peak_Hour' in processed_df.columns:
                    processed_df['Temp_Peak'] = processed_df['Temperature(Â°C)'] * processed_df['Is_Peak_Hour']
                interaction_count += 3
            
            # èˆ’é€‚åº¦Ã—æ—¶é—´äº¤äº’
            if 'Comfort_Index' in processed_df.columns:
                processed_df['Comfort_Peak'] = processed_df['Comfort_Index'] * processed_df['Is_Peak_Hour']
                processed_df['Comfort_Weekend'] = processed_df['Comfort_Index'] * processed_df['IsWeekend']
                interaction_count += 2
            
            feature_count += interaction_count
            progress_info += f"âœ… åˆ›å»ºäº† {interaction_count} ä¸ªäº¤äº’ç‰¹å¾\n"
            
            # 5. æ•°å€¼ç‰¹å¾å˜æ¢
            numeric_cols = processed_df.select_dtypes(include=[np.number]).columns
            numeric_cols = [col for col in numeric_cols if col != target_column and col in ['Wind speed (m/s)', 'Visibility (10m)', 'Dew point temperature(Â°C)', 'Solar Radiation (MJ/m2)']]
            
            transform_count = 0
            for col in numeric_cols[:3]:  # é™åˆ¶å¤„ç†å‰3åˆ—
                try:
                    # å¹³æ–¹ç‰¹å¾
                    processed_df[f'{col}_Squared'] = processed_df[col] ** 2
                    transform_count += 1
                    
                    # å¯¹æ•°å˜æ¢ï¼ˆå¤„ç†æ­£å€¼ï¼‰
                    if (processed_df[col] > 0).all():
                        processed_df[f'{col}_Log'] = np.log1p(processed_df[col])
                        transform_count += 1
                        
                except Exception as e:
                    continue
            
            feature_count += transform_count
            progress_info += f"âœ… åˆ›å»ºäº† {transform_count} ä¸ªæ•°å€¼å˜æ¢ç‰¹å¾\n"
            
            # ä¿å­˜å¤„ç†åçš„æ•°æ®
            self.processed_data = processed_df
            
            # ä¿å­˜é¢„å¤„ç†ç»“æœ
            self.preprocessing_results = {
                'original_shape': self.df.shape,
                'final_shape': processed_df.shape,
                'total_features_created': feature_count,
                'feature_breakdown': {
                    'time_basic': time_basic_count if 'time_basic_count' in locals() else 0,
                    'time_advanced': time_advanced_count if 'time_advanced_count' in locals() else 0,
                    'weather': weather_count,
                    'comfort': comfort_count,
                    'interaction': interaction_count,
                    'transform': transform_count
                }
            }
            
            # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
            final_info = f"""
            ğŸ‰ **æ™ºèƒ½ç‰¹å¾å·¥ç¨‹å®Œæˆï¼**
            
            ğŸ“Š **ç‰¹å¾ç»Ÿè®¡:**
            - åŸå§‹ç‰¹å¾æ•°: {self.df.shape[1]}
            - æ–°å¢ç‰¹å¾æ•°: {feature_count}
            - æœ€ç»ˆç‰¹å¾æ•°: {processed_df.shape[1]}
            - æ•°æ®å½¢çŠ¶: {processed_df.shape}
            
            ğŸ”§ **æ™ºèƒ½å¤„ç†æ­¥éª¤:**
            {progress_info}
            
            ğŸ¯ **ç‰¹å¾å·¥ç¨‹äº®ç‚¹:**
            - åŸºäºåŒå³°æ¨¡å¼çš„æ—¶é—´æ®µè¯†åˆ«
            - æ™ºèƒ½èˆ’é€‚åº¦æŒ‡æ•°è®¡ç®—
            - å¤šç»´åº¦äº¤äº’ç‰¹å¾ç”Ÿæˆ
            - è‡ªé€‚åº”æ•°å€¼å˜æ¢
            """
            
            # åˆ›å»ºç‰¹å¾é‡è¦æ€§å›¾è¡¨
            importance_chart = self.create_importance_chart(target_column)
            
            # ç”Ÿæˆå¤„ç†åæ•°æ®é¢„è§ˆ
            preview_html = processed_df.head(8).to_html(
                classes="table table-striped table-hover",
                escape=False
            )
            
            return final_info, importance_chart, preview_html
            
        except Exception as e:
            return f"âŒ æ™ºèƒ½ç‰¹å¾å·¥ç¨‹å¤±è´¥: {str(e)}", None, None
    
    def complete_preprocessing_pipeline(self):
        """å®Œæ•´çš„æ•°æ®é¢„å¤„ç†æµæ°´çº¿ - åˆ†æ­¥éª¤å¯è§†åŒ–ç‰ˆæœ¬"""
        if self.df is None:
            return "âŒ è¯·å…ˆåŠ è½½æ•°æ®", None, None, None
        
        try:
            # åˆå§‹åŒ–æ­¥éª¤è¿½è¸ª
            self.pipeline_steps = {}
            self.feature_explanations = {}
            
            preprocessing_report = "ğŸ”§ **å®Œæ•´æ•°æ®é¢„å¤„ç†æµæ°´çº¿ (Enhancedæ¨¡å—æ ‡å‡†)**\n\n"
            
            # å¤åˆ¶æ•°æ®ä»¥é¿å…ä¿®æ”¹åŸå§‹æ•°æ®
            processed_df = self.df.copy()
            original_shape = processed_df.shape
            self.pipeline_steps['original'] = {
                'data': processed_df.copy(),
                'shape': original_shape,
                'features': list(processed_df.columns)
            }
            
            preprocessing_report += f"ğŸ“Š **åŸå§‹æ•°æ®:** {original_shape[0]} è¡Œ Ã— {original_shape[1]} åˆ—\n\n"
            
            # æ­¥éª¤1: å¤„ç†éè¿è¥æ—¥
            step1_df = processed_df.copy()
            remaining_count = len(step1_df)
            if 'Functioning Day' in step1_df.columns:
                non_functioning = step1_df['Functioning Day'] == 'No'
                non_functioning_count = non_functioning.sum()
                step1_df = step1_df[step1_df['Functioning Day'] == 'Yes'].reset_index(drop=True)
                remaining_count = len(step1_df)
                
                self.pipeline_steps['step1'] = {
                    'data': step1_df.copy(),
                    'removed_rows': non_functioning_count,
                    'remaining_rows': remaining_count,
                    'description': 'ç§»é™¤éè¿è¥æ—¥æ•°æ®'
                }
                
                preprocessing_report += f"ğŸ”§ **æ­¥éª¤1: éè¿è¥æ—¥å¤„ç†**\n"
                preprocessing_report += f"- ç§»é™¤éè¿è¥æ—¥: {non_functioning_count} æ¡è®°å½•\n"
                preprocessing_report += f"- å‰©ä½™æ•°æ®: {remaining_count} è¡Œ\n\n"
            else:
                self.pipeline_steps['step1'] = {
                    'data': step1_df.copy(),
                    'removed_rows': 0,
                    'remaining_rows': remaining_count,
                    'description': 'æ— éè¿è¥æ—¥æ•°æ®éœ€è¦å¤„ç†'
                }
            
            processed_df = step1_df.copy()
            
            # æ­¥éª¤2: åŸºç¡€æ—¶é—´ç‰¹å¾
            step2_df = processed_df.copy()
            time_features = []
            time_feature_details = {}
            
            if 'Date' in step2_df.columns:
                date_col = 'Date'
                try:
                    # å°è¯•å¤šç§æ—¥æœŸæ ¼å¼
                    step2_df[date_col] = pd.to_datetime(step2_df[date_col], format='%d/%m/%Y')
                except ValueError:
                    try:
                        step2_df[date_col] = pd.to_datetime(step2_df[date_col], dayfirst=True)
                    except ValueError:
                        step2_df[date_col] = pd.to_datetime(step2_df[date_col], format='mixed', dayfirst=True)
                
                # åŸºç¡€æ—¶é—´ç‰¹å¾
                basic_time_features = {
                    'Year': (step2_df[date_col].dt.year, 'å¹´ä»½: ä»æ—¥æœŸä¸­æå–å¹´ä»½ä¿¡æ¯'),
                    'Month': (step2_df[date_col].dt.month, 'æœˆä»½: ä»æ—¥æœŸä¸­æå–æœˆä»½(1-12)'),
                    'Day': (step2_df[date_col].dt.day, 'æ—¥æœŸ: ä»æ—¥æœŸä¸­æå–æ—¥æœŸ(1-31)'),
                    'Weekday': (step2_df[date_col].dt.weekday, 'æ˜ŸæœŸ: æ˜ŸæœŸä¸€=0åˆ°æ˜ŸæœŸæ—¥=6'),
                    'DayOfYear': (step2_df[date_col].dt.dayofyear, 'å¹´ä¸­å¤©æ•°: ä¸€å¹´ä¸­çš„ç¬¬å‡ å¤©(1-365)'),
                    'Quarter': (step2_df[date_col].dt.quarter, 'å­£åº¦: ä¸€å¹´ä¸­çš„å­£åº¦(1-4)'),
                    'IsWeekend': ((step2_df[date_col].dt.weekday >= 5).astype(int), 'å‘¨æœ«æ ‡è¯†: å‘¨å…­æ—¥=1,å·¥ä½œæ—¥=0')
                }
                
                for feature, (data, description) in basic_time_features.items():
                    step2_df[feature] = data
                    time_feature_details[feature] = description
                
                # å‘¨æœŸæ€§ç¼–ç ï¼ˆä¸‰è§’å‡½æ•°ï¼‰
                cyclic_features = {
                    'Hour_Sin': (np.sin(2 * np.pi * step2_df['Hour'] / 24), 'å°æ—¶æ­£å¼¦ç¼–ç : sin(2Ï€Ã—å°æ—¶/24)'),
                    'Hour_Cos': (np.cos(2 * np.pi * step2_df['Hour'] / 24), 'å°æ—¶ä½™å¼¦ç¼–ç : cos(2Ï€Ã—å°æ—¶/24)'),
                    'DayOfYear_Sin': (np.sin(2 * np.pi * step2_df['DayOfYear'] / 365), 'å¹´ä¸­å¤©æ•°æ­£å¼¦ç¼–ç : æ•æ‰å­£èŠ‚æ€§'),
                    'DayOfYear_Cos': (np.cos(2 * np.pi * step2_df['DayOfYear'] / 365), 'å¹´ä¸­å¤©æ•°ä½™å¼¦ç¼–ç : æ•æ‰å­£èŠ‚æ€§'),
                    'Month_Sin': (np.sin(2 * np.pi * step2_df['Month'] / 12), 'æœˆä»½æ­£å¼¦ç¼–ç : æ•æ‰æœˆåº¦å‘¨æœŸ'),
                    'Month_Cos': (np.cos(2 * np.pi * step2_df['Month'] / 12), 'æœˆä»½ä½™å¼¦ç¼–ç : æ•æ‰æœˆåº¦å‘¨æœŸ'),
                    'Weekday_Sin': (np.sin(2 * np.pi * step2_df['Weekday'] / 7), 'æ˜ŸæœŸæ­£å¼¦ç¼–ç : æ•æ‰å‘¨æœŸæ€§'),
                    'Weekday_Cos': (np.cos(2 * np.pi * step2_df['Weekday'] / 7), 'æ˜ŸæœŸä½™å¼¦ç¼–ç : æ•æ‰å‘¨æœŸæ€§')
                }
                
                for feature, (data, description) in cyclic_features.items():
                    step2_df[feature] = data
                    time_feature_details[feature] = description
                
                time_features = list(basic_time_features.keys()) + list(cyclic_features.keys())
                
                self.pipeline_steps['step2'] = {
                    'data': step2_df.copy(),
                    'new_features': time_features,
                    'feature_details': time_feature_details,
                    'description': 'åˆ›å»ºåŸºç¡€æ—¶é—´ç‰¹å¾å’Œå‘¨æœŸæ€§ç¼–ç '
                }
                
                preprocessing_report += f"â° **æ­¥éª¤2: æ—¥æœŸæ—¶é—´ç‰¹å¾**\n"
                preprocessing_report += f"- åˆ›å»º {len(time_features)} ä¸ªåŸºç¡€æ—¶é—´ç‰¹å¾\n\n"
            
            processed_df = step2_df.copy()
            
            # 3. é«˜çº§æ—¶é—´ç‰¹å¾ (åŸºäºæ•°æ®æ´å¯Ÿçš„åŒå³°æ¨¡å¼)
            advanced_time_features = []
            if 'Hour' in processed_df.columns:
                # åŸºäºåŒå³°æ¨¡å¼çš„æ—¶é—´æ®µç‰¹å¾
                processed_df['Hour_Deep_Night'] = (processed_df['Hour'].isin([0, 1, 2, 3, 4, 5])).astype(int)
                processed_df['Hour_Early_Morning'] = (processed_df['Hour'].isin([6, 7])).astype(int)
                processed_df['Hour_Morning_Peak'] = (processed_df['Hour'].isin([8, 9])).astype(int)
                processed_df['Hour_Morning_Decline'] = (processed_df['Hour'].isin([10, 11, 12])).astype(int)
                processed_df['Hour_Afternoon'] = (processed_df['Hour'].isin([13, 14, 15, 16])).astype(int)
                processed_df['Hour_Evening_Peak'] = (processed_df['Hour'].isin([17, 18, 19])).astype(int)
                processed_df['Hour_Evening_Decline'] = (processed_df['Hour'].isin([20, 21, 22, 23])).astype(int)
                
                # å³°å€¼æ—¶é—´æ ‡è¯†
                processed_df['Is_Peak_Hour'] = (processed_df['Hour'].isin([8, 17, 18, 19])).astype(int)
                processed_df['Is_Low_Hour'] = (processed_df['Hour'].isin([3, 4, 5])).astype(int)
                
                # é€šå‹¤æ—¶é—´æ ‡è¯†
                processed_df['Is_Rush_Hour'] = ((processed_df['Hour'].between(7, 9)) | 
                                              (processed_df['Hour'].between(17, 19))).astype(int)
                
                advanced_time_features = [
                    'Hour_Deep_Night', 'Hour_Early_Morning', 'Hour_Morning_Peak',
                    'Hour_Morning_Decline', 'Hour_Afternoon', 'Hour_Evening_Peak',
                    'Hour_Evening_Decline', 'Is_Peak_Hour', 'Is_Low_Hour', 'Is_Rush_Hour'
                ]
                
                preprocessing_report += f"ğŸ• **æ­¥éª¤3: é«˜çº§æ—¶é—´ç‰¹å¾**\n"
                preprocessing_report += f"- åˆ›å»º {len(advanced_time_features)} ä¸ªé«˜çº§æ—¶é—´ç‰¹å¾\n\n"
            
            # 4. å¤©æ°”ç‰¹å¾å·¥ç¨‹ (å®Œå…¨å¤åˆ¶enhancedæ¨¡å—çš„è¯¦ç»†åˆ†æ®µ)
            weather_features = []
            
            # æ¸©åº¦åˆ†æ®µç‰¹å¾ (åŸºäºconfig.pyçš„é˜ˆå€¼)
            if 'Temperature(Â°C)' in processed_df.columns:
                temp_col = 'Temperature(Â°C)'
                # temp_ranges: [-50, 0, 10, 20, 30, 50]
                processed_df['Temp_Severe_Cold'] = (processed_df[temp_col] < 0).astype(int)
                processed_df['Temp_Cold'] = ((processed_df[temp_col] >= 0) & (processed_df[temp_col] < 10)).astype(int)
                processed_df['Temp_Cool'] = ((processed_df[temp_col] >= 10) & (processed_df[temp_col] < 20)).astype(int)
                processed_df['Temp_Warm'] = ((processed_df[temp_col] >= 20) & (processed_df[temp_col] < 30)).astype(int)
                processed_df['Temp_Hot'] = (processed_df[temp_col] >= 30).astype(int)
                weather_features.extend(['Temp_Severe_Cold', 'Temp_Cold', 'Temp_Cool', 'Temp_Warm', 'Temp_Hot'])
            
            # æ¹¿åº¦åˆ†æ®µç‰¹å¾ (4ä¸ªç­‰çº§)
            if 'Humidity(%)' in processed_df.columns:
                humidity_col = 'Humidity(%)'
                # humidity_ranges: [0, 30, 50, 70, 100]
                processed_df['Humidity_Low'] = (processed_df[humidity_col] < 30).astype(int)
                processed_df['Humidity_Medium'] = ((processed_df[humidity_col] >= 30) & (processed_df[humidity_col] < 50)).astype(int)
                processed_df['Humidity_High'] = ((processed_df[humidity_col] >= 50) & (processed_df[humidity_col] < 70)).astype(int)
                processed_df['Humidity_Very_High'] = (processed_df[humidity_col] >= 70).astype(int)
                weather_features.extend(['Humidity_Low', 'Humidity_Medium', 'Humidity_High', 'Humidity_Very_High'])
            
            # é£é€Ÿåˆ†æ®µç‰¹å¾
            if 'Wind speed (m/s)' in processed_df.columns:
                wind_col = 'Wind speed (m/s)'
                # wind_ranges: [0, 2, 4, 6, 20]
                processed_df['Wind_Calm'] = (processed_df[wind_col] < 2).astype(int)
                processed_df['Wind_Light'] = ((processed_df[wind_col] >= 2) & (processed_df[wind_col] < 4)).astype(int)
                processed_df['Wind_Moderate'] = ((processed_df[wind_col] >= 4) & (processed_df[wind_col] < 6)).astype(int)
                processed_df['Wind_Strong'] = (processed_df[wind_col] >= 6).astype(int)
                weather_features.extend(['Wind_Calm', 'Wind_Light', 'Wind_Moderate', 'Wind_Strong'])
            
            # é™æ°´ç‰¹å¾ (è¯¦ç»†åˆ†çº§)
            if 'Rainfall(mm)' in processed_df.columns:
                processed_df['Has_Rain'] = (processed_df['Rainfall(mm)'] > 0).astype(int)
                processed_df['Light_Rain'] = ((processed_df['Rainfall(mm)'] > 0) & (processed_df['Rainfall(mm)'] <= 2.5)).astype(int)
                processed_df['Moderate_Rain'] = ((processed_df['Rainfall(mm)'] > 2.5) & (processed_df['Rainfall(mm)'] <= 10)).astype(int)
                processed_df['Heavy_Rain'] = (processed_df['Rainfall(mm)'] > 10).astype(int)
                weather_features.extend(['Has_Rain', 'Light_Rain', 'Moderate_Rain', 'Heavy_Rain'])
            
            if 'Snowfall (cm)' in processed_df.columns:
                processed_df['Has_Snow'] = (processed_df['Snowfall (cm)'] > 0).astype(int)
                processed_df['Light_Snow'] = ((processed_df['Snowfall (cm)'] > 0) & (processed_df['Snowfall (cm)'] <= 2)).astype(int)
                processed_df['Heavy_Snow'] = (processed_df['Snowfall (cm)'] > 2).astype(int)
                weather_features.extend(['Has_Snow', 'Light_Snow', 'Heavy_Snow'])
            
            # é™æ°´æ€»é‡
            if 'Rainfall(mm)' in processed_df.columns and 'Snowfall (cm)' in processed_df.columns:
                processed_df['Total_Precipitation'] = processed_df['Rainfall(mm)'] + processed_df['Snowfall (cm)']
                processed_df['Has_Precipitation'] = ((processed_df['Rainfall(mm)'] > 0) | (processed_df['Snowfall (cm)'] > 0)).astype(int)
                weather_features.extend(['Total_Precipitation', 'Has_Precipitation'])
            
            preprocessing_report += f"ğŸŒ¤ï¸ **æ­¥éª¤4: å¤©æ°”ç‰¹å¾å·¥ç¨‹**\n"
            preprocessing_report += f"- åˆ›å»º {len(weather_features)} ä¸ªå¤©æ°”ç‰¹å¾\n\n"
            
            # 5. èˆ’é€‚åº¦æŒ‡æ•°ç‰¹å¾ (å®Œå…¨å¤åˆ¶enhancedæ¨¡å—)
            comfort_features = []
            if 'Temperature(Â°C)' in processed_df.columns and 'Humidity(%)' in processed_df.columns:
                temp_col = 'Temperature(Â°C)'
                humidity_col = 'Humidity(%)'
                
                # èˆ’é€‚åº¦æŒ‡æ•°ï¼ˆ4çº§åˆ†ç±»ï¼‰
                processed_df['Comfort_Index'] = np.where(
                    (processed_df[temp_col].between(20, 30)) & (processed_df[humidity_col].between(30, 70)),
                    1.0,  # æœ€èˆ’é€‚
                    np.where(
                        (processed_df[temp_col].between(10, 35)) & (processed_df[humidity_col].between(20, 80)),
                        0.7,  # è¾ƒèˆ’é€‚
                        np.where(
                            (processed_df[temp_col].between(0, 40)) & (processed_df[humidity_col].between(10, 90)),
                            0.4,  # ä¸€èˆ¬
                            0.1   # ä¸èˆ’é€‚
                        )
                    )
                )
                
                # ä½“æ„Ÿæ¸©åº¦ï¼ˆHeat Indexç®€åŒ–ç‰ˆï¼‰
                processed_df['Heat_Index'] = (processed_df[temp_col] + 
                                            0.5 * (processed_df[humidity_col] - 50) / 100 * processed_df[temp_col])
                
                # å®Œç¾å¤©æ°”æ ‡è¯†
                perfect_conditions = [
                    processed_df[temp_col].between(20, 28),
                    processed_df[humidity_col].between(40, 60),
                    processed_df.get('Rainfall(mm)', pd.Series([0]*len(processed_df))) == 0,
                    processed_df.get('Snowfall (cm)', pd.Series([0]*len(processed_df))) == 0
                ]
                if 'Wind speed (m/s)' in processed_df.columns:
                    perfect_conditions.append(processed_df['Wind speed (m/s)'] < 3)
                
                processed_df['Perfect_Weather'] = pd.concat(perfect_conditions, axis=1).all(axis=1).astype(int)
                
                # æç«¯å¤©æ°”æ ‡è¯†
                extreme_conditions = [
                    processed_df[temp_col] < -10,
                    processed_df[temp_col] > 35,
                    processed_df[humidity_col] > 90,
                    processed_df[humidity_col] < 20
                ]
                if 'Rainfall(mm)' in processed_df.columns:
                    extreme_conditions.append(processed_df['Rainfall(mm)'] > 10)
                if 'Snowfall (cm)' in processed_df.columns:
                    extreme_conditions.append(processed_df['Snowfall (cm)'] > 5)
                
                processed_df['Extreme_Weather'] = pd.concat(extreme_conditions, axis=1).any(axis=1).astype(int)
                
                comfort_features = ['Comfort_Index', 'Heat_Index', 'Perfect_Weather', 'Extreme_Weather']
                
                preprocessing_report += f"ğŸ˜Š **æ­¥éª¤5: èˆ’é€‚åº¦æŒ‡æ•°ç‰¹å¾**\n"
                preprocessing_report += f"- åˆ›å»º {len(comfort_features)} ä¸ªèˆ’é€‚åº¦ç‰¹å¾\n\n"
            
            # 6. äº¤äº’ç‰¹å¾ (å®Œå…¨å¤åˆ¶enhancedæ¨¡å—)
            interaction_features = []
            
            # æ¸©åº¦Ã—æ—¶é—´äº¤äº’
            if 'Temperature(Â°C)' in processed_df.columns:
                processed_df['Temp_Hour'] = processed_df['Temperature(Â°C)'] * processed_df['Hour']
                processed_df['Temp_Weekend'] = processed_df['Temperature(Â°C)'] * processed_df['IsWeekend']
                processed_df['Temp_Peak'] = processed_df['Temperature(Â°C)'] * processed_df['Is_Peak_Hour']
                interaction_features.extend(['Temp_Hour', 'Temp_Weekend', 'Temp_Peak'])
            
            # å­£èŠ‚Ã—æ—¶é—´äº¤äº’
            if 'Seasons' in processed_df.columns:
                for season in processed_df['Seasons'].unique():
                    season_col = f'Season_{season}'
                    processed_df[season_col] = (processed_df['Seasons'] == season).astype(int)
                    
                    peak_interaction_col = f'{season}_Peak'
                    weekend_interaction_col = f'{season}_Weekend'
                    
                    processed_df[peak_interaction_col] = processed_df[season_col] * processed_df['Is_Peak_Hour']
                    processed_df[weekend_interaction_col] = processed_df[season_col] * processed_df['IsWeekend']
                    
                    interaction_features.extend([season_col, peak_interaction_col, weekend_interaction_col])
            
            # èˆ’é€‚åº¦Ã—æ—¶é—´äº¤äº’
            if 'Comfort_Index' in processed_df.columns:
                processed_df['Comfort_Peak'] = processed_df['Comfort_Index'] * processed_df['Is_Peak_Hour']
                processed_df['Comfort_Weekend'] = processed_df['Comfort_Index'] * processed_df['IsWeekend']
                interaction_features.extend(['Comfort_Peak', 'Comfort_Weekend'])
            
            # å¤©æ°”ç»„åˆç‰¹å¾
            if 'Temperature(Â°C)' in processed_df.columns and 'Humidity(%)' in processed_df.columns:
                processed_df['Temp_Humidity'] = processed_df['Temperature(Â°C)'] * processed_df['Humidity(%)'] / 100
                interaction_features.append('Temp_Humidity')
            
            preprocessing_report += f"ğŸ”— **æ­¥éª¤6: äº¤äº’ç‰¹å¾**\n"
            preprocessing_report += f"- åˆ›å»º {len(interaction_features)} ä¸ªäº¤äº’ç‰¹å¾\n\n"
            
            # 7. åˆ†ç±»ç‰¹å¾ç¼–ç 
            encoded_features = []
            categorical_features = ['Seasons', 'Holiday']
            
            for col in categorical_features:
                if col in processed_df.columns:
                    # One-hotç¼–ç 
                    dummies = pd.get_dummies(processed_df[col], prefix=col)
                    processed_df = pd.concat([processed_df, dummies], axis=1)
                    encoded_features.extend(dummies.columns.tolist())
            
            preprocessing_report += f"ğŸ“‘ **æ­¥éª¤7: åˆ†ç±»ç‰¹å¾ç¼–ç **\n"
            preprocessing_report += f"- One-hotç¼–ç ç”Ÿæˆ {len(encoded_features)} ä¸ªç‰¹å¾\n\n"
            
            # 8. ç‰¹å¾é€‰æ‹© (enhancedæ¨¡å—çš„correlationæ–¹æ³•ï¼Œä¸é™åˆ¶æ•°é‡)
            target_col = 'Rented Bike Count'
            if target_col in processed_df.columns:
                # è·å–æ‰€æœ‰æ•°å€¼ç‰¹å¾ï¼ˆæ’é™¤ç›®æ ‡å˜é‡å’Œæ—¥æœŸï¼‰
                exclude_cols = [target_col, 'Date']
                numeric_features = processed_df.select_dtypes(include=[np.number]).columns.tolist()
                feature_candidates = [col for col in numeric_features if col not in exclude_cols]
                
                # åŸºäºç›¸å…³æ€§é€‰æ‹© (enhancedæ¨¡å—çš„é»˜è®¤æ–¹æ³•)
                correlations = processed_df[feature_candidates + [target_col]].corr()[target_col].abs()
                correlations = correlations.drop(target_col).sort_values(ascending=False)
                
                # enhancedæ¨¡å—çš„ç›¸å…³æ€§é˜ˆå€¼ä¸º0.1ï¼Œä¸é™åˆ¶ç‰¹å¾æ•°é‡
                threshold = 0.1
                selected_features = correlations[correlations > threshold].index.tolist()
                
                preprocessing_report += f"ğŸ¯ **æ­¥éª¤8: ç‰¹å¾é€‰æ‹© (Enhancedæ ‡å‡†)**\n"
                preprocessing_report += f"- å€™é€‰ç‰¹å¾: {len(feature_candidates)} ä¸ª\n"
                preprocessing_report += f"- ç›¸å…³æ€§é˜ˆå€¼: {threshold}\n"
                preprocessing_report += f"- æœ€ç»ˆé€‰æ‹©: {len(selected_features)} ä¸ªç‰¹å¾\n\n"
                
                # ä¿å­˜æœ€ç»ˆæ•°æ®
                final_features = selected_features + [target_col]
                self.final_preprocessed_data = processed_df[final_features].copy()
                
                # Topç‰¹å¾å±•ç¤º
                top_features = correlations.head(10)
                preprocessing_report += f"ğŸ† **Top 10 ç‰¹å¾ (æŒ‰ç›¸å…³æ€§):**\n"
                for i, (feature, corr) in enumerate(top_features.items(), 1):
                    preprocessing_report += f"{i:2d}. {feature}: {corr:.4f}\n"
                preprocessing_report += "\n"
            
            # 9. æ•°æ®é›†åˆ†å‰²ï¼ˆæ—¶é—´åºåˆ—å‹å¥½ï¼‰
            if self.final_preprocessed_data is not None and len(self.final_preprocessed_data) > 0:
                # æŒ‰æ—¶é—´é¡ºåºåˆ†å‰² (enhancedæ¨¡å—æ ‡å‡†: 70%/15%/15%)
                total_samples = len(self.final_preprocessed_data)
                train_size = int(0.7 * total_samples)
                val_size = int(0.15 * total_samples)
                test_size = total_samples - train_size - val_size
                
                # åˆ†å‰²æ•°æ®
                train_data = self.final_preprocessed_data.iloc[:train_size].copy()
                val_data = self.final_preprocessed_data.iloc[train_size:train_size+val_size].copy()
                test_data = self.final_preprocessed_data.iloc[train_size+val_size:].copy()
                
                # ä¿å­˜åˆ†å‰²åçš„æ•°æ®
                self.train_data = train_data
                self.val_data = val_data
                self.test_data = test_data
                
                preprocessing_report += f"ğŸ“Š **æ­¥éª¤9: æ•°æ®é›†åˆ†å‰² (æ—¶é—´åºåˆ—æ–¹å¼)**\n"
                preprocessing_report += f"- è®­ç»ƒé›†: {train_data.shape[0]} è¡Œ Ã— {train_data.shape[1]} åˆ— (70.0%)\n"
                preprocessing_report += f"- éªŒè¯é›†: {val_data.shape[0]} è¡Œ Ã— {val_data.shape[1]} åˆ— (15.0%)\n"
                preprocessing_report += f"- æµ‹è¯•é›†: {test_data.shape[0]} è¡Œ Ã— {test_data.shape[1]} åˆ— ({test_size/total_samples*100:.1f}%)\n\n"
            
            # æœ€ç»ˆç»Ÿè®¡  
            final_shape = self.final_preprocessed_data.shape if self.final_preprocessed_data is not None else processed_df.shape
            preprocessing_report += f"âœ… **é¢„å¤„ç†å®Œæˆ (Enhancedæ ‡å‡†):**\n"
            preprocessing_report += f"- æœ€ç»ˆæ•°æ®: {final_shape[0]} è¡Œ Ã— {final_shape[1]} åˆ—\n"
            preprocessing_report += f"- ç‰¹å¾ç»Ÿè®¡:\n"
            preprocessing_report += f"  â€¢ æ—¶é—´ç‰¹å¾: {len(time_features) if 'time_features' in locals() else 0} ä¸ª\n"
            preprocessing_report += f"  â€¢ é«˜çº§æ—¶é—´ç‰¹å¾: {len(advanced_time_features) if 'advanced_time_features' in locals() else 0} ä¸ª\n" 
            preprocessing_report += f"  â€¢ å¤©æ°”ç‰¹å¾: {len(weather_features) if 'weather_features' in locals() else 0} ä¸ª\n"
            preprocessing_report += f"  â€¢ èˆ’é€‚åº¦ç‰¹å¾: {len(comfort_features) if 'comfort_features' in locals() else 0} ä¸ª\n"
            preprocessing_report += f"  â€¢ äº¤äº’ç‰¹å¾: {len(interaction_features) if 'interaction_features' in locals() else 0} ä¸ª\n"
            preprocessing_report += f"  â€¢ ç¼–ç ç‰¹å¾: {len(encoded_features) if 'encoded_features' in locals() else 0} ä¸ª\n"
            preprocessing_report += f"  â€¢ é€‰æ‹©ç‰¹å¾: {len(selected_features) if 'selected_features' in locals() else 0} ä¸ª\n"
            
            if hasattr(self, 'train_data'):
                preprocessing_report += f"- å»ºæ¨¡å°±ç»ª: âœ… è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†å·²å‡†å¤‡\n"
            
            # æ·»åŠ è¯¦ç»†ç‰¹å¾è¯´æ˜
            preprocessing_report += f"\n\n## ğŸ” **è¯¦ç»†ç‰¹å¾ç”Ÿæˆè¿‡ç¨‹è¯´æ˜**\n\n"
            
            # ç”Ÿæˆç‰¹å¾è¯¦ç»†è¯´æ˜
            if hasattr(self, 'pipeline_steps'):
                for step_name, step_data in self.pipeline_steps.items():
                    if step_name.startswith('step') and 'feature_details' in step_data:
                        step_num = step_name.replace('step', '')
                        step_desc = step_data.get('description', '')
                        features = step_data.get('new_features', [])
                        details = step_data.get('feature_details', {})
                        
                        if features and details:
                            preprocessing_report += f"### ğŸ“ **æ­¥éª¤{step_num}: {step_desc}**\n\n"
                            for feature in features[:10]:  # é™åˆ¶æ˜¾ç¤ºå‰10ä¸ªç‰¹å¾
                                if feature in details:
                                    preprocessing_report += f"- **{feature}**: {details[feature]}\n"
                            if len(features) > 10:
                                preprocessing_report += f"- ... å…± {len(features)} ä¸ªç‰¹å¾\n"
                            preprocessing_report += "\n"
            
            # åˆ›å»ºåˆ†æ­¥éª¤å¯è§†åŒ–
            step_by_step_plot = self.create_step_by_step_visualization()
            
            # ç”Ÿæˆä¸‹è½½æ–‡ä»¶
            download_files = self.prepare_download_files()
            
            # ç”Ÿæˆæ•°æ®é¢„è§ˆï¼ˆä¼˜å…ˆæ˜¾ç¤ºè®­ç»ƒæ•°æ®ï¼‰
            if hasattr(self, 'train_data') and self.train_data is not None:
                preview_html = f"""
                <div style="margin-bottom: 15px;">
                    <h4 style="color: #2c3e50;">ğŸ¯ è®­ç»ƒé›†æ•°æ®é¢„è§ˆ (å‰8è¡Œ)</h4>
                    <p style="color: #7f8c8d;">å½¢çŠ¶: {self.train_data.shape[0]} è¡Œ Ã— {self.train_data.shape[1]} åˆ—</p>
                </div>
                """ + self.train_data.head(8).to_html(
                    classes="table table-striped table-hover",
                    escape=False,
                    max_cols=10  # é™åˆ¶æ˜¾ç¤ºåˆ—æ•°
                )
            elif self.final_preprocessed_data is not None:
                preview_html = f"""
                <div style="margin-bottom: 15px;">
                    <h4 style="color: #2c3e50;">ğŸ“Š é¢„å¤„ç†æ•°æ®é¢„è§ˆ (å‰8è¡Œ)</h4>
                    <p style="color: #7f8c8d;">å½¢çŠ¶: {self.final_preprocessed_data.shape[0]} è¡Œ Ã— {self.final_preprocessed_data.shape[1]} åˆ—</p>
                </div>
                """ + self.final_preprocessed_data.head(8).to_html(
                    classes="table table-striped table-hover",
                    escape=False,
                    max_cols=10
                )
            else:
                preview_html = "<p style='color: #e74c3c;'>âš ï¸ é¢„å¤„ç†æ•°æ®ä¸å¯ç”¨</p>"
            
            # ä¿å­˜é¢„å¤„ç†ç»“æœ
            self.preprocessing_results = {
                'original_shape': original_shape,
                'final_shape': final_shape,
                'feature_counts': {
                    'time_features': len(time_features) if 'time_features' in locals() else 0,
                    'advanced_time_features': len(advanced_time_features) if 'advanced_time_features' in locals() else 0,
                    'weather_features': len(weather_features) if 'weather_features' in locals() else 0,
                    'comfort_features': len(comfort_features) if 'comfort_features' in locals() else 0,
                    'interaction_features': len(interaction_features) if 'interaction_features' in locals() else 0,
                    'encoded_features': len(encoded_features) if 'encoded_features' in locals() else 0,
                    'selected_features': len(selected_features) if 'selected_features' in locals() else 0
                },
                'selected_features': selected_features if 'selected_features' in locals() else [],
                'top_features': top_features.to_dict() if 'top_features' in locals() else {}
            }
            
            return preprocessing_report, step_by_step_plot, preview_html, download_files
            
        except Exception as e:
            return f"âŒ é¢„å¤„ç†æµæ°´çº¿å¤±è´¥: {str(e)}", None, None, None
    
    def run_complete_pipeline(self):
        """è¿è¡Œå®Œæ•´æ•°æ®ç§‘å­¦æµæ°´çº¿"""
        if self.df is None:
            return "âŒ è¯·å…ˆåŠ è½½æ•°æ®", None, None, None, None, None, None, None
        
        try:
            pipeline_report = "ğŸš€ **å®Œæ•´æ•°æ®ç§‘å­¦æµæ°´çº¿æ‰§è¡Œä¸­...**\n\n"
            
            # 1. æ‰§è¡ŒEDAåˆ†æ
            pipeline_report += "ğŸ“Š **æ­¥éª¤1: æ‰§è¡Œå®Œæ•´EDAåˆ†æ**\n"
            eda_report, eda_plot = self.comprehensive_eda_analysis()
            pipeline_report += "âœ… EDAåˆ†æå®Œæˆ\n\n"
            
            # 2. æ‰§è¡Œæ·±åº¦åˆ†æ
            pipeline_report += "ğŸ” **æ­¥éª¤2: æ‰§è¡Œæ·±åº¦æ•°æ®æ´å¯Ÿ**\n"
            deep_report, time_plot, weather_plot, demand_plot, predictive_plot = self.deep_analysis()
            pipeline_report += "âœ… æ·±åº¦åˆ†æå®Œæˆ\n\n"
            
            # 3. æ‰§è¡Œå®Œæ•´é¢„å¤„ç†
            pipeline_report += "ğŸ”§ **æ­¥éª¤3: æ‰§è¡Œå®Œæ•´é¢„å¤„ç†æµæ°´çº¿**\n"
            preprocess_result = self.complete_preprocessing_pipeline()
            if len(preprocess_result) == 4:
                preprocess_report, preprocess_plot, final_preview, _ = preprocess_result  # å¿½ç•¥ä¸‹è½½æ–‡ä»¶
            else:
                preprocess_report, preprocess_plot, final_preview = preprocess_result
            pipeline_report += "âœ… é¢„å¤„ç†å®Œæˆ\n\n"
            
            # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
            pipeline_report += "ğŸ¯ **æµæ°´çº¿æ‰§è¡Œæ‘˜è¦:**\n"
            pipeline_report += f"- EDAåˆ†æ: {len(self.eda_results)} ä¸ªå…³é”®å‘ç°\n" if hasattr(self, 'eda_results') else "- EDAåˆ†æ: å·²å®Œæˆ\n"
            pipeline_report += f"- æ·±åº¦æ´å¯Ÿ: æ—¶é—´æ¨¡å¼ã€å¤©æ°”å½±å“ã€éœ€æ±‚åˆ†å±‚åˆ†æ\n"
            
            if self.final_preprocessed_data is not None:
                pipeline_report += f"- æ•°æ®é¢„å¤„ç†: {self.final_preprocessed_data.shape[0]} è¡Œ Ã— {self.final_preprocessed_data.shape[1]} åˆ—\n"
                pipeline_report += f"- å»ºæ¨¡å°±ç»ªæ•°æ®: âœ… å¯ç”¨äºæœºå™¨å­¦ä¹ è®­ç»ƒ\n"
                
                # æ˜¾ç¤ºæ•°æ®é›†åˆ†å‰²ä¿¡æ¯
                if hasattr(self, 'train_data'):
                    pipeline_report += f"\nğŸ“Š **æ•°æ®é›†åˆ†å‰²:**\n"
                    pipeline_report += f"- è®­ç»ƒé›†: {self.train_data.shape[0]} è¡Œ Ã— {self.train_data.shape[1]} åˆ—\n"
                    pipeline_report += f"- éªŒè¯é›†: {self.val_data.shape[0]} è¡Œ Ã— {self.val_data.shape[1]} åˆ—\n"
                    pipeline_report += f"- æµ‹è¯•é›†: {self.test_data.shape[0]} è¡Œ Ã— {self.test_data.shape[1]} åˆ—\n"
            else:
                pipeline_report += f"- æ•°æ®é¢„å¤„ç†: âš ï¸ è¯·æ£€æŸ¥é¢„å¤„ç†æ­¥éª¤\n"
            
            pipeline_report += "\nğŸ‰ **å®Œæ•´æ•°æ®ç§‘å­¦æµæ°´çº¿æ‰§è¡Œå®Œæ¯•ï¼**\n"
            pipeline_report += "ğŸ“ æ‰€æœ‰åˆ†æç»“æœå·²ä¿å­˜åœ¨å†…å­˜ä¸­ï¼Œå¯ç”¨äºåç»­å»ºæ¨¡å®éªŒã€‚\n"
            
            # æ·»åŠ å»ºæ¨¡å‡†å¤‡ä¿¡æ¯
            if hasattr(self, 'train_data'):
                pipeline_report += f"\nğŸš€ **å»ºæ¨¡å‡†å¤‡å°±ç»ª:**\n"
                pipeline_report += f"- ç‰¹å¾æ•°é‡: {self.train_data.shape[1] - 1} ä¸ª\n"
                pipeline_report += f"- è®­ç»ƒæ ·æœ¬: {self.train_data.shape[0]} ä¸ª\n"
                pipeline_report += f"- ç‰¹å¾ç±»å‹: æ—¶é—´ç‰¹å¾ã€å¤©æ°”ç‰¹å¾ã€äº¤äº’ç‰¹å¾\n"
                pipeline_report += f"- æ¨èç®—æ³•: éšæœºæ£®æ—ã€XGBoostã€LSTM\n"
            
            # ç”Ÿæˆè¯¦ç»†ç‰¹å¾è¯´æ˜
            feature_explanation = self.generate_feature_explanation()
            pipeline_report += f"\n{feature_explanation}"
            
            # ç”Ÿæˆä¸‹è½½æ–‡ä»¶
            download_files = self.prepare_download_files()
            
            return (pipeline_report, eda_plot, time_plot, weather_plot, 
                   demand_plot, predictive_plot, preprocess_plot, final_preview, download_files)
            
        except Exception as e:
            return f"âŒ å®Œæ•´æµæ°´çº¿æ‰§è¡Œå¤±è´¥: {str(e)}", None, None, None, None, None, None, None, None
    
    def generate_feature_explanation(self):
        """ç”Ÿæˆè¯¦ç»†ç‰¹å¾è¯´æ˜"""
        try:
            explanation = "\n## ğŸ”§ **è¯¦ç»†ç‰¹å¾å·¥ç¨‹è¯´æ˜**\n\n"
            
            if hasattr(self, 'preprocessing_results') and self.preprocessing_results:
                feature_counts = self.preprocessing_results.get('feature_counts', {})
                
                explanation += f"### ğŸ“Š **ç‰¹å¾ç±»å‹ç»Ÿè®¡:**\n"
                total_features = sum(feature_counts.values())
                explanation += f"- **æ€»ç‰¹å¾æ•°**: {total_features} ä¸ª\n\n"
                
                # æ—¶é—´ç‰¹å¾è¯¦è§£
                if feature_counts.get('time_features', 0) > 0:
                    explanation += f"### â° **æ—¶é—´ç‰¹å¾ ({feature_counts['time_features']} ä¸ª)**\n"
                    explanation += f"- **åŸºç¡€æ—¶é—´**: Year, Month, Day, Weekday, DayOfYear, Quarter\n"
                    explanation += f"- **å‘¨æœ«æ ‡è¯†**: IsWeekend (äºŒå…ƒç‰¹å¾)\n"
                    explanation += f"- **å‘¨æœŸæ€§ç¼–ç **: Hour_Sin/Cos, Month_Sin/Cos, DayOfYear_Sin/Cos, Weekday_Sin/Cos\n"
                    explanation += f"- **ä½œç”¨**: æ•æ‰æ—¶é—´çš„å‘¨æœŸæ€§æ¨¡å¼å’Œå­£èŠ‚æ€§è¶‹åŠ¿\n\n"
                
                # é«˜çº§æ—¶é—´ç‰¹å¾è¯¦è§£
                if feature_counts.get('advanced_time_features', 0) > 0:
                    explanation += f"### ğŸ• **é«˜çº§æ—¶é—´ç‰¹å¾ ({feature_counts['advanced_time_features']} ä¸ª)**\n"
                    explanation += f"- **æ—¶æ®µç»†åˆ†**: Hour_Deep_Night, Hour_Morning_Peak, Hour_Evening_Peakç­‰\n"
                    explanation += f"- **å³°å€¼è¯†åˆ«**: Is_Peak_Hour, Is_Low_Hour, Is_Rush_Hour\n"
                    explanation += f"- **é€šå‹¤æ—¶é—´**: åŸºäºé¦–å°”è‡ªè¡Œè½¦ä½¿ç”¨çš„åŒå³°æ¨¡å¼è¯†åˆ«\n"
                    explanation += f"- **ä½œç”¨**: ç²¾ç¡®æ•æ‰åŸå¸‚äº¤é€šå’Œè‡ªè¡Œè½¦ä½¿ç”¨çš„æ—¶é—´è§„å¾‹\n\n"
                
                # å¤©æ°”ç‰¹å¾è¯¦è§£
                if feature_counts.get('weather_features', 0) > 0:
                    explanation += f"### ğŸŒ¤ï¸ **å¤©æ°”ç‰¹å¾ ({feature_counts['weather_features']} ä¸ª)**\n"
                    explanation += f"- **æ¸©åº¦åˆ†æ®µ**: Temp_Severe_Cold, Temp_Cold, Temp_Cool, Temp_Warm, Temp_Hot\n"
                    explanation += f"- **æ¹¿åº¦åˆ†çº§**: Humidity_Low, Medium, High, Very_High (4çº§)\n"
                    explanation += f"- **é£é€Ÿåˆ†ç±»**: Wind_Calm, Light, Moderate, Strong\n"
                    explanation += f"- **é™æ°´ç»†åˆ†**: Has_Rain, Light_Rain, Moderate_Rain, Heavy_Rain\n"
                    explanation += f"- **é™é›ªè¯†åˆ«**: Has_Snow, Light_Snow, Heavy_Snow\n"
                    explanation += f"- **å¤åˆé™æ°´**: Total_Precipitation, Has_Precipitation\n"
                    explanation += f"- **ä½œç”¨**: é‡åŒ–å¤©æ°”æ¡ä»¶å¯¹è‡ªè¡Œè½¦ä½¿ç”¨çš„å¤šç»´åº¦å½±å“\n\n"
                
                # èˆ’é€‚åº¦ç‰¹å¾è¯¦è§£
                if feature_counts.get('comfort_features', 0) > 0:
                    explanation += f"### ğŸ˜Š **èˆ’é€‚åº¦ç‰¹å¾ ({feature_counts['comfort_features']} ä¸ª)**\n"
                    explanation += f"- **èˆ’é€‚åº¦æŒ‡æ•°**: æ¸©åº¦å’Œæ¹¿åº¦çš„å¤åˆè¯„ä¼° (4çº§åˆ†ç±»)\n"
                    explanation += f"- **ä½“æ„Ÿæ¸©åº¦**: Heat_Index (è€ƒè™‘æ¹¿åº¦çš„æ¸©åº¦ä¿®æ­£)\n"
                    explanation += f"- **å®Œç¾å¤©æ°”**: Perfect_Weather (å¤šæ¡ä»¶ç»„åˆåˆ¤æ–­)\n"
                    explanation += f"- **æç«¯å¤©æ°”**: Extreme_Weather (æ¶åŠ£æ¡ä»¶è¯†åˆ«)\n"
                    explanation += f"- **ä½œç”¨**: ä»äººä½“æ„ŸçŸ¥è§’åº¦è¯„ä¼°ç¯å¢ƒèˆ’é€‚åº¦\n\n"
                
                # äº¤äº’ç‰¹å¾è¯¦è§£
                if feature_counts.get('interaction_features', 0) > 0:
                    explanation += f"### ğŸ”— **äº¤äº’ç‰¹å¾ ({feature_counts['interaction_features']} ä¸ª)**\n"
                    explanation += f"- **æ¸©åº¦Ã—æ—¶é—´**: Temp_Hour, Temp_Weekend, Temp_Peak\n"
                    explanation += f"- **å­£èŠ‚Ã—æ—¶é—´**: Season_Peak, Season_Weekend (å„å­£èŠ‚)\n"
                    explanation += f"- **èˆ’é€‚åº¦Ã—æ—¶é—´**: Comfort_Peak, Comfort_Weekend\n"
                    explanation += f"- **æ¸©æ¹¿åº¦ç»„åˆ**: Temp_Humidity\n"
                    explanation += f"- **ä½œç”¨**: æ•æ‰å¤šå˜é‡é—´çš„éçº¿æ€§äº¤äº’æ•ˆåº”\n\n"
                
                # ç¼–ç ç‰¹å¾è¯¦è§£
                if feature_counts.get('encoded_features', 0) > 0:
                    explanation += f"### ğŸ“‘ **ç¼–ç ç‰¹å¾ ({feature_counts['encoded_features']} ä¸ª)**\n"
                    explanation += f"- **å­£èŠ‚ç¼–ç **: Spring, Summer, Autumn, Winter\n"
                    explanation += f"- **èŠ‚å‡æ—¥ç¼–ç **: Holiday, No Holiday\n"
                    explanation += f"- **ç¼–ç æ–¹å¼**: One-hotç¼–ç ï¼Œé¿å…åºæ•°å‡è®¾\n"
                    explanation += f"- **ä½œç”¨**: å°†åˆ†ç±»å˜é‡è½¬æ¢ä¸ºæœºå™¨å­¦ä¹ å¯ç”¨æ ¼å¼\n\n"
                
                # ç‰¹å¾é€‰æ‹©è¯´æ˜
                if feature_counts.get('selected_features', 0) > 0:
                    explanation += f"### ğŸ¯ **ç‰¹å¾é€‰æ‹© ({feature_counts['selected_features']} ä¸ª)**\n"
                    explanation += f"- **é€‰æ‹©æ–¹æ³•**: åŸºäºä¸ç›®æ ‡å˜é‡çš„ç›¸å…³æ€§\n"
                    explanation += f"- **ç›¸å…³æ€§é˜ˆå€¼**: 0.1 (Enhancedæ¨¡å—æ ‡å‡†)\n"
                    explanation += f"- **é€‰æ‹©ç­–ç•¥**: æ— äººå·¥ç‰¹å¾æ•°é‡é™åˆ¶\n"
                    explanation += f"- **ä½œç”¨**: ä¿ç•™æ‰€æœ‰æœ‰æ•ˆç‰¹å¾ï¼Œæé«˜æ¨¡å‹æ€§èƒ½\n\n"
                
                # æ•°æ®åˆ†å‰²è¯´æ˜
                if hasattr(self, 'train_data'):
                    explanation += f"### ğŸ“Š **æ•°æ®åˆ†å‰²ç­–ç•¥**\n"
                    explanation += f"- **åˆ†å‰²æ–¹å¼**: æ—¶é—´åºåˆ—å‹å¥½åˆ†å‰²\n"
                    explanation += f"- **åˆ†å‰²æ¯”ä¾‹**: 70% è®­ç»ƒ / 15% éªŒè¯ / 15% æµ‹è¯•\n"
                    explanation += f"- **æ—¶é—´é¡ºåº**: ä¿æŒæ•°æ®çš„æ—¶é—´è¿ç»­æ€§\n"
                    explanation += f"- **ä½œç”¨**: æ¨¡æ‹ŸçœŸå®é¢„æµ‹åœºæ™¯ï¼Œé¿å…æ•°æ®æ³„éœ²\n\n"
                
                # å»ºæ¨¡å»ºè®®
                explanation += f"### ğŸš€ **å»ºæ¨¡å»ºè®®**\n"
                explanation += f"- **æ¨èç®—æ³•**: éšæœºæ£®æ—ã€XGBoostã€LSTMæ—¶åºæ¨¡å‹\n"
                explanation += f"- **éªŒè¯ç­–ç•¥**: æ—¶é—´åºåˆ—äº¤å‰éªŒè¯\n"
                explanation += f"- **è¯„ä¼°æŒ‡æ ‡**: MAE, RMSE, MAPE\n"
                explanation += f"- **ç‰¹å¾é‡è¦æ€§**: å¯é€šè¿‡æ ‘æ¨¡å‹è·å¾—ç‰¹å¾è´¡çŒ®åº¦\n\n"
                
                explanation += f"### âœ¨ **å¢å¼ºç‰¹æ€§**\n"
                explanation += f"- ğŸ¯ **å®Œå…¨å¤åˆ¶Enhancedæ¨¡å—**: 100%éµå¾ªenhanced_data_preprocessing.pyæ ‡å‡†\n"
                explanation += f"- ğŸ“Š **æ™ºèƒ½ç‰¹å¾å·¥ç¨‹**: åŸºäºé¦–å°”è‡ªè¡Œè½¦ä½¿ç”¨æ¨¡å¼çš„ä¸“ä¸šè®¾è®¡\n"
                explanation += f"- ğŸ”§ **æ— æŸç‰¹å¾é€‰æ‹©**: ä¿ç•™æ‰€æœ‰æœ‰æ•ˆç‰¹å¾ï¼Œä¸äººä¸ºé™åˆ¶æ•°é‡\n"
                explanation += f"- ğŸ“ˆ **å»ºæ¨¡å°±ç»ª**: ç›´æ¥å¯ç”¨äºæœºå™¨å­¦ä¹ è®­ç»ƒçš„å®Œæ•´æ•°æ®é›†\n"
            
            else:
                explanation += "ç‰¹å¾å·¥ç¨‹è¯¦æƒ…æš‚ä¸å¯ç”¨ï¼Œè¯·å…ˆæ‰§è¡Œå®Œæ•´é¢„å¤„ç†æµæ°´çº¿ã€‚\n"
            
            return explanation
            
        except Exception as e:
            return f"\n## âŒ **ç‰¹å¾è¯´æ˜ç”Ÿæˆå¤±è´¥**: {str(e)}\n"
    
    def prepare_download_files(self):
        """å‡†å¤‡ä¸‹è½½æ–‡ä»¶"""
        try:
            import tempfile
            import os
            
            download_files = []
            
            # åˆ›å»ºä¸´æ—¶ç›®å½•
            temp_dir = tempfile.mkdtemp()
            
            # ä¿å­˜è®­ç»ƒæ•°æ®
            if hasattr(self, 'train_data') and self.train_data is not None:
                train_file = os.path.join(temp_dir, 'train_data.csv')
                self.train_data.to_csv(train_file, index=False, encoding='utf-8')
                download_files.append(train_file)
            
            # ä¿å­˜éªŒè¯æ•°æ®
            if hasattr(self, 'val_data') and self.val_data is not None:
                val_file = os.path.join(temp_dir, 'validation_data.csv')
                self.val_data.to_csv(val_file, index=False, encoding='utf-8')
                download_files.append(val_file)
            
            # ä¿å­˜æµ‹è¯•æ•°æ®
            if hasattr(self, 'test_data') and self.test_data is not None:
                test_file = os.path.join(temp_dir, 'test_data.csv')
                self.test_data.to_csv(test_file, index=False, encoding='utf-8')
                download_files.append(test_file)
            
            # ä¿å­˜å®Œæ•´é¢„å¤„ç†æ•°æ®
            if self.final_preprocessed_data is not None:
                full_file = os.path.join(temp_dir, 'preprocessed_full_data.csv')
                self.final_preprocessed_data.to_csv(full_file, index=False, encoding='utf-8')
                download_files.append(full_file)
            
            return download_files if download_files else None
            
        except Exception as e:
            print(f"å‡†å¤‡ä¸‹è½½æ–‡ä»¶å¤±è´¥: {str(e)}")
            return None
    
    def create_step_by_step_visualization(self):
        """åˆ›å»ºåˆ†æ­¥éª¤é¢„å¤„ç†å¯è§†åŒ–"""
        try:
            if not hasattr(self, 'pipeline_steps'):
                return None
            
            # åˆ›å»º9ä¸ªå­å›¾å±•ç¤ºå„ä¸ªæ­¥éª¤
            fig = make_subplots(
                rows=3, cols=3,
                subplot_titles=(
                    'æ­¥éª¤1: éè¿è¥æ—¥å¤„ç†', 'æ­¥éª¤2: åŸºç¡€æ—¶é—´ç‰¹å¾', 'æ­¥éª¤3: é«˜çº§æ—¶é—´ç‰¹å¾',
                    'æ­¥éª¤4: å¤©æ°”ç‰¹å¾å·¥ç¨‹', 'æ­¥éª¤5: èˆ’é€‚åº¦ç‰¹å¾', 'æ­¥éª¤6: äº¤äº’ç‰¹å¾',
                    'æ­¥éª¤7: åˆ†ç±»ç¼–ç ', 'æ­¥éª¤8: ç‰¹å¾é€‰æ‹©', 'æ­¥éª¤9: æ•°æ®åˆ†å‰²'
                ),
                specs=[[{"type": "indicator"}, {"type": "bar"}, {"type": "bar"}],
                       [{"type": "pie"}, {"type": "bar"}, {"type": "scatter"}],
                       [{"type": "bar"}, {"type": "bar"}, {"type": "pie"}]]
            )
            
            # æ­¥éª¤1: éè¿è¥æ—¥å¤„ç†
            if 'step1' in self.pipeline_steps:
                step1 = self.pipeline_steps['step1']
                removed = step1.get('removed_rows', 0)
                remaining = step1.get('remaining_rows', 0)
                
                fig.add_trace(
                    go.Indicator(
                        mode="number+delta",
                        value=remaining,
                        delta={'reference': remaining + removed, 'relative': True},
                        title={"text": f"å‰©ä½™æ•°æ®è¡Œæ•°<br>ç§»é™¤{removed}è¡Œ"},
                        number={'font': {'size': 20}}
                    ),
                    row=1, col=1
                )
            
            # æ­¥éª¤2: åŸºç¡€æ—¶é—´ç‰¹å¾
            if 'step2' in self.pipeline_steps:
                step2 = self.pipeline_steps['step2']
                features = step2.get('new_features', [])
                if features:
                    # åˆ†ç±»æ—¶é—´ç‰¹å¾
                    basic_features = [f for f in features if not any(x in f for x in ['Sin', 'Cos'])]
                    cyclic_features = [f for f in features if any(x in f for x in ['Sin', 'Cos'])]
                    
                    fig.add_trace(
                        go.Bar(
                            x=['åŸºç¡€ç‰¹å¾', 'å‘¨æœŸæ€§ç¼–ç '],
                            y=[len(basic_features), len(cyclic_features)],
                            marker_color=['#3498db', '#e74c3c'],
                            text=[len(basic_features), len(cyclic_features)],
                            textposition='auto'
                        ),
                        row=1, col=2
                    )
            
            # æ­¥éª¤3: é«˜çº§æ—¶é—´ç‰¹å¾
            if 'step3' in self.pipeline_steps:
                step3 = self.pipeline_steps['step3']
                features = step3.get('new_features', [])
                if features:
                    # åˆ†ç±»é«˜çº§æ—¶é—´ç‰¹å¾
                    peak_features = [f for f in features if 'Peak' in f or 'Rush' in f]
                    period_features = [f for f in features if 'Hour_' in f and 'Peak' not in f and 'Rush' not in f]
                    
                    fig.add_trace(
                        go.Bar(
                            x=['æ—¶æ®µç‰¹å¾', 'å³°å€¼ç‰¹å¾'],
                            y=[len(period_features), len(peak_features)],
                            marker_color=['#f39c12', '#2ecc71'],
                            text=[len(period_features), len(peak_features)],
                            textposition='auto'
                        ),
                        row=1, col=3
                    )
            
            # æ­¥éª¤4: å¤©æ°”ç‰¹å¾
            if 'step4' in self.pipeline_steps:
                step4 = self.pipeline_steps['step4']
                features = step4.get('new_features', [])
                if features:
                    # åˆ†ç±»å¤©æ°”ç‰¹å¾
                    temp_features = [f for f in features if 'Temp_' in f]
                    humidity_features = [f for f in features if 'Humidity_' in f]
                    wind_features = [f for f in features if 'Wind_' in f]
                    precip_features = [f for f in features if any(x in f for x in ['Rain', 'Snow', 'Precipitation'])]
                    
                    weather_types = ['æ¸©åº¦', 'æ¹¿åº¦', 'é£é€Ÿ', 'é™æ°´']
                    weather_counts = [len(temp_features), len(humidity_features), len(wind_features), len(precip_features)]
                    
                    fig.add_trace(
                        go.Pie(
                            labels=weather_types,
                            values=weather_counts,
                            marker_colors=['#e74c3c', '#3498db', '#95a5a6', '#9b59b6']
                        ),
                        row=2, col=1
                    )
            
            # æ­¥éª¤5: èˆ’é€‚åº¦ç‰¹å¾
            if 'step5' in self.pipeline_steps:
                step5 = self.pipeline_steps['step5']
                features = step5.get('new_features', [])
                if features:
                    fig.add_trace(
                        go.Bar(
                            x=features,
                            y=[1] * len(features),
                            marker_color='#2ecc71',
                            text=features,
                            textposition='auto'
                        ),
                        row=2, col=2
                    )
            
            # æ­¥éª¤6: äº¤äº’ç‰¹å¾
            if 'step6' in self.pipeline_steps:
                step6 = self.pipeline_steps['step6']
                features = step6.get('new_features', [])
                if features:
                    # æŒ‰äº¤äº’ç±»å‹åˆ†ç±»
                    temp_interactions = [f for f in features if 'Temp_' in f]
                    season_interactions = [f for f in features if 'Season' in f]
                    comfort_interactions = [f for f in features if 'Comfort_' in f]
                    other_interactions = [f for f in features if f not in temp_interactions + season_interactions + comfort_interactions]
                    
                    # åˆ›å»ºæ•£ç‚¹å›¾æ˜¾ç¤ºäº¤äº’ç‰¹å¾æ•°é‡
                    interaction_types = ['æ¸©åº¦äº¤äº’', 'å­£èŠ‚äº¤äº’', 'èˆ’é€‚åº¦äº¤äº’', 'å…¶ä»–äº¤äº’']
                    interaction_counts = [len(temp_interactions), len(season_interactions), len(comfort_interactions), len(other_interactions)]
                    
                    fig.add_trace(
                        go.Scatter(
                            x=interaction_types,
                            y=interaction_counts,
                            mode='markers+lines',
                            marker=dict(size=15, color='#9b59b6'),
                            line=dict(color='#9b59b6', width=3)
                        ),
                        row=2, col=3
                    )
            
            # æ­¥éª¤7: åˆ†ç±»ç¼–ç 
            if 'step7' in self.pipeline_steps:
                step7 = self.pipeline_steps['step7']
                features = step7.get('new_features', [])
                if features:
                    # æŒ‰ç¼–ç ç±»å‹åˆ†ç±»
                    season_encoded = [f for f in features if 'Seasons_' in f]
                    holiday_encoded = [f for f in features if 'Holiday_' in f]
                    
                    fig.add_trace(
                        go.Bar(
                            x=['å­£èŠ‚ç¼–ç ', 'èŠ‚å‡æ—¥ç¼–ç '],
                            y=[len(season_encoded), len(holiday_encoded)],
                            marker_color=['#f39c12', '#e67e22'],
                            text=[len(season_encoded), len(holiday_encoded)],
                            textposition='auto'
                        ),
                        row=3, col=1
                    )
            
            # æ­¥éª¤8: ç‰¹å¾é€‰æ‹©
            if 'step8' in self.pipeline_steps:
                step8 = self.pipeline_steps['step8']
                correlations = step8.get('feature_correlations', {})
                if correlations:
                    # æ˜¾ç¤ºtop10ç‰¹å¾ç›¸å…³æ€§
                    top_features = sorted(correlations.items(), key=lambda x: x[1], reverse=True)[:10]
                    if top_features:
                        features, corr_values = zip(*top_features)
                        
                        fig.add_trace(
                            go.Bar(
                                x=list(corr_values),
                                y=list(features),
                                orientation='h',
                                marker_color='#3498db',
                                text=[f'{corr:.3f}' for corr in corr_values],
                                textposition='auto'
                            ),
                            row=3, col=2
                        )
            
            # æ­¥éª¤9: æ•°æ®åˆ†å‰²
            if 'step9' in self.pipeline_steps:
                step9 = self.pipeline_steps['step9']
                if 'train_data' in step9:
                    train_size = len(step9['train_data'])
                    val_size = len(step9['val_data'])
                    test_size = len(step9['test_data'])
                    
                    fig.add_trace(
                        go.Pie(
                            labels=['è®­ç»ƒé›†(70%)', 'éªŒè¯é›†(15%)', 'æµ‹è¯•é›†(15%)'],
                            values=[train_size, val_size, test_size],
                            marker_colors=['#3498db', '#e74c3c', '#2ecc71']
                        ),
                        row=3, col=3
                    )
            
            fig.update_layout(
                height=1200,
                title_text="ğŸ”§ åˆ†æ­¥éª¤æ•°æ®é¢„å¤„ç†å¯è§†åŒ–æµç¨‹",
                title_x=0.5,
                showlegend=False,
                template="plotly_white"
            )
            
            return fig
            
        except Exception as e:
            print(f"åˆ›å»ºåˆ†æ­¥éª¤å¯è§†åŒ–å¤±è´¥: {str(e)}")
            return None
    
    def create_preprocessing_visualization(self):
        """åˆ›å»ºé¢„å¤„ç†å¯è§†åŒ–"""
        try:
            if self.final_preprocessed_data is None:
                return None
            
            target_col = 'Rented Bike Count'
            
            # åˆ›å»ºé¢„å¤„ç†ç»“æœå›¾è¡¨
            fig = make_subplots(
                rows=2, cols=2,
                subplot_titles=(
                    'ç‰¹å¾é‡è¦æ€§æ’å', 
                    'æ•°æ®å¤„ç†å‰åå¯¹æ¯”', 
                    'ç‰¹å¾ç±»å‹åˆ†å¸ƒ', 
                    'æ•°æ®é›†åˆ†å‰²' if hasattr(self, 'train_data') else 'æ•°æ®è´¨é‡è¯„ä¼°'
                ),
                specs=[[{"type": "bar"}, {"type": "bar"}],
                       [{"type": "pie"}, {"type": "bar" if hasattr(self, 'train_data') else "scatter"}]]
            )
            
            # 1. ç‰¹å¾é‡è¦æ€§
            if target_col in self.final_preprocessed_data.columns:
                feature_cols = [col for col in self.final_preprocessed_data.columns if col != target_col]
                correlations = self.final_preprocessed_data[feature_cols].corrwith(
                    self.final_preprocessed_data[target_col]
                ).abs().sort_values(ascending=False).head(10)
                
                fig.add_trace(
                    go.Bar(
                        x=correlations.values,
                        y=correlations.index,
                        orientation='h',
                        marker_color='#3498db',
                        text=[f'{corr:.3f}' for corr in correlations.values],
                        textposition='auto'
                    ),
                    row=1, col=1
                )
            
            # 2. æ•°æ®å¤„ç†å‰åå¯¹æ¯”
            if hasattr(self, 'df') and self.df is not None:
                comparison_data = {
                    'åŸå§‹æ•°æ®': [self.df.shape[0], self.df.shape[1]],
                    'å¤„ç†åæ•°æ®': [self.final_preprocessed_data.shape[0], self.final_preprocessed_data.shape[1]]
                }
                
                categories = ['æ•°æ®è¡Œæ•°', 'ç‰¹å¾åˆ—æ•°']
                fig.add_trace(
                    go.Bar(
                        name='åŸå§‹æ•°æ®',
                        x=categories,
                        y=comparison_data['åŸå§‹æ•°æ®'],
                        marker_color='#e74c3c'
                    ),
                    row=1, col=2
                )
                fig.add_trace(
                    go.Bar(
                        name='å¤„ç†åæ•°æ®',
                        x=categories,
                        y=comparison_data['å¤„ç†åæ•°æ®'],
                        marker_color='#2ecc71'
                    ),
                    row=1, col=2
                )
            
            # 3. ç‰¹å¾ç±»å‹åˆ†å¸ƒ
            if hasattr(self, 'preprocessing_results') and self.preprocessing_results and 'feature_counts' in self.preprocessing_results:
                feature_counts = self.preprocessing_results['feature_counts']
                
                # è¿‡æ»¤æ‰å€¼ä¸º0çš„ç‰¹å¾ç±»å‹
                filtered_types = []
                filtered_counts = []
                type_names = {
                    'time_features': 'æ—¶é—´ç‰¹å¾',
                    'advanced_time_features': 'é«˜çº§æ—¶é—´ç‰¹å¾',
                    'weather_features': 'å¤©æ°”ç‰¹å¾',
                    'comfort_features': 'èˆ’é€‚åº¦ç‰¹å¾',
                    'interaction_features': 'äº¤äº’ç‰¹å¾',
                    'encoded_features': 'ç¼–ç ç‰¹å¾'
                }
                
                for ftype, count in feature_counts.items():
                    if count > 0 and ftype in type_names:
                        filtered_types.append(type_names[ftype])
                        filtered_counts.append(count)
                
                if filtered_types:
                    fig.add_trace(
                        go.Pie(
                            labels=filtered_types,
                            values=filtered_counts,
                            name="ç‰¹å¾ç±»å‹åˆ†å¸ƒ",
                            marker_colors=['#3498db', '#e74c3c', '#f39c12', '#2ecc71', '#9b59b6', '#34495e'][:len(filtered_types)]
                        ),
                        row=2, col=1
                    )
                else:
                    # å¦‚æœæ²¡æœ‰ç‰¹å¾ç»Ÿè®¡ï¼Œæ˜¾ç¤ºé»˜è®¤åˆ†å¸ƒ
                    fig.add_trace(
                        go.Pie(
                            labels=['åŸºç¡€ç‰¹å¾', 'è¡ç”Ÿç‰¹å¾'],
                            values=[10, 20],
                            name="ç‰¹å¾ç±»å‹åˆ†å¸ƒ",
                            marker_colors=['#3498db', '#2ecc71']
                        ),
                        row=2, col=1
                    )
            else:
                # å¦‚æœæ²¡æœ‰é¢„å¤„ç†ç»“æœï¼Œæ˜¾ç¤ºé»˜è®¤åˆ†å¸ƒ
                fig.add_trace(
                    go.Pie(
                        labels=['åŸå§‹ç‰¹å¾', 'æ–°å¢ç‰¹å¾'],
                        values=[self.df.shape[1] if self.df is not None else 10, 
                               (self.final_preprocessed_data.shape[1] - self.df.shape[1]) if self.final_preprocessed_data is not None and self.df is not None else 15],
                        name="ç‰¹å¾ç±»å‹åˆ†å¸ƒ",
                        marker_colors=['#e74c3c', '#2ecc71']
                    ),
                    row=2, col=1
                )
            
            # 4. æ•°æ®é›†åˆ†å‰²æƒ…å†µï¼ˆå¦‚æœæœ‰åˆ†å‰²ï¼‰
            if hasattr(self, 'train_data'):
                split_labels = ['è®­ç»ƒé›†', 'éªŒè¯é›†', 'æµ‹è¯•é›†']
                split_sizes = [self.train_data.shape[0], self.val_data.shape[0], self.test_data.shape[0]]
                
                fig.add_trace(
                    go.Bar(
                        x=split_labels,
                        y=split_sizes,
                        marker_color=['#3498db', '#e74c3c', '#2ecc71'],
                        text=[f'{size}' for size in split_sizes],
                        textposition='auto',
                        name='æ•°æ®é›†åˆ†å‰²'
                    ),
                    row=2, col=2
                )
            else:
                # æ•°æ®è´¨é‡è¯„ä¼°ï¼ˆå¦‚æœæ²¡æœ‰åˆ†å‰²ï¼‰
                quality_metrics = ['å®Œæ•´æ€§', 'ç‰¹å¾ä¸°å¯Œåº¦', 'ç›¸å…³æ€§å¼ºåº¦', 'å¤„ç†æ•ˆç‡']
                quality_scores = [
                    95,  # å®Œæ•´æ€§
                    min(100, len(feature_cols) * 2) if 'feature_cols' in locals() else 80,  # ç‰¹å¾ä¸°å¯Œåº¦
                    correlations.mean() * 100 if 'correlations' in locals() else 60,  # ç›¸å…³æ€§å¼ºåº¦
                    90   # å¤„ç†æ•ˆç‡
                ]
                
                fig.add_trace(
                    go.Scatter(
                        x=quality_metrics,
                        y=quality_scores,
                        mode='markers+lines',
                        marker=dict(size=15, color='#2ecc71'),
                        line=dict(color='#2ecc71', width=3),
                        name='è´¨é‡è¯„åˆ†'
                    ),
                    row=2, col=2
                )
            
            fig.update_layout(
                height=800,
                title_text="ğŸ”§ æ•°æ®é¢„å¤„ç†ç»“æœä»ªè¡¨æ¿",
                title_x=0.5,
                showlegend=True,
                template="plotly_white"
            )
            
            return fig
            
        except Exception as e:
            print(f"åˆ›å»ºé¢„å¤„ç†å¯è§†åŒ–å¤±è´¥: {str(e)}")
            return None
    
    def create_importance_chart(self, target_column):
        """åˆ›å»ºç‰¹å¾é‡è¦æ€§å›¾è¡¨"""
        if self.processed_data is None or target_column not in self.processed_data.columns:
            return None
        
        try:
            # è®¡ç®—ç›¸å…³æ€§
            numeric_features = self.processed_data.select_dtypes(include=[np.number]).columns
            numeric_features = [col for col in numeric_features if col != target_column]
            
            correlations = []
            feature_names = []
            
            for feature in numeric_features[:15]:  # é™åˆ¶æ˜¾ç¤ºå‰15ä¸ªç‰¹å¾
                try:
                    corr = abs(self.processed_data[feature].corr(self.processed_data[target_column]))
                    if not np.isnan(corr) and corr > 0:
                        correlations.append(corr)
                        feature_names.append(feature)
                except:
                    continue
            
            if not correlations:
                return None
            
            # æ’åº
            sorted_data = sorted(zip(feature_names, correlations), key=lambda x: x[1], reverse=True)
            sorted_features, sorted_correlations = zip(*sorted_data)
            
            # åˆ›å»ºé¢œè‰²æ¸å˜
            colors = px.colors.sequential.Viridis[::-1]
            
            fig = go.Figure()
            fig.add_trace(go.Bar(
                x=sorted_correlations,
                y=sorted_features,
                orientation='h',
                marker=dict(
                    color=sorted_correlations,
                    colorscale='Viridis',
                    colorbar=dict(title="ç›¸å…³æ€§å¼ºåº¦")
                ),
                text=[f'{corr:.3f}' for corr in sorted_correlations],
                textposition='auto'
            ))
            
            fig.update_layout(
                title=f"ğŸ¯ ç‰¹å¾ä¸ '{target_column}' çš„ç›¸å…³æ€§æ’å",
                xaxis_title="ç›¸å…³æ€§ç³»æ•° (ç»å¯¹å€¼)",
                yaxis_title="ç‰¹å¾åç§°",
                height=max(400, len(sorted_features) * 25),
                template="plotly_white",
                title_x=0.5
            )
            
            return fig
            
        except Exception as e:
            print(f"åˆ›å»ºç‰¹å¾é‡è¦æ€§å›¾è¡¨å¤±è´¥: {str(e)}")
            return None
    
    def deep_analysis(self):
        """æ‰§è¡Œæ·±åº¦æ•°æ®åˆ†æ"""
        if self.df is None:
            return "âŒ è¯·å…ˆåŠ è½½æ•°æ®", None, None, None, None
        
        try:
            # ç¡®ä¿æ—¶é—´ç‰¹å¾å­˜åœ¨
            if 'Date' in self.df.columns:
                date_col = 'Date'
                # ç¡®ä¿æ—¥æœŸæ ¼å¼æ­£ç¡®
                if self.df[date_col].dtype == 'object':
                    try:
                        self.df[date_col] = pd.to_datetime(self.df[date_col], format='%d/%m/%Y')
                    except ValueError:
                        try:
                            self.df[date_col] = pd.to_datetime(self.df[date_col], dayfirst=True)
                        except ValueError:
                            self.df[date_col] = pd.to_datetime(self.df[date_col], format='mixed', dayfirst=True)
                
                # åˆ›å»ºå¿…è¦çš„æ—¶é—´ç‰¹å¾
                if 'Weekday' not in self.df.columns:
                    self.df['Weekday'] = self.df[date_col].dt.weekday
                if 'IsWeekend' not in self.df.columns:
                    self.df['IsWeekend'] = (self.df['Weekday'] >= 5).astype(int)
                if 'Month' not in self.df.columns:
                    self.df['Month'] = self.df[date_col].dt.month
                if 'Year' not in self.df.columns:
                    self.df['Year'] = self.df[date_col].dt.year
                if 'DayOfYear' not in self.df.columns:
                    self.df['DayOfYear'] = self.df[date_col].dt.dayofyear
            
            # ç¡®å®šç›®æ ‡åˆ—
            target_col = 'Rented Bike Count'  # é»˜è®¤ç›®æ ‡åˆ—
            if target_col not in self.df.columns:
                numeric_cols = self.df.select_dtypes(include=[np.number]).columns
                target_col = numeric_cols[0] if len(numeric_cols) > 0 else self.df.columns[0]
            
            print(f"æ·±åº¦åˆ†æç›®æ ‡åˆ—: {target_col}")
            print(f"å½“å‰æ•°æ®å½¢çŠ¶: {self.df.shape}")
            print(f"å¯ç”¨åˆ—: {list(self.df.columns)}")
            
            # 1. é«˜çº§æ—¶é—´æ¨¡å¼åˆ†æ
            time_analysis_result, time_plot = self.advanced_time_pattern_analysis(target_col)
            
            # 2. å¤©æ°”å½±å“æ·±åº¦åˆ†æ
            weather_analysis_result, weather_plot = self.weather_impact_deep_dive(target_col)
            
            # 3. éœ€æ±‚æ¨¡å¼åˆ†å‰²åˆ†æ
            segmentation_result, segmentation_plot = self.demand_pattern_segmentation(target_col)
            
            # 4. é¢„æµ‹æ€§æ´å¯Ÿåˆ†æ
            predictive_result, predictive_plot = self.predictive_insights_analysis(target_col)
            
            # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
            comprehensive_report = f"""
            ğŸ” **æ·±åº¦æ•°æ®æ´å¯Ÿåˆ†æå®Œæˆï¼**
            
            ğŸ“Š **æ ¸å¿ƒå‘ç°æ‘˜è¦:**
            {time_analysis_result}
            
            ğŸŒ¤ï¸ **å¤©æ°”å½±å“æ´å¯Ÿ:**
            {weather_analysis_result}
            
            ğŸ“ˆ **éœ€æ±‚æ¨¡å¼ç‰¹å¾:**
            {segmentation_result}
            
            ğŸ¯ **é¢„æµ‹æ€§è¯„ä¼°:**
            {predictive_result}
            
            ğŸ’¡ **æ·±åº¦åˆ†æä»·å€¼:**
            - è¯†åˆ«äº†åŒå³°éœ€æ±‚æ¨¡å¼çš„æ·±å±‚åŸå› 
            - é‡åŒ–äº†å¤©æ°”å› ç´ çš„å…·ä½“å½±å“
            - å‘ç°äº†ä¸åŒéœ€æ±‚å±‚çº§çš„ç‰¹å¾å·®å¼‚
            - è¯„ä¼°äº†æ•°æ®çš„é¢„æµ‹å»ºæ¨¡æ½œåŠ›
            """
            
            return comprehensive_report, time_plot, weather_plot, segmentation_plot, predictive_plot
            
        except Exception as e:
            return f"âŒ æ·±åº¦åˆ†æå¤±è´¥: {str(e)}", None, None, None, None
    
    def advanced_time_pattern_analysis(self, target_col):
        """é«˜çº§æ—¶é—´æ¨¡å¼åˆ†æ"""
        try:
            if 'Hour' not in self.df.columns:
                return "ç¼ºå°‘å°æ—¶æ•°æ®", None
            
            # åŒå³°æ¨¡å¼åˆ†æ
            hourly_avg = self.df.groupby('Hour')[target_col].mean()
            hourly_std = self.df.groupby('Hour')[target_col].std()
            
            # è¯†åˆ«å³°å€¼å’Œè°·å€¼
            peaks = []
            valleys = []
            
            hours = sorted(hourly_avg.index)
            for i in range(1, len(hours)-1):
                prev_hour, curr_hour, next_hour = hours[i-1], hours[i], hours[i+1]
                prev_val = hourly_avg[prev_hour]
                curr_val = hourly_avg[curr_hour]
                next_val = hourly_avg[next_hour]
                
                if curr_val > prev_val and curr_val > next_val:
                    peaks.append((curr_hour, curr_val))
                if curr_val < prev_val and curr_val < next_val:
                    valleys.append((curr_hour, curr_val))
            
            # å·¥ä½œæ—¥vså‘¨æœ«å¯¹æ¯”
            weekday_pattern = None
            weekend_pattern = None
            
            if 'IsWeekend' in self.df.columns:
                weekday_pattern = self.df[self.df['IsWeekend'] == 0].groupby('Hour')[target_col].mean()
                weekend_pattern = self.df[self.df['IsWeekend'] == 1].groupby('Hour')[target_col].mean()
            
            # åˆ›å»ºæ—¶é—´æ¨¡å¼å›¾è¡¨
            fig = make_subplots(
                rows=2, cols=2,
                subplot_titles=('å°æ—¶éœ€æ±‚æ¨¡å¼', 'å·¥ä½œæ—¥vså‘¨æœ«', 'å³°è°·å¯¹æ¯”', 'éœ€æ±‚æ³¢åŠ¨æ€§'),
                specs=[[{"type": "scatter"}, {"type": "scatter"}],
                       [{"type": "bar"}, {"type": "scatter"}]]
            )
            
            # å°æ—¶éœ€æ±‚æ¨¡å¼
            fig.add_trace(
                go.Scatter(
                    x=hourly_avg.index,
                    y=hourly_avg.values,
                    mode='lines+markers',
                    name='å¹³å‡éœ€æ±‚',
                    line=dict(color='#3498db', width=3)
                ),
                row=1, col=1
            )
            
            # æ ‡è®°å³°å€¼å’Œè°·å€¼
            if peaks:
                peak_hours, peak_values = zip(*peaks)
                fig.add_trace(
                    go.Scatter(
                        x=peak_hours,
                        y=peak_values,
                        mode='markers',
                        name='å³°å€¼',
                        marker=dict(color='red', size=10, symbol='triangle-up')
                    ),
                    row=1, col=1
                )
            
            # å·¥ä½œæ—¥vså‘¨æœ«
            fig.add_trace(
                go.Scatter(
                    x=weekday_pattern.index,
                    y=weekday_pattern.values,
                    mode='lines',
                    name='å·¥ä½œæ—¥',
                    line=dict(color='#e74c3c', width=2)
                ),
                row=1, col=2
            )
            
            fig.add_trace(
                go.Scatter(
                    x=weekend_pattern.index,
                    y=weekend_pattern.values,
                    mode='lines',
                    name='å‘¨æœ«',
                    line=dict(color='#2ecc71', width=2)
                ),
                row=1, col=2
            )
            
            # å³°è°·å¯¹æ¯”
            peak_valley_labels = ['æ·±å¤œä½è°·', 'æ—©é«˜å³°', 'æ™šé«˜å³°']
            peak_valley_values = [
                hourly_avg[3:6].mean(),  # æ·±å¤œ
                hourly_avg[8:10].mean(),  # æ—©é«˜å³°
                hourly_avg[17:20].mean()  # æ™šé«˜å³°
            ]
            
            fig.add_trace(
                go.Bar(
                    x=peak_valley_labels,
                    y=peak_valley_values,
                    marker_color=['#3498db', '#e74c3c', '#f39c12']
                ),
                row=2, col=1
            )
            
            # éœ€æ±‚æ³¢åŠ¨æ€§
            fig.add_trace(
                go.Scatter(
                    x=hourly_std.index,
                    y=hourly_std.values,
                    mode='lines+markers',
                    name='æ ‡å‡†å·®',
                    line=dict(color='#9b59b6', width=2)
                ),
                row=2, col=2
            )
            
            fig.update_layout(
                height=800,
                title_text="â° é«˜çº§æ—¶é—´æ¨¡å¼æ·±åº¦åˆ†æ",
                title_x=0.5,
                template="plotly_white"
            )
            
            # åˆ†æç»“æœæ–‡æœ¬
            result_text = f"å‘ç°{len(peaks)}ä¸ªéœ€æ±‚å³°å€¼ï¼Œ{len(valleys)}ä¸ªä½è°·"
            if len(peaks) >= 2:
                result_text += "ï¼Œå‘ˆç°æ˜æ˜¾åŒå³°æ¨¡å¼"
            
            return result_text, fig
            
        except Exception as e:
            return f"æ—¶é—´æ¨¡å¼åˆ†æå¤±è´¥: {str(e)}", None
    
    def weather_impact_deep_dive(self, target_col):
        """å¤©æ°”å½±å“æ·±åº¦åˆ†æ"""
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰å¤©æ°”æ•°æ®
            weather_cols = ['Temperature(Â°C)', 'Humidity(%)', 'Wind speed (m/s)', 'Rainfall(mm)', 'Snowfall (cm)']
            available_weather_cols = [col for col in weather_cols if col in self.df.columns]
            
            if len(available_weather_cols) == 0:
                return "ç¼ºå°‘å¤©æ°”æ•°æ®", None
            
            # å¦‚æœæ²¡æœ‰æ¸©åº¦æ•°æ®ï¼ŒåŸºäºç°æœ‰æ•°æ®è¿›è¡Œåˆ†æ
            if 'Temperature(Â°C)' not in self.df.columns:
                analysis_text = f"åŸºäºå¯ç”¨å¤©æ°”æ•°æ®åˆ†æï¼š{', '.join(available_weather_cols)}\n\n"
                
                # åˆ†ææ¹¿åº¦å½±å“
                if 'Humidity(%)' in self.df.columns:
                    humidity_corr = self.df['Humidity(%)'].corr(self.df[target_col])
                    analysis_text += f"ğŸŒŠ æ¹¿åº¦å½±å“åˆ†æï¼š\n"
                    analysis_text += f"- æ¹¿åº¦ç›¸å…³æ€§: {humidity_corr:.4f}\n"
                    
                    high_humidity = self.df[self.df['Humidity(%)'] > 70][target_col].mean()
                    low_humidity = self.df[self.df['Humidity(%)'] < 40][target_col].mean()
                    analysis_text += f"- é«˜æ¹¿åº¦(>70%)å¹³å‡éœ€æ±‚: {high_humidity:.1f}\n"
                    analysis_text += f"- ä½æ¹¿åº¦(<40%)å¹³å‡éœ€æ±‚: {low_humidity:.1f}\n\n"
                
                # åˆ†æé™é›¨å½±å“
                if 'Rainfall(mm)' in self.df.columns:
                    rain_days = (self.df['Rainfall(mm)'] > 0).sum()
                    rain_avg = self.df[self.df['Rainfall(mm)'] > 0][target_col].mean() if rain_days > 0 else 0
                    no_rain_avg = self.df[self.df['Rainfall(mm)'] == 0][target_col].mean()
                    analysis_text += f"ğŸŒ§ï¸ é™é›¨å½±å“åˆ†æï¼š\n"
                    analysis_text += f"- é™é›¨å¤©æ•°: {rain_days} ({rain_days/len(self.df)*100:.1f}%)\n"
                    analysis_text += f"- é™é›¨æ—¥å¹³å‡éœ€æ±‚: {rain_avg:.1f}\n"
                    analysis_text += f"- æ— é›¨æ—¥å¹³å‡éœ€æ±‚: {no_rain_avg:.1f}\n\n"
                
                # åˆ†æé£é€Ÿå½±å“
                if 'Wind speed (m/s)' in self.df.columns:
                    wind_corr = self.df['Wind speed (m/s)'].corr(self.df[target_col])
                    analysis_text += f"ğŸ’¨ é£é€Ÿå½±å“åˆ†æï¼š\n"
                    analysis_text += f"- é£é€Ÿç›¸å…³æ€§: {wind_corr:.4f}\n"
                    
                    strong_wind = self.df[self.df['Wind speed (m/s)'] > 4][target_col].mean() if (self.df['Wind speed (m/s)'] > 4).any() else 0
                    light_wind = self.df[self.df['Wind speed (m/s)'] <= 2][target_col].mean()
                    analysis_text += f"- å¼ºé£(>4m/s)å¹³å‡éœ€æ±‚: {strong_wind:.1f}\n"
                    analysis_text += f"- å¾®é£(â‰¤2m/s)å¹³å‡éœ€æ±‚: {light_wind:.1f}\n"
                
                # åˆ›å»ºåŸºäºå¯ç”¨æ•°æ®çš„å›¾è¡¨
                weather_plot = self.create_available_weather_plot(available_weather_cols, target_col)
                
                return analysis_text, weather_plot
            
            # æ¸©åº¦èˆ’é€‚åŒºé—´åˆ†æ
            temp_bins = np.arange(-20, 41, 5)
            self.df['TempBin'] = pd.cut(self.df['Temperature(Â°C)'], bins=temp_bins)
            temp_demand = self.df.groupby('TempBin')[target_col].agg(['mean', 'count'])
            temp_demand = temp_demand[temp_demand['count'] >= 10]
            
            # å¤åˆå¤©æ°”æ¡ä»¶
            conditions = [self.df['Temperature(Â°C)'].between(15, 25)]
            
            if 'Humidity(%)' in self.df.columns:
                conditions.append(self.df['Humidity(%)'].between(40, 70))
            
            if 'Rainfall(mm)' in self.df.columns:
                conditions.append(self.df['Rainfall(mm)'] == 0)
            
            if 'Snowfall (cm)' in self.df.columns:
                conditions.append(self.df['Snowfall (cm)'] == 0)
            
            # ç»„åˆæ‰€æœ‰æ¡ä»¶
            ideal_weather_mask = conditions[0]
            for condition in conditions[1:]:
                ideal_weather_mask = ideal_weather_mask & condition
            
            ideal_count = ideal_weather_mask.sum()
            ideal_demand = self.df[ideal_weather_mask][target_col].mean() if ideal_count > 0 else 0
            
            # åˆ›å»ºå¤©æ°”å½±å“å›¾è¡¨
            fig = make_subplots(
                rows=2, cols=2,
                subplot_titles=('æ¸©åº¦vséœ€æ±‚', 'å¤©æ°”ç±»å‹åˆ†å¸ƒ', 'æ¸©æ¹¿åº¦çƒ­åŠ›å›¾', 'æç«¯å¤©æ°”å½±å“'),
                specs=[[{"type": "scatter"}, {"type": "pie"}],
                       [{"type": "heatmap"}, {"type": "bar"}]]
            )
            
            # æ¸©åº¦vséœ€æ±‚æ•£ç‚¹å›¾
            if len(temp_demand) > 0:
                temp_centers = [interval.mid for interval in temp_demand.index]
                fig.add_trace(
                    go.Scatter(
                        x=temp_centers,
                        y=temp_demand['mean'].values,
                        mode='markers+lines',
                        name='æ¸©åº¦éœ€æ±‚å…³ç³»',
                        marker=dict(size=temp_demand['count']/20, color='#e74c3c')
                    ),
                    row=1, col=1
                )
            
            # å¤©æ°”ç±»å‹åˆ†å¸ƒ
            weather_types = ['ç†æƒ³å¤©æ°”', 'ä¸€èˆ¬å¤©æ°”', 'æ¶åŠ£å¤©æ°”']
            weather_counts = [ideal_count, len(self.df) - ideal_count, 0]
            
            fig.add_trace(
                go.Pie(
                    labels=weather_types,
                    values=weather_counts,
                    marker_colors=['#2ecc71', '#f39c12', '#e74c3c']
                ),
                row=1, col=2
            )
            
            # æ¸©æ¹¿åº¦çƒ­åŠ›å›¾ï¼ˆå¦‚æœæœ‰æ¹¿åº¦æ•°æ®ï¼‰
            if 'Humidity(%)' in self.df.columns:
                temp_humidity_pivot = self.df.pivot_table(
                    values=target_col, 
                    index=pd.cut(self.df['Temperature(Â°C)'], bins=10),
                    columns=pd.cut(self.df['Humidity(%)'], bins=10),
                    aggfunc='mean'
                )
                
                if not temp_humidity_pivot.empty:
                    fig.add_trace(
                        go.Heatmap(
                            z=temp_humidity_pivot.values,
                            colorscale='Viridis',
                            name='éœ€æ±‚çƒ­åŠ›å›¾'
                        ),
                        row=2, col=1
                    )
            
            # æç«¯å¤©æ°”å½±å“
            extreme_conditions = ['é«˜æ¸©', 'ä½æ¸©', 'é«˜æ¹¿', 'å¼ºé£']
            extreme_impacts = []
            
            if 'Temperature(Â°C)' in self.df.columns:
                high_temp_impact = self.df[self.df['Temperature(Â°C)'] > 30][target_col].mean() if (self.df['Temperature(Â°C)'] > 30).any() else 0
                low_temp_impact = self.df[self.df['Temperature(Â°C)'] < 0][target_col].mean() if (self.df['Temperature(Â°C)'] < 0).any() else 0
                extreme_impacts.extend([high_temp_impact, low_temp_impact])
            else:
                extreme_impacts.extend([0, 0])
            
            if 'Humidity(%)' in self.df.columns:
                high_humidity_impact = self.df[self.df['Humidity(%)'] > 80][target_col].mean() if (self.df['Humidity(%)'] > 80).any() else 0
                extreme_impacts.append(high_humidity_impact)
            else:
                extreme_impacts.append(0)
            
            if 'Wind speed (m/s)' in self.df.columns:
                strong_wind_impact = self.df[self.df['Wind speed (m/s)'] > 6][target_col].mean() if (self.df['Wind speed (m/s)'] > 6).any() else 0
                extreme_impacts.append(strong_wind_impact)
            else:
                extreme_impacts.append(0)
            
            fig.add_trace(
                go.Bar(
                    x=extreme_conditions,
                    y=extreme_impacts,
                    marker_color=['#e74c3c', '#3498db', '#9b59b6', '#f39c12']
                ),
                row=2, col=2
            )
            
            fig.update_layout(
                height=800,
                title_text="ğŸŒ¤ï¸ å¤©æ°”å½±å“æ·±åº¦åˆ†æ",
                title_x=0.5,
                template="plotly_white"
            )
            
            result_text = f"ç†æƒ³å¤©æ°”å æ¯”{ideal_count/len(self.df)*100:.1f}%ï¼Œå¹³å‡éœ€æ±‚{ideal_demand:.1f}"
            
            return result_text, fig
            
        except Exception as e:
            return f"å¤©æ°”åˆ†æå¤±è´¥: {str(e)}", None
    
    def create_available_weather_plot(self, available_weather_cols, target_col):
        """åŸºäºå¯ç”¨å¤©æ°”æ•°æ®åˆ›å»ºå›¾è¡¨"""
        try:
            fig = make_subplots(
                rows=2, cols=2,
                subplot_titles=('æ¹¿åº¦vséœ€æ±‚', 'é™é›¨å½±å“', 'é£é€Ÿvséœ€æ±‚', 'å¤©æ°”æ¡ä»¶å¯¹æ¯”'),
                specs=[[{"type": "scatter"}, {"type": "box"}],
                       [{"type": "scatter"}, {"type": "bar"}]]
            )
            
            # 1. æ¹¿åº¦vséœ€æ±‚
            if 'Humidity(%)' in available_weather_cols:
                fig.add_trace(
                    go.Scatter(
                        x=self.df['Humidity(%)'],
                        y=self.df[target_col],
                        mode='markers',
                        name='æ¹¿åº¦vséœ€æ±‚',
                        marker=dict(color='#3498db', size=4, opacity=0.6)
                    ),
                    row=1, col=1
                )
            
            # 2. é™é›¨å½±å“
            if 'Rainfall(mm)' in available_weather_cols:
                rain_data = self.df[self.df['Rainfall(mm)'] > 0][target_col]
                no_rain_data = self.df[self.df['Rainfall(mm)'] == 0][target_col]
                
                if len(rain_data) > 0:
                    fig.add_trace(
                        go.Box(y=rain_data, name="é™é›¨æ—¥", marker_color='#e74c3c'),
                        row=1, col=2
                    )
                fig.add_trace(
                    go.Box(y=no_rain_data, name="æ— é›¨æ—¥", marker_color='#2ecc71'),
                    row=1, col=2
                )
            
            # 3. é£é€Ÿvséœ€æ±‚
            if 'Wind speed (m/s)' in available_weather_cols:
                fig.add_trace(
                    go.Scatter(
                        x=self.df['Wind speed (m/s)'],
                        y=self.df[target_col],
                        mode='markers',
                        name='é£é€Ÿvséœ€æ±‚',
                        marker=dict(color='#f39c12', size=4, opacity=0.6)
                    ),
                    row=2, col=1
                )
            
            # 4. å¤©æ°”æ¡ä»¶å¯¹æ¯”
            weather_conditions = []
            weather_demands = []
            
            if 'Humidity(%)' in available_weather_cols:
                high_humidity_demand = self.df[self.df['Humidity(%)'] > 70][target_col].mean()
                weather_conditions.append('é«˜æ¹¿åº¦')
                weather_demands.append(high_humidity_demand)
            
            if 'Wind speed (m/s)' in available_weather_cols:
                strong_wind_demand = self.df[self.df['Wind speed (m/s)'] > 4][target_col].mean() if (self.df['Wind speed (m/s)'] > 4).any() else 0
                weather_conditions.append('å¼ºé£')
                weather_demands.append(strong_wind_demand)
            
            if 'Rainfall(mm)' in available_weather_cols:
                rain_demand = self.df[self.df['Rainfall(mm)'] > 0][target_col].mean() if (self.df['Rainfall(mm)'] > 0).any() else 0
                weather_conditions.append('é™é›¨')
                weather_demands.append(rain_demand)
            
            if weather_conditions:
                fig.add_trace(
                    go.Bar(
                        x=weather_conditions,
                        y=weather_demands,
                        marker_color=['#3498db', '#f39c12', '#e74c3c'][:len(weather_conditions)]
                    ),
                    row=2, col=2
                )
            
            fig.update_layout(
                height=800,
                title_text="ğŸŒ¤ï¸ å¯ç”¨å¤©æ°”æ•°æ®å½±å“åˆ†æ",
                title_x=0.5,
                template="plotly_white"
            )
            
            return fig
            
        except Exception as e:
            print(f"åˆ›å»ºå¤©æ°”å›¾è¡¨å¤±è´¥: {str(e)}")
            return None
    
    def demand_pattern_segmentation(self, target_col):
        """éœ€æ±‚æ¨¡å¼åˆ†å‰²åˆ†æ"""
        try:
            # éœ€æ±‚æ°´å¹³åˆ†å±‚
            quantiles = self.df[target_col].quantile([0.2, 0.4, 0.6, 0.8])
            
            def categorize_demand(demand):
                if demand <= quantiles[0.2]:
                    return 'æä½éœ€æ±‚'
                elif demand <= quantiles[0.4]:
                    return 'ä½éœ€æ±‚'
                elif demand <= quantiles[0.6]:
                    return 'ä¸­ç­‰éœ€æ±‚'
                elif demand <= quantiles[0.8]:
                    return 'é«˜éœ€æ±‚'
                else:
                    return 'æé«˜éœ€æ±‚'
            
            self.df['DemandLevel'] = self.df[target_col].apply(categorize_demand)
            demand_distribution = self.df['DemandLevel'].value_counts()
            
            # åˆ›å»ºéœ€æ±‚åˆ†å‰²å›¾è¡¨
            fig = make_subplots(
                rows=2, cols=2,
                subplot_titles=('éœ€æ±‚åˆ†å±‚åˆ†å¸ƒ', 'å„å±‚çº§æ—¶é—´ç‰¹å¾', 'éœ€æ±‚è¶‹åŠ¿', 'å¼‚å¸¸é«˜éœ€æ±‚äº‹ä»¶'),
                specs=[[{"type": "pie"}, {"type": "bar"}],
                       [{"type": "scatter"}, {"type": "histogram"}]]
            )
            
            # éœ€æ±‚åˆ†å±‚åˆ†å¸ƒ
            fig.add_trace(
                go.Pie(
                    labels=demand_distribution.index,
                    values=demand_distribution.values,
                    marker_colors=['#3498db', '#2ecc71', '#f39c12', '#e74c3c', '#9b59b6']
                ),
                row=1, col=1
            )
            
            # å„å±‚çº§å³°å€¼æ—¶é—´
            level_peak_hours = []
            level_names = []
            for level in demand_distribution.index:
                level_data = self.df[self.df['DemandLevel'] == level]
                if len(level_data) > 0 and 'Hour' in level_data.columns:
                    peak_hour = level_data['Hour'].mode().iloc[0]
                    level_peak_hours.append(peak_hour)
                    level_names.append(level)
            
            if level_peak_hours:
                fig.add_trace(
                    go.Bar(
                        x=level_names,
                        y=level_peak_hours,
                        marker_color=['#3498db', '#2ecc71', '#f39c12', '#e74c3c', '#9b59b6']
                    ),
                    row=1, col=2
                )
            
            # éœ€æ±‚æ—¶é—´è¶‹åŠ¿
            hourly_demand = self.df.groupby('Hour')[target_col].mean()
            fig.add_trace(
                go.Scatter(
                    x=hourly_demand.index,
                    y=hourly_demand.values,
                    mode='lines+markers',
                    name='éœ€æ±‚è¶‹åŠ¿',
                    line=dict(color='#2ecc71', width=3)
                ),
                row=2, col=1
            )
            
            # å¼‚å¸¸é«˜éœ€æ±‚åˆ†å¸ƒ
            extreme_threshold = self.df[target_col].quantile(0.95)
            extreme_demands = self.df[self.df[target_col] >= extreme_threshold][target_col]
            
            if len(extreme_demands) > 0:
                fig.add_trace(
                    go.Histogram(
                        x=extreme_demands,
                        name='æé«˜éœ€æ±‚',
                        marker_color='#e74c3c',
                        opacity=0.7
                    ),
                    row=2, col=2
                )
            
            fig.update_layout(
                height=800,
                title_text="ğŸ“Š éœ€æ±‚æ¨¡å¼åˆ†å‰²åˆ†æ",
                title_x=0.5,
                template="plotly_white"
            )
            
            result_text = f"è¯†åˆ«5ä¸ªéœ€æ±‚å±‚çº§ï¼Œæé«˜éœ€æ±‚é˜ˆå€¼{extreme_threshold:.1f}"
            
            return result_text, fig
            
        except Exception as e:
            return f"éœ€æ±‚åˆ†å‰²åˆ†æå¤±è´¥: {str(e)}", None
    
    def predictive_insights_analysis(self, target_col):
        """é¢„æµ‹æ€§æ´å¯Ÿåˆ†æ"""
        try:
            # ç‰¹å¾é‡è¦æ€§è¯„ä¼°
            numeric_features = self.df.select_dtypes(include=[np.number]).columns.tolist()
            numeric_features = [col for col in numeric_features if col != target_col]
            
            feature_importance = {}
            for feature in numeric_features[:10]:  # é™åˆ¶å‰10ä¸ªç‰¹å¾
                if feature in self.df.columns:
                    correlation = abs(self.df[feature].corr(self.df[target_col]))
                    if not np.isnan(correlation):
                        feature_importance[feature] = correlation
            
            # æ’åºç‰¹å¾é‡è¦æ€§
            sorted_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)
            
            # å¯é¢„æµ‹æ€§åˆ†æï¼ˆè‡ªç›¸å…³ï¼‰
            lag_1h_corr = 0
            lag_24h_corr = 0
            
            try:
                # æŒ‰æ—¶é—´æ’åº
                if 'Date' in self.df.columns and 'Hour' in self.df.columns:
                    sorted_df = self.df.sort_values(['Date', 'Hour'])
                    
                    # è®¡ç®—æ»åç›¸å…³æ€§
                    lag_1h_corr = sorted_df[target_col].corr(sorted_df[target_col].shift(1))
                    lag_24h_corr = sorted_df[target_col].corr(sorted_df[target_col].shift(24))
                    
                    if np.isnan(lag_1h_corr):
                        lag_1h_corr = 0
                    if np.isnan(lag_24h_corr):
                        lag_24h_corr = 0
            except Exception as e:
                print(f"è‡ªç›¸å…³åˆ†æå¤±è´¥: {str(e)}")
                pass
            
            # åˆ›å»ºé¢„æµ‹æ´å¯Ÿå›¾è¡¨
            fig = make_subplots(
                rows=2, cols=2,
                subplot_titles=('ç‰¹å¾é‡è¦æ€§æ’å', 'è‡ªç›¸å…³åˆ†æ', 'å»ºæ¨¡ç­–ç•¥å»ºè®®', 'æ•°æ®è´¨é‡è¯„ä¼°'),
                specs=[[{"type": "bar"}, {"type": "bar"}],
                       [{"type": "scatter"}, {"type": "pie"}]]
            )
            
            # ç‰¹å¾é‡è¦æ€§
            if sorted_features:
                features, importances = zip(*sorted_features[:8])
                fig.add_trace(
                    go.Bar(
                        x=list(importances),
                        y=list(features),
                        orientation='h',
                        marker_color='#3498db',
                        text=[f'{imp:.3f}' for imp in importances],
                        textposition='auto'
                    ),
                    row=1, col=1
                )
            
            # è‡ªç›¸å…³åˆ†æ
            lag_types = ['1å°æ—¶æ»å', '24å°æ—¶æ»å']
            lag_values = [abs(lag_1h_corr), abs(lag_24h_corr)]
            
            fig.add_trace(
                go.Bar(
                    x=lag_types,
                    y=lag_values,
                    marker_color=['#e74c3c', '#f39c12'],
                    text=[f'{val:.3f}' for val in lag_values],
                    textposition='auto'
                ),
                row=1, col=2
            )
            
            # å»ºæ¨¡ç­–ç•¥è¯„åˆ†
            strategies = ['æ—¶åºæ¨¡å‹', 'é›†æˆå­¦ä¹ ', 'æ·±åº¦å­¦ä¹ ', 'å›å½’æ¨¡å‹']
            strategy_scores = [
                0.8 if lag_24h_corr > 0.3 else 0.4,  # æ—¶åºæ¨¡å‹
                0.9,  # é›†æˆå­¦ä¹ 
                0.7 if len(sorted_features) > 10 else 0.5,  # æ·±åº¦å­¦ä¹ 
                0.6  # å›å½’æ¨¡å‹
            ]
            
            fig.add_trace(
                go.Scatter(
                    x=strategies,
                    y=strategy_scores,
                    mode='markers+lines',
                    marker=dict(size=15, color='#2ecc71'),
                    line=dict(color='#2ecc71', width=3)
                ),
                row=2, col=1
            )
            
            # æ•°æ®è´¨é‡è¯„ä¼°
            quality_aspects = ['å®Œæ•´æ€§', 'ä¸€è‡´æ€§', 'æ—¶åºæ€§', 'ç‰¹å¾ä¸°å¯Œåº¦']
            quality_scores = [
                95,  # å®Œæ•´æ€§
                90,  # ä¸€è‡´æ€§  
                85 if lag_24h_corr > 0.2 else 70,  # æ—¶åºæ€§
                min(100, len(sorted_features) * 5)  # ç‰¹å¾ä¸°å¯Œåº¦
            ]
            
            fig.add_trace(
                go.Pie(
                    labels=quality_aspects,
                    values=quality_scores,
                    marker_colors=['#3498db', '#2ecc71', '#f39c12', '#e74c3c']
                ),
                row=2, col=2
            )
            
            fig.update_layout(
                height=800,
                title_text="ğŸ¯ é¢„æµ‹æ€§æ´å¯Ÿåˆ†æ",
                title_x=0.5,
                template="plotly_white"
            )
            
            # å»ºæ¨¡å»ºè®®
            recommendations = []
            if lag_24h_corr > 0.3:
                recommendations.append("å¼ºæ—¶åºç›¸å…³æ€§ï¼Œæ¨èARIMA/LSTM")
            if len(sorted_features) > 5:
                recommendations.append("ç‰¹å¾ä¸°å¯Œï¼Œæ¨èéšæœºæ£®æ—/XGBoost")
            recommendations.append("å»ºè®®ä½¿ç”¨æ—¶é—´åºåˆ—äº¤å‰éªŒè¯")
            
            result_text = f"é¢„æµ‹æ€§è¯„ä¼°å®Œæˆï¼Œ{len(recommendations)}æ¡å»ºæ¨¡å»ºè®®"
            
            return result_text, fig
            
        except Exception as e:
            return f"é¢„æµ‹æ´å¯Ÿåˆ†æå¤±è´¥: {str(e)}", None

# ç®€åŒ–çš„é…ç½®ç±»
class config:
    class DATA_CONFIG:
        date_column = 'Date'
        target_column = 'Rented Bike Count'

# åˆ›å»ºå…¨å±€æ•°æ®å¤„ç†å™¨
processor = DataProcessor()

# è‡ªå®šä¹‰CSSæ ·å¼
custom_css = """
<style>
    /* å…¨å±€å®¹å™¨æ ·å¼ */
    .gradio-container {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 50%, #f093fb 100%) !important;
        font-family: 'Segoe UI', 'Roboto', 'Arial', sans-serif !important;
        min-height: 100vh;
        position: relative;
    }
    
    /* æ·»åŠ åŠ¨æ€èƒŒæ™¯æ•ˆæœ */
    .gradio-container::before {
        content: '';
        position: fixed;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        background: 
            radial-gradient(circle at 20% 80%, rgba(120, 119, 198, 0.3) 0%, transparent 50%),
            radial-gradient(circle at 80% 20%, rgba(255, 119, 198, 0.3) 0%, transparent 50%),
            radial-gradient(circle at 40% 40%, rgba(120, 219, 255, 0.3) 0%, transparent 50%);
        z-index: -1;
        animation: backgroundMove 10s ease-in-out infinite;
    }
    
    @keyframes backgroundMove {
        0%, 100% { opacity: 0.3; }
        50% { opacity: 0.6; }
    }
    
    /* ä¸»æ ‡é¢˜æ ·å¼ */
    .main-title {
        text-align: center;
        color: #2c3e50;
        font-size: 2.8em;
        font-weight: bold;
        margin: 30px 0;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
        background: linear-gradient(45deg, #3498db, #e74c3c, #f39c12);
        background-size: 200% 200%;
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        animation: gradient 3s ease infinite, glow 2s ease-in-out infinite alternate;
    }
    
    @keyframes gradient {
        0% { background-position: 0% 50%; }
        50% { background-position: 100% 50%; }
        100% { background-position: 0% 50%; }
    }
    
    @keyframes glow {
        from { filter: brightness(1) drop-shadow(0 0 5px rgba(52, 152, 219, 0.3)); }
        to { filter: brightness(1.2) drop-shadow(0 0 15px rgba(52, 152, 219, 0.6)); }
    }
    
    /* ä¿¡æ¯å¡ç‰‡æ ·å¼ */
    .info-card {
        background: rgba(255, 255, 255, 0.95);
        border-radius: 20px;
        padding: 25px;
        margin: 15px 0;
        box-shadow: 0 15px 35px rgba(31, 38, 135, 0.2);
        backdrop-filter: blur(10px);
        border: 1px solid rgba(255, 255, 255, 0.2);
        animation: slideInUp 0.8s ease-out;
        transition: transform 0.3s ease, box-shadow 0.3s ease;
    }
    
    .info-card:hover {
        transform: translateY(-5px);
        box-shadow: 0 20px 40px rgba(31, 38, 135, 0.3);
    }
    
    @keyframes slideInUp {
        from {
            transform: translateY(30px);
            opacity: 0;
        }
        to {
            transform: translateY(0);
            opacity: 1;
        }
    }
    
    /* æŒ‰é’®æ ·å¼ */
    .gr-button {
        background: linear-gradient(45deg, #3498db, #2ecc71, #9b59b6) !important;
        background-size: 200% 200% !important;
        border: none !important;
        border-radius: 25px !important;
        color: white !important;
        font-weight: bold !important;
        padding: 12px 24px !important;
        transition: all 0.3s ease !important;
        box-shadow: 0 4px 15px rgba(52, 152, 219, 0.4) !important;
        text-transform: uppercase !important;
        letter-spacing: 1px !important;
        position: relative;
        overflow: hidden;
        animation: buttonGradient 3s ease infinite;
    }
    
    .gr-button::before {
        content: '';
        position: absolute;
        top: 0;
        left: -100%;
        width: 100%;
        height: 100%;
        background: linear-gradient(90deg, transparent, rgba(255, 255, 255, 0.2), transparent);
        transition: left 0.5s;
    }
    
    .gr-button:hover::before {
        left: 100%;
    }
    
    .gr-button:hover {
        transform: translateY(-3px) scale(1.05) !important;
        box-shadow: 0 8px 25px rgba(52, 152, 219, 0.6) !important;
        background: linear-gradient(45deg, #2980b9, #27ae60, #8e44ad) !important;
    }
    
    .gr-button:active {
        transform: translateY(-1px) scale(1.02) !important;
    }
    
    @keyframes buttonGradient {
        0% { background-position: 0% 50%; }
        50% { background-position: 100% 50%; }
        100% { background-position: 0% 50%; }
    }
    
    /* æ ‡ç­¾é¡µæ ·å¼ */
    .gr-tabs .gr-tab {
        background: rgba(255, 255, 255, 0.1) !important;
        border-radius: 15px 15px 0 0 !important;
        color: white !important;
        font-weight: bold !important;
        transition: all 0.3s ease !important;
    }
    
    .gr-tabs .gr-tab:hover {
        background: rgba(255, 255, 255, 0.2) !important;
        transform: translateY(-2px) !important;
    }
    
    .gr-tabs .gr-tab.selected {
        background: rgba(255, 255, 255, 0.9) !important;
        color: #2c3e50 !important;
    }
    
    /* ä¸‹æ‹‰æ¡†æ ·å¼ */
    .gr-dropdown {
        border-radius: 15px !important;
        border: 2px solid rgba(255, 255, 255, 0.3) !important;
        background: rgba(255, 255, 255, 0.9) !important;
        transition: all 0.3s ease !important;
    }
    
    .gr-dropdown:focus {
        border-color: #3498db !important;
        box-shadow: 0 0 15px rgba(52, 152, 219, 0.3) !important;
    }
    
    /* æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ */
    .gr-file {
        border: 3px dashed rgba(255, 255, 255, 0.3) !important;
        border-radius: 20px !important;
        background: rgba(255, 255, 255, 0.1) !important;
        transition: all 0.3s ease !important;
    }
    
    .gr-file:hover {
        border-color: #3498db !important;
        background: rgba(52, 152, 219, 0.1) !important;
        transform: scale(1.02) !important;
    }
    
    /* è¡¨æ ¼æ ·å¼ */
    .table-striped {
        background: rgba(255, 255, 255, 0.95) !important;
        border-radius: 15px !important;
        overflow: hidden !important;
        box-shadow: 0 8px 25px rgba(0, 0, 0, 0.1) !important;
    }
    
    .table-striped th {
        background: linear-gradient(45deg, #3498db, #2ecc71) !important;
        color: white !important;
        font-weight: bold !important;
        text-align: center !important;
    }
    
    .table-striped tr:hover {
        background: rgba(52, 152, 219, 0.1) !important;
        transform: scale(1.01) !important;
        transition: all 0.2s ease !important;
    }
    
    /* å›¾è¡¨å®¹å™¨ */
    .plot-container {
        background: rgba(255, 255, 255, 0.95);
        border-radius: 20px;
        padding: 20px;
        margin: 15px 0;
        box-shadow: 0 10px 30px rgba(31, 38, 135, 0.2);
        backdrop-filter: blur(5px);
        border: 1px solid rgba(255, 255, 255, 0.2);
        animation: fadeIn 1s ease-out;
    }
    
    @keyframes fadeIn {
        from { opacity: 0; transform: scale(0.95); }
        to { opacity: 1; transform: scale(1); }
    }
    
    /* è¿›åº¦æ¡æ ·å¼ */
    .progress-bar {
        background: linear-gradient(90deg, #3498db, #e74c3c, #f39c12, #2ecc71);
        background-size: 400% 400%;
        animation: gradient 2s ease infinite;
        border-radius: 10px;
        height: 6px;
        margin: 10px 0;
    }
    
    /* å“åº”å¼è®¾è®¡ */
    @media (max-width: 768px) {
        .main-title {
            font-size: 2em;
        }
        
        .info-card {
            padding: 15px;
            margin: 10px 0;
        }
        
        .gr-button {
            padding: 10px 20px !important;
            font-size: 14px !important;
        }
    }
    
    /* åŠ¨ç”»å»¶è¿Ÿ */
    .info-card:nth-child(1) { animation-delay: 0.1s; }
    .info-card:nth-child(2) { animation-delay: 0.2s; }
    .info-card:nth-child(3) { animation-delay: 0.3s; }
    .info-card:nth-child(4) { animation-delay: 0.4s; }
</style>
"""

def create_interface():
    """åˆ›å»ºGradioç•Œé¢"""
    
    with gr.Blocks(
        css=custom_css, 
        title="ğŸš´â€â™‚ï¸ é¦–å°”è‡ªè¡Œè½¦éœ€æ±‚é¢„æµ‹æ•°æ®å¤„ç†å¹³å°",
        theme=gr.themes.Soft()
    ) as demo:
        
        # æ ‡é¢˜å’Œä»‹ç»
        gr.HTML("""
        <div class="main-title">
            ğŸš´â€â™‚ï¸ é¦–å°”è‡ªè¡Œè½¦éœ€æ±‚é¢„æµ‹ - å®Œæ•´æ•°æ®ç§‘å­¦å¹³å°
        </div>
        <div class="info-card">
            <h3 style="color: #2c3e50; margin-bottom: 15px;">ğŸ¯ å®Œæ•´æ•°æ®ç§‘å­¦æµæ°´çº¿</h3>
            <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 12px;">
                <div style="padding: 12px; background: linear-gradient(45deg, #3498db, rgba(52, 152, 219, 0.1)); border-radius: 10px;">
                    <strong>ğŸ“‚ æ™ºèƒ½æ•°æ®åŠ è½½</strong><br>
                    <small>å¤šç¼–ç æ”¯æŒï¼Œè´¨é‡è¯„ä¼°ï¼Œæ¦‚è§ˆä»ªè¡¨æ¿</small>
                </div>
                <div style="padding: 12px; background: linear-gradient(45deg, #e74c3c, rgba(231, 76, 60, 0.1)); border-radius: 10px;">
                    <strong>ğŸ¯ ç›®æ ‡å˜é‡åˆ†æ</strong><br>
                    <small>ç»Ÿè®¡ç‰¹å¾ï¼Œåˆ†å¸ƒæ£€éªŒï¼Œå¼‚å¸¸å€¼æ£€æµ‹</small>
                </div>
                <div style="padding: 12px; background: linear-gradient(45deg, #2ecc71, rgba(46, 204, 113, 0.1)); border-radius: 10px;">
                    <strong>ğŸ” æ·±åº¦æ•°æ®æ´å¯Ÿ</strong><br>
                    <small>æ—¶é—´æ¨¡å¼ï¼Œå¤©æ°”å½±å“ï¼Œéœ€æ±‚åˆ†å±‚</small>
                </div>
                <div style="padding: 12px; background: linear-gradient(45deg, #f39c12, rgba(243, 156, 18, 0.1)); border-radius: 10px;">
                    <strong>ğŸ”§ ç‰¹å¾å·¥ç¨‹</strong><br>
                    <small>æ—¶é—´ç‰¹å¾ï¼Œäº¤äº’ç‰¹å¾ï¼Œèˆ’é€‚åº¦æŒ‡æ•°</small>
                </div>
                <div style="padding: 12px; background: linear-gradient(45deg, #9b59b6, rgba(155, 89, 182, 0.1)); border-radius: 10px;">
                    <strong>ğŸ“Š å®Œæ•´EDA</strong><br>
                    <small>æ¢ç´¢æ€§åˆ†æï¼Œç›¸å…³æ€§ï¼Œæ¨¡å¼è¯†åˆ«</small>
                </div>
                <div style="padding: 12px; background: linear-gradient(45deg, #1abc9c, rgba(26, 188, 156, 0.1)); border-radius: 10px;">
                    <strong>âš™ï¸ å®Œæ•´é¢„å¤„ç†</strong><br>
                    <small>æ•°æ®æ¸…æ´—ï¼Œç‰¹å¾é€‰æ‹©ï¼Œæ ‡å‡†åŒ–</small>
                </div>
            </div>
            <div style="margin-top: 15px; padding: 15px; background: rgba(52, 73, 94, 0.1); border-radius: 10px; text-align: center;">
                <h4 style="margin: 0; color: #34495e;">ğŸš€ é›†æˆEnhancedæ¨¡å—å®Œæ•´åŠŸèƒ½</h4>
                <p style="margin: 5px 0; color: #7f8c8d;">æ¢ç´¢æ€§åˆ†æ â†’ æ·±åº¦æ´å¯Ÿ â†’ æ™ºèƒ½é¢„å¤„ç† â†’ å»ºæ¨¡å°±ç»ªæ•°æ®</p>
                <div style="margin-top: 10px;">
                    <span style="color: #27ae60; font-weight: bold;">âœ… enhanced_data_exploration</span> | 
                    <span style="color: #e74c3c; font-weight: bold;">âœ… enhanced_data_analysis</span> | 
                    <span style="color: #f39c12; font-weight: bold;">âœ… enhanced_data_preprocessing</span>
                </div>
            </div>
        </div>
        """)
        
        # ä¸»ç•Œé¢æ ‡ç­¾é¡µ
        with gr.Tabs():
            
            # æ•°æ®åŠ è½½æ ‡ç­¾é¡µ
            with gr.TabItem("ğŸ“‚ æ•°æ®åŠ è½½", elem_id="data_loading"):
                gr.HTML("<h2 style='text-align: center; color: #2c3e50; margin: 20px 0;'>ğŸ“‚ æ™ºèƒ½æ•°æ®åŠ è½½ç³»ç»Ÿ</h2>")
                
                with gr.Row():
                    with gr.Column(scale=1):
                        file_input = gr.File(
                            label="ğŸ”½ é€‰æ‹©CSVæ•°æ®æ–‡ä»¶",
                            file_types=[".csv"],
                            type="filepath",
                            elem_id="file-upload"
                        )
                        load_btn = gr.Button(
                            "ğŸš€ å¼€å§‹åŠ è½½æ•°æ®", 
                            variant="primary",
                            size="lg"
                        )
                        
                        gr.HTML("""
                        <div style="margin-top: 15px; padding: 15px; background: rgba(52, 152, 219, 0.1); border-radius: 10px; animation: pulse 2s infinite;">
                            <h4>ğŸ’¡ ä½¿ç”¨æç¤º</h4>
                            <ul>
                                <li>âœ… æ”¯æŒUTF-8ã€GBKç­‰å¤šç§ç¼–ç çš„CSVæ–‡ä»¶</li>
                                <li>ğŸ“ å»ºè®®æ–‡ä»¶å¤§å°ä¸è¶…è¿‡100MB</li>
                                <li>ğŸ“Š ç¡®ä¿æ•°æ®åŒ…å«æ•°å€¼å’Œåˆ†ç±»ç‰¹å¾</li>
                                <li>ğŸ“ ç¬¬ä¸€è¡Œåº”ä¸ºåˆ—å</li>
                                <li>ğŸš€ æ”¯æŒè‡ªåŠ¨ç¼–ç æ£€æµ‹å’Œé”™è¯¯å¤„ç†</li>
                            </ul>
                            <div style="margin-top: 10px; padding: 8px; background: rgba(46, 204, 113, 0.2); border-radius: 5px;">
                                <strong>ğŸ¯ å»ºè®®æ•°æ®æ ¼å¼ï¼š</strong> åŒ…å«æ—¶é—´ã€å¤©æ°”ã€ç›®æ ‡å˜é‡ç­‰å­—æ®µ
                            </div>
                        </div>
                        
                        <style>
                        @keyframes pulse {
                            0% { box-shadow: 0 0 0 0 rgba(52, 152, 219, 0.4); }
                            70% { box-shadow: 0 0 0 10px rgba(52, 152, 219, 0); }
                            100% { box-shadow: 0 0 0 0 rgba(52, 152, 219, 0); }
                        }
                        </style>
                        """)
                    
                    with gr.Column(scale=2):
                        load_status = gr.Markdown(
                            "ğŸ’¡ **ç­‰å¾…ä¸Šä¼ **\n\nè¯·é€‰æ‹©CSVæ ¼å¼çš„æ•°æ®æ–‡ä»¶å¼€å§‹æ™ºèƒ½åˆ†æã€‚ç³»ç»Ÿå°†è‡ªåŠ¨æ£€æµ‹æ•°æ®è´¨é‡ã€ç»“æ„å’Œç‰¹å¾ç±»å‹ã€‚"
                        )
                
                with gr.Row():
                    with gr.Column():
                        data_preview = gr.HTML(label="ğŸ“Š æ•°æ®é¢„è§ˆè¡¨æ ¼")
                
                with gr.Row():
                    with gr.Column():
                        overview_plot = gr.Plot(label="ğŸ“ˆ æ•°æ®æ¦‚è§ˆä»ªè¡¨æ¿")
            
            # ç›®æ ‡åˆ†ææ ‡ç­¾é¡µ
            with gr.TabItem("ğŸ¯ ç›®æ ‡åˆ†æ", elem_id="target_analysis"):
                gr.HTML("<h2 style='text-align: center; color: #2c3e50; margin: 20px 0;'>ğŸ¯ ç›®æ ‡å˜é‡æ·±åº¦åˆ†æ</h2>")
                
                with gr.Row():
                    with gr.Column(scale=1):
                        target_column = gr.Dropdown(
                            label="ğŸ¯ é€‰æ‹©ç›®æ ‡å˜é‡",
                            choices=[],
                            interactive=True,
                            info="é€‰æ‹©æ‚¨è¦é¢„æµ‹çš„ç›®æ ‡å˜é‡"
                        )
                        analyze_btn = gr.Button(
                            "ğŸ” å¼€å§‹æ·±åº¦åˆ†æ", 
                            variant="primary",
                            size="lg"
                        )
                        
                        gr.HTML("""
                        <div style="margin-top: 15px; padding: 15px; background: rgba(231, 76, 60, 0.1); border-radius: 10px; border-left: 4px solid #e74c3c;">
                            <h4>ğŸ“‹ æ·±åº¦åˆ†æå†…å®¹</h4>
                            <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(180px, 1fr)); gap: 8px; margin: 10px 0;">
                                <div style="padding: 8px; background: rgba(231, 76, 60, 0.1); border-radius: 5px;">
                                    <strong>ğŸ“ˆ ç»Ÿè®¡åˆ†æ</strong><br>
                                    <small>å‡å€¼ã€æ–¹å·®ã€ååº¦ã€å³°åº¦</small>
                                </div>
                                <div style="padding: 8px; background: rgba(231, 76, 60, 0.1); border-radius: 5px;">
                                    <strong>ğŸ“Š åˆ†å¸ƒæ£€éªŒ</strong><br>
                                    <small>æ­£æ€æ€§ã€Q-Qå›¾åˆ†æ</small>
                                </div>
                                <div style="padding: 8px; background: rgba(231, 76, 60, 0.1); border-radius: 5px;">
                                    <strong>ğŸ” å¼‚å¸¸æ£€æµ‹</strong><br>
                                    <small>IQRæ–¹æ³•ã€æå€¼åˆ†æ</small>
                                </div>
                                <div style="padding: 8px; background: rgba(231, 76, 60, 0.1); border-radius: 5px;">
                                    <strong>â° æ—¶åºç‰¹å¾</strong><br>
                                    <small>è¶‹åŠ¿ã€å­£èŠ‚æ€§æ¨¡å¼</small>
                                </div>
                            </div>
                            <div style="margin-top: 10px; padding: 8px; background: rgba(46, 204, 113, 0.2); border-radius: 5px;">
                                <strong>ğŸ¯ æ™ºèƒ½æ´å¯Ÿï¼š</strong> è‡ªåŠ¨è¯†åˆ«æ•°æ®ç‰¹å¾å’Œæ½œåœ¨é—®é¢˜
                            </div>
                        </div>
                        """)
                    
                    with gr.Column(scale=2):
                        target_analysis = gr.Markdown(
                            "ğŸ’¡ **åˆ†æå‡†å¤‡**\n\nè¯·ä»ä¸‹æ‹‰èœå•ä¸­é€‰æ‹©ç›®æ ‡å˜é‡ï¼Œç„¶åç‚¹å‡»åˆ†ææŒ‰é’®å¼€å§‹æ·±åº¦ç»Ÿè®¡åˆ†æã€‚"
                        )
                
                with gr.Row():
                    with gr.Column():
                        target_plot = gr.Plot(label="ğŸ“Š ç›®æ ‡å˜é‡ç»¼åˆåˆ†æå›¾è¡¨")
            
            # æ·±åº¦æ•°æ®åˆ†ææ ‡ç­¾é¡µ
            with gr.TabItem("ğŸ” æ·±åº¦åˆ†æ", elem_id="deep_analysis"):
                gr.HTML("<h2 style='text-align: center; color: #2c3e50; margin: 20px 0;'>ğŸ” æ·±åº¦æ•°æ®æ´å¯Ÿåˆ†æ</h2>")
                
                with gr.Row():
                    with gr.Column(scale=1):
                        deep_analysis_btn = gr.Button(
                            "ğŸš€ å¼€å§‹æ·±åº¦åˆ†æ", 
                            variant="primary",
                            size="lg"
                        )
                        
                        gr.HTML("""
                        <div style="margin-top: 15px; padding: 15px; background: rgba(46, 204, 113, 0.1); border-radius: 10px;">
                            <h4>ğŸ”¬ æ·±åº¦åˆ†æå†…å®¹</h4>
                            <ul>
                                <li>ğŸ“Š é«˜çº§æ—¶é—´æ¨¡å¼æŒ–æ˜</li>
                                <li>ğŸŒ¤ï¸ å¤©æ°”å½±å“æ·±åº¦è§£æ</li>
                                <li>ğŸ“ˆ éœ€æ±‚æ¨¡å¼åˆ†å‰²åˆ†æ</li>
                                <li>ğŸ¯ é¢„æµ‹æ€§æ´å¯Ÿè¯„ä¼°</li>
                                <li>ğŸ“‹ å»ºæ¨¡ç­–ç•¥å»ºè®®</li>
                            </ul>
                        </div>
                        """)
                    
                    with gr.Column(scale=2):
                        deep_analysis_report = gr.Markdown(
                            "ğŸ’¡ **æ·±åº¦åˆ†æå‡†å¤‡**\n\nç‚¹å‡»å¼€å§‹æ·±åº¦åˆ†ææŒ‰é’®ï¼Œç³»ç»Ÿå°†å¯¹æ•°æ®è¿›è¡Œå…¨æ–¹ä½æ·±åº¦æ´å¯Ÿï¼Œè¯†åˆ«éšè—æ¨¡å¼å’Œå…³é”®ç‰¹å¾ã€‚"
                        )
                
                with gr.Row():
                    with gr.Column():
                        time_pattern_plot = gr.Plot(label="â° é«˜çº§æ—¶é—´æ¨¡å¼åˆ†æ")
                    with gr.Column():
                        weather_impact_plot = gr.Plot(label="ğŸŒ¤ï¸ å¤©æ°”å½±å“æ·±åº¦åˆ†æ")
                
                with gr.Row():
                    with gr.Column():
                        demand_segmentation_plot = gr.Plot(label="ğŸ“Š éœ€æ±‚æ¨¡å¼åˆ†å‰²")
                    with gr.Column():
                        predictive_insights_plot = gr.Plot(label="ğŸ¯ é¢„æµ‹æ€§æ´å¯Ÿ")
            
            # ç‰¹å¾å·¥ç¨‹æ ‡ç­¾é¡µ
            with gr.TabItem("ğŸ”§ ç‰¹å¾å·¥ç¨‹", elem_id="feature_engineering"):
                gr.HTML("<h2 style='text-align: center; color: #2c3e50; margin: 20px 0;'>ğŸ”§ æ™ºèƒ½ç‰¹å¾å·¥ç¨‹ç³»ç»Ÿ</h2>")
                
                with gr.Row():
                    with gr.Column():
                        date_column = gr.Dropdown(
                            label="ğŸ“… é€‰æ‹©æ—¥æœŸæ—¶é—´åˆ—",
                            choices=[],
                            interactive=True,
                            info="å¦‚æœæ•°æ®åŒ…å«æ—¶é—´ä¿¡æ¯ï¼Œè¯·é€‰æ‹©ç›¸åº”åˆ—"
                        )
                        target_for_fe = gr.Dropdown(
                            label="ğŸ¯ é€‰æ‹©ç›®æ ‡å˜é‡",
                            choices=[],
                            interactive=True,
                            info="é€‰æ‹©ç›®æ ‡å˜é‡ä»¥è®¡ç®—ç‰¹å¾é‡è¦æ€§"
                        )
                        feature_btn = gr.Button(
                            "âš¡ æ‰§è¡Œç‰¹å¾å·¥ç¨‹", 
                            variant="primary",
                            size="lg"
                        )
                        
                        gr.HTML("""
                        <div style="margin-top: 15px; padding: 15px; background: rgba(243, 156, 18, 0.1); border-radius: 10px;">
                            <h4>ğŸ› ï¸ å·¥ç¨‹å†…å®¹</h4>
                            <ul>
                                <li>â° æ—¶é—´ç‰¹å¾æå–</li>
                                <li>ğŸ”„ å‘¨æœŸæ€§ç¼–ç </li>
                                <li>ğŸ“ æ•°å€¼å˜æ¢</li>
                                <li>ğŸ”— äº¤äº’ç‰¹å¾</li>
                                <li>ğŸ“Š é‡è¦æ€§åˆ†æ</li>
                            </ul>
                        </div>
                        """)
                
                with gr.Row():
                    with gr.Column():
                        fe_status = gr.Markdown(
                            "ğŸ’¡ **ç‰¹å¾å·¥ç¨‹å‡†å¤‡**\n\né…ç½®æ—¥æœŸåˆ—å’Œç›®æ ‡å˜é‡ï¼Œç„¶åæ‰§è¡Œæ™ºèƒ½ç‰¹å¾å·¥ç¨‹ã€‚ç³»ç»Ÿå°†è‡ªåŠ¨åˆ›å»ºå¤šç§ç±»å‹çš„è¡ç”Ÿç‰¹å¾ã€‚"
                        )
                
                with gr.Row():
                    with gr.Column():
                        importance_plot = gr.Plot(label="ğŸ“Š ç‰¹å¾é‡è¦æ€§æ’å")
                    with gr.Column():
                        processed_preview = gr.HTML(label="ğŸ”§ å¤„ç†åæ•°æ®é¢„è§ˆ")
            
            # å®Œæ•´EDAåˆ†ææ ‡ç­¾é¡µ
            with gr.TabItem("ğŸ“Š å®Œæ•´EDA", elem_id="comprehensive_eda"):
                gr.HTML("<h2 style='text-align: center; color: #2c3e50; margin: 20px 0;'>ğŸ“Š å®Œæ•´æ¢ç´¢æ€§æ•°æ®åˆ†æ</h2>")
                
                with gr.Row():
                    with gr.Column(scale=1):
                        eda_analysis_btn = gr.Button(
                            "ğŸ” æ‰§è¡Œå®Œæ•´EDA", 
                            variant="primary",
                            size="lg"
                        )
                        
                        gr.HTML("""
                        <div style="margin-top: 15px; padding: 15px; background: rgba(52, 152, 219, 0.1); border-radius: 10px;">
                            <h4>ğŸ“‹ EDAåˆ†æå†…å®¹</h4>
                            <ul>
                                <li>ğŸ“Š æ•°æ®åŸºæœ¬ä¿¡æ¯ç»Ÿè®¡</li>
                                <li>ğŸ¯ ç›®æ ‡å˜é‡æ·±åº¦åˆ†æ</li>
                                <li>ğŸ“ˆ æ•°å€¼ç‰¹å¾ç›¸å…³æ€§</li>
                                <li>â° æ—¶é—´æ¨¡å¼è¯†åˆ«</li>
                                <li>ğŸŒ¤ï¸ å¤©æ°”å½±å“è¯„ä¼°</li>
                                <li>ğŸ“‘ åˆ†ç±»ç‰¹å¾åˆ†æ</li>
                            </ul>
                        </div>
                        """)
                    
                    with gr.Column(scale=2):
                        eda_analysis_report = gr.Markdown(
                            "ğŸ’¡ **EDAåˆ†æå‡†å¤‡**\n\nç‚¹å‡»æ‰§è¡Œå®Œæ•´EDAæŒ‰é’®ï¼Œç³»ç»Ÿå°†å¯¹æ•°æ®è¿›è¡Œå…¨é¢çš„æ¢ç´¢æ€§åˆ†æï¼Œç”Ÿæˆè¯¦ç»†çš„ç»Ÿè®¡æŠ¥å‘Šå’Œå¯è§†åŒ–ã€‚"
                        )
                
                with gr.Row():
                    with gr.Column():
                        comprehensive_eda_plot = gr.Plot(label="ğŸ“Š å®Œæ•´EDAåˆ†æä»ªè¡¨æ¿")
            
            # å®Œæ•´é¢„å¤„ç†æµæ°´çº¿æ ‡ç­¾é¡µ
            with gr.TabItem("ğŸ”§ å®Œæ•´é¢„å¤„ç†", elem_id="complete_preprocessing"):
                gr.HTML("<h2 style='text-align: center; color: #2c3e50; margin: 20px 0;'>ğŸ”§ å®Œæ•´æ•°æ®é¢„å¤„ç†æµæ°´çº¿</h2>")
                
                with gr.Row():
                    with gr.Column(scale=1):
                        preprocessing_pipeline_btn = gr.Button(
                            "âš¡ æ‰§è¡Œå®Œæ•´é¢„å¤„ç†", 
                            variant="primary",
                            size="lg"
                        )
                        
                        gr.HTML("""
                        <div style="margin-top: 15px; padding: 15px; background: rgba(243, 156, 18, 0.1); border-radius: 10px;">
                            <h4>ğŸ› ï¸ é¢„å¤„ç†æµæ°´çº¿</h4>
                            <ul>
                                <li>ğŸ”§ éè¿è¥æ—¥æ•°æ®å¤„ç†</li>
                                <li>â° å®Œæ•´æ—¶é—´ç‰¹å¾å·¥ç¨‹</li>
                                <li>ğŸŒ¤ï¸ å¤©æ°”ç‰¹å¾å·¥ç¨‹</li>
                                <li>ğŸ”— äº¤äº’ç‰¹å¾åˆ›å»º</li>
                                <li>ğŸ“‘ åˆ†ç±»ç‰¹å¾ç¼–ç </li>
                                <li>ğŸ¯ æ™ºèƒ½ç‰¹å¾é€‰æ‹©</li>
                            </ul>
                        </div>
                        """)
                    
                    with gr.Column(scale=2):
                        preprocessing_pipeline_report = gr.Markdown(
                            "ğŸ’¡ **é¢„å¤„ç†æµæ°´çº¿å‡†å¤‡**\n\nç‚¹å‡»æ‰§è¡Œå®Œæ•´é¢„å¤„ç†æŒ‰é’®ï¼Œç³»ç»Ÿå°†æŒ‰ç…§enhancedæ¨¡å—çš„æ ‡å‡†æ‰§è¡Œå®Œæ•´çš„æ•°æ®é¢„å¤„ç†æµæ°´çº¿ã€‚"
                        )
                
                with gr.Row():
                    with gr.Column():
                        preprocessing_pipeline_plot = gr.Plot(label="ğŸ”§ é¢„å¤„ç†ç»“æœä»ªè¡¨æ¿")
                    with gr.Column():
                        final_data_preview = gr.HTML(label="ğŸ“‹ æœ€ç»ˆæ•°æ®é¢„è§ˆ")
                
                with gr.Row():
                    with gr.Column():
                        download_files = gr.File(
                            label="ğŸ“¥ ä¸‹è½½å¤„ç†åçš„æ•°æ®",
                            file_count="multiple",
                            interactive=False,
                            visible=False
                        )
                        gr.HTML("""
                        <div style="margin-top: 15px; padding: 15px; background: rgba(46, 204, 113, 0.1); border-radius: 10px;">
                            <h4>ğŸ“¦ æ•°æ®ä¸‹è½½è¯´æ˜</h4>
                            <ul>
                                <li><strong>train_data.csv</strong>: è®­ç»ƒæ•°æ®é›† (70%)</li>
                                <li><strong>validation_data.csv</strong>: éªŒè¯æ•°æ®é›† (15%)</li>
                                <li><strong>test_data.csv</strong>: æµ‹è¯•æ•°æ®é›† (15%)</li>
                                <li><strong>preprocessed_full_data.csv</strong>: å®Œæ•´é¢„å¤„ç†æ•°æ®</li>
                            </ul>
                            <p style="color: #27ae60; margin: 10px 0; font-weight: bold;">
                                ğŸ’¡ æ•°æ®å·²æŒ‰æ—¶é—´é¡ºåºåˆ†å‰²ï¼Œå¯ç›´æ¥ç”¨äºæœºå™¨å­¦ä¹ è®­ç»ƒ
                            </p>
                        </div>
                        """)
            

        
        # äº‹ä»¶ç»‘å®šå‡½æ•°
        def update_dropdowns(file):
            """æ›´æ–°ä¸‹æ‹‰èœå•é€‰é¡¹"""
            if file is None:
                return (
                    gr.update(choices=[]), 
                    gr.update(choices=[]), 
                    gr.update(choices=[])
                )
            
            try:
                # ä½¿ç”¨ä¸load_dataç›¸åŒçš„ç¼–ç æ£€æµ‹é€»è¾‘
                encodings = ['utf-8', 'gbk', 'gb2312', 'cp936', 'iso-8859-1', 'latin1']
                temp_df = None
                
                for encoding in encodings:
                    try:
                        temp_df = pd.read_csv(file.name, encoding=encoding)
                        break
                    except UnicodeDecodeError:
                        continue
                else:
                    # å¦‚æœæ‰€æœ‰ç¼–ç éƒ½å¤±è´¥ï¼Œä½¿ç”¨é”™è¯¯å¤„ç†æ¨¡å¼
                    temp_df = pd.read_csv(file.name, encoding='utf-8', errors='ignore')
                
                if temp_df is not None:
                    numeric_cols = temp_df.select_dtypes(include=[np.number]).columns.tolist()
                    all_cols = temp_df.columns.tolist()
                    
                    return (
                        gr.update(choices=numeric_cols, value=numeric_cols[0] if numeric_cols else None),
                        gr.update(choices=all_cols),
                        gr.update(choices=numeric_cols, value=numeric_cols[0] if numeric_cols else None)
                    )
                else:
                    return (
                        gr.update(choices=[]), 
                        gr.update(choices=[]), 
                        gr.update(choices=[])
                    )
                    
            except Exception as e:
                print(f"æ›´æ–°ä¸‹æ‹‰èœå•å¤±è´¥: {str(e)}")
                return (
                    gr.update(choices=[]), 
                    gr.update(choices=[]), 
                    gr.update(choices=[])
                )
        
        # ç»‘å®šæ‰€æœ‰äº‹ä»¶  
        def load_and_update(file):
            """åŠ è½½æ•°æ®å¹¶æ›´æ–°ä¸‹æ‹‰èœå•"""
            # å…ˆåŠ è½½æ•°æ®
            load_result = processor.load_data(file)
            
            # ç„¶åæ›´æ–°ä¸‹æ‹‰èœå•
            dropdown_result = update_dropdowns(file)
            
            # è¿”å›æ‰€æœ‰ç»“æœ
            return load_result + dropdown_result
        
        load_btn.click(
            fn=load_and_update,
            inputs=[file_input],
            outputs=[load_status, data_preview, overview_plot, target_column, date_column, target_for_fe]
        )
        
        analyze_btn.click(
            fn=processor.analyze_target,
            inputs=[target_column],
            outputs=[target_analysis, target_plot]
        )
        
        feature_btn.click(
            fn=processor.feature_engineering,
            inputs=[date_column, target_for_fe],
            outputs=[fe_status, importance_plot, processed_preview]
        )
        
        deep_analysis_btn.click(
            fn=processor.deep_analysis,
            inputs=[],
            outputs=[deep_analysis_report, time_pattern_plot, weather_impact_plot, 
                    demand_segmentation_plot, predictive_insights_plot]
        )
        
        # æ–°å¢äº‹ä»¶ç»‘å®š
        eda_analysis_btn.click(
            fn=processor.comprehensive_eda_analysis,
            inputs=[],
            outputs=[eda_analysis_report, comprehensive_eda_plot]
        )
        
        def update_preprocessing_with_download():
            """æ‰§è¡Œé¢„å¤„ç†å¹¶æ›´æ–°ä¸‹è½½æ–‡ä»¶"""
            report, plot, preview, files = processor.complete_preprocessing_pipeline()
            
            # æ›´æ–°ä¸‹è½½æ–‡ä»¶å¯è§æ€§
            download_visible = files is not None
            download_value = files if files else None
            
            return (
                report, 
                plot, 
                preview, 
                gr.update(value=download_value, visible=download_visible)
            )
        
        preprocessing_pipeline_btn.click(
            fn=update_preprocessing_with_download,
            inputs=[],
            outputs=[preprocessing_pipeline_report, preprocessing_pipeline_plot, final_data_preview, download_files]
        )
        

    
    return demo

# ä¸»ç¨‹åº
if __name__ == "__main__":
    print("ğŸš´â€â™‚ï¸ å¯åŠ¨é¦–å°”è‡ªè¡Œè½¦éœ€æ±‚é¢„æµ‹æ•°æ®å¤„ç†å¹³å°...")
    print("ğŸŒ åº”ç”¨å°†åœ¨æµè§ˆå™¨ä¸­è‡ªåŠ¨æ‰“å¼€")
    print("ğŸ“± æœ¬åœ°è®¿é—®åœ°å€: http://localhost:7860")
    print("â­ æŒ‰ Ctrl+C åœæ­¢åº”ç”¨\n")
    
    # åˆ›å»ºå¹¶å¯åŠ¨ç•Œé¢
    demo = create_interface()
    demo.launch(
        server_name="127.0.0.1",
        server_port=7860,
        share=True,
        inbrowser=True,
        show_error=True,
        debug=False,
        quiet=False
    )