#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®éªŒ4ï¼šè®­ç»ƒæ ·æœ¬å¤§å°å½±å“åˆ†æ (æˆå‘˜D)
CDS503 Group Project - é¦–å°”è‡ªè¡Œè½¦éœ€æ±‚é¢„æµ‹

ç›®æ ‡ï¼šåˆ†æè®­ç»ƒæ ·æœ¬å¤§å°å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“
æ–¹æ³•ï¼šä»¥10%é€’å¢çš„æ–¹å¼æµ‹è¯•ä¸åŒè®­ç»ƒé›†å¤§å°ï¼ˆ10%-100%ï¼‰
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import xgboost as xgb
import time
import warnings
warnings.filterwarnings('ignore')

from data_preprocessing import BikeDataPreprocessor

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class SampleSizeAnalysis:
    """è®­ç»ƒæ ·æœ¬å¤§å°åˆ†æå®éªŒç±»"""
    
    def __init__(self):
        self.results = {}
        self.learning_curves = {}
        self.preprocessor = BikeDataPreprocessor()
        
    def calculate_metrics(self, y_true, y_pred):
        """è®¡ç®—è¯„ä¼°æŒ‡æ ‡"""
        rmse = np.sqrt(mean_squared_error(y_true, y_pred))
        mae = mean_absolute_error(y_true, y_pred)
        r2 = r2_score(y_true, y_pred)
        mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-8))) * 100
        
        return {
            'RMSE': rmse,
            'MAE': mae,
            'RÂ²': r2,
            'MAPE': mape
        }
    
    def create_models(self):
        """åˆ›å»ºè¦æµ‹è¯•çš„æ¨¡å‹"""
        models = {
            'Linear Regression': LinearRegression(),
            'Random Forest': RandomForestRegressor(
                n_estimators=100,
                max_depth=20,
                random_state=42
            ),
            'XGBoost': xgb.XGBRegressor(
                n_estimators=100,
                max_depth=6,
                learning_rate=0.1,
                random_state=42
            ),
            'SVR': SVR(kernel='rbf', C=1.0, gamma='scale')
        }
        return models
    
    def train_with_sample_size(self, model, X_train, y_train, X_val, X_test, 
                              y_val, y_test, sample_ratio, model_name):
        """ä½¿ç”¨æŒ‡å®šæ¯”ä¾‹çš„è®­ç»ƒæ•°æ®è®­ç»ƒæ¨¡å‹"""
        
        # è®¡ç®—æ ·æœ¬æ•°é‡
        n_samples = int(len(X_train) * sample_ratio)
        
        # éšæœºé‡‡æ ·ï¼ˆä¿æŒæ—¶é—´é¡ºåºï¼‰
        indices = np.arange(len(X_train))
        np.random.seed(42)  # ç¡®ä¿å¯é‡å¤æ€§
        selected_indices = np.sort(np.random.choice(indices, size=n_samples, replace=False))
        
        X_train_sample = X_train.iloc[selected_indices]
        y_train_sample = y_train.iloc[selected_indices]
        
        # è®­ç»ƒæ¨¡å‹
        start_time = time.time()
        try:
            model.fit(X_train_sample, y_train_sample)
            training_time = time.time() - start_time
            
            # é¢„æµ‹
            y_train_pred = model.predict(X_train_sample)
            y_val_pred = model.predict(X_val)
            y_test_pred = model.predict(X_test)
            
            # è®¡ç®—æŒ‡æ ‡
            train_metrics = self.calculate_metrics(y_train_sample, y_train_pred)
            val_metrics = self.calculate_metrics(y_val, y_val_pred)
            test_metrics = self.calculate_metrics(y_test, y_test_pred)
            
            return {
                'sample_size': n_samples,
                'sample_ratio': sample_ratio,
                'train_metrics': train_metrics,
                'val_metrics': val_metrics,
                'test_metrics': test_metrics,
                'training_time': training_time,
                'success': True
            }
            
        except Exception as e:
            print(f"  âŒ {model_name} åœ¨æ ·æœ¬æ¯”ä¾‹ {sample_ratio:.1%} æ—¶è®­ç»ƒå¤±è´¥: {str(e)}")
            return {
                'sample_size': n_samples,
                'sample_ratio': sample_ratio,
                'success': False,
                'error': str(e)
            }
    
    def analyze_learning_curve(self, model_name, model, X_train, y_train, 
                              X_val, X_test, y_val, y_test):
        """åˆ†æç‰¹å®šæ¨¡å‹çš„å­¦ä¹ æ›²çº¿"""
        print(f"\nğŸ“ˆ åˆ†æ {model_name} çš„å­¦ä¹ æ›²çº¿...")
        
        # å®šä¹‰æ ·æœ¬æ¯”ä¾‹ï¼ˆ10%åˆ°100%ï¼Œä»¥10%é€’å¢ï¼‰
        sample_ratios = np.arange(0.1, 1.1, 0.1)
        
        results = []
        
        for ratio in sample_ratios:
            print(f"  è®­ç»ƒæ ·æœ¬æ¯”ä¾‹: {ratio:.1%} ({int(len(X_train) * ratio)} æ ·æœ¬)")
            
            # åˆ›å»ºæ¨¡å‹å‰¯æœ¬ä»¥é¿å…é‡å¤ä½¿ç”¨å·²è®­ç»ƒçš„æ¨¡å‹
            if model_name == 'Linear Regression':
                model_copy = LinearRegression()
            elif model_name == 'Random Forest':
                model_copy = RandomForestRegressor(
                    n_estimators=100, max_depth=20, random_state=42
                )
            elif model_name == 'XGBoost':
                model_copy = xgb.XGBRegressor(
                    n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42
                )
            elif model_name == 'SVR':
                model_copy = SVR(kernel='rbf', C=1.0, gamma='scale')
            else:
                model_copy = model
            
            result = self.train_with_sample_size(
                model_copy, X_train, y_train, X_val, X_test, 
                y_val, y_test, ratio, model_name
            )
            
            if result['success']:
                print(f"    éªŒè¯é›† RMSE: {result['val_metrics']['RMSE']:.2f}")
                print(f"    æµ‹è¯•é›† RMSE: {result['test_metrics']['RMSE']:.2f}")
                print(f"    è®­ç»ƒæ—¶é—´: {result['training_time']:.2f}ç§’")
            
            results.append(result)
        
        return results
    
    def run_experiment(self):
        """è¿è¡Œè®­ç»ƒæ ·æœ¬å¤§å°åˆ†æå®éªŒ"""
        print("ğŸš€ å¼€å§‹å®éªŒ4ï¼šè®­ç»ƒæ ·æœ¬å¤§å°å½±å“åˆ†æ")
        print("="*50)
        
        # æ•°æ®é¢„å¤„ç†
        print("1. æ•°æ®é¢„å¤„ç†...")
        df = self.preprocessor.load_data()
        df_processed = self.preprocessor.prepare_features(df, use_lag_features=False)
        
        # æ•°æ®åˆ†å‰²
        X_train, X_val, X_test, y_train, y_val, y_test = \
            self.preprocessor.split_data_temporal(df_processed)
        
        # ç‰¹å¾æ ‡å‡†åŒ–
        X_train_scaled, X_val_scaled, X_test_scaled = \
            self.preprocessor.scale_features(X_train, X_val, X_test)
        
        print(f"\næ•°æ®æ¦‚è§ˆ:")
        print(f"  ç‰¹å¾æ•°é‡: {X_train_scaled.shape[1]}")
        print(f"  è®­ç»ƒæ ·æœ¬æ€»æ•°: {X_train_scaled.shape[0]}")
        print(f"  éªŒè¯æ ·æœ¬: {X_val_scaled.shape[0]}")
        print(f"  æµ‹è¯•æ ·æœ¬: {X_test_scaled.shape[0]}")
        
        # åˆ›å»ºæ¨¡å‹
        models = self.create_models()
        
        print(f"\n2. å¼€å§‹åˆ†æ {len(models)} ä¸ªæ¨¡å‹çš„å­¦ä¹ æ›²çº¿...")
        
        # åˆ†ææ¯ä¸ªæ¨¡å‹çš„å­¦ä¹ æ›²çº¿
        for i, (model_name, model) in enumerate(models.items(), 1):
            print(f"\nè¿›åº¦: {i}/{len(models)}")
            
            learning_curve_results = self.analyze_learning_curve(
                model_name, model,
                X_train_scaled, y_train, X_val_scaled, X_test_scaled,
                y_val, y_test
            )
            
            self.learning_curves[model_name] = learning_curve_results
        
        print("\nâœ… è®­ç»ƒæ ·æœ¬å¤§å°åˆ†æå®Œæˆ!")
        
        # ç”ŸæˆæŠ¥å‘Š
        self.generate_analysis_report()
        
        # ä¿å­˜ç»“æœ
        self.save_results()
        
        return self.learning_curves
    
    def generate_analysis_report(self):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        print("\nğŸ“Š ç”Ÿæˆè®­ç»ƒæ ·æœ¬å¤§å°åˆ†ææŠ¥å‘Š...")
        
        # åˆ›å»ºè¯¦ç»†ç»“æœDataFrame
        detailed_results = []
        
        for model_name, results in self.learning_curves.items():
            for result in results:
                if result['success']:
                    row = {
                        'Model': model_name,
                        'Sample_Ratio': result['sample_ratio'],
                        'Sample_Size': result['sample_size'],
                        'Train_RMSE': result['train_metrics']['RMSE'],
                        'Val_RMSE': result['val_metrics']['RMSE'],
                        'Test_RMSE': result['test_metrics']['RMSE'],
                        'Test_RÂ²': result['test_metrics']['RÂ²'],
                        'Training_Time': result['training_time']
                    }
                    detailed_results.append(row)
        
        results_df = pd.DataFrame(detailed_results)
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        results_df.to_csv('experiment_4_detailed_results.csv', index=False)
        
        # åˆ›å»ºæ±‡æ€»è¡¨ï¼ˆæ¯ä¸ªæ¨¡å‹åœ¨100%æ•°æ®ä¸Šçš„æœ€ç»ˆæ€§èƒ½ï¼‰
        summary_results = []
        for model_name in self.learning_curves.keys():
            model_results = results_df[results_df['Model'] == model_name]
            if not model_results.empty:
                # è·å–100%æ•°æ®çš„ç»“æœ
                full_data_result = model_results[model_results['Sample_Ratio'] == 1.0]
                if not full_data_result.empty:
                    best_result = full_data_result.iloc[0]
                    summary_results.append({
                        'Model': model_name,
                        'Final_Test_RMSE': best_result['Test_RMSE'],
                        'Final_Test_RÂ²': best_result['Test_RÂ²'],
                        'Final_Training_Time': best_result['Training_Time'],
                        'Data_Efficiency': self.calculate_data_efficiency(model_name, results_df)
                    })
        
        summary_df = pd.DataFrame(summary_results)
        summary_df = summary_df.sort_values('Final_Test_RMSE')
        
        print("\nğŸ“ˆ æ¨¡å‹æœ€ç»ˆæ€§èƒ½æ±‡æ€» (100%è®­ç»ƒæ•°æ®):")
        print("="*70)
        print(summary_df.round(4).to_string(index=False))
        
        # ä¿å­˜æ±‡æ€»ç»“æœ
        summary_df.to_csv('experiment_4_summary.csv', index=False)
        
        # åˆ›å»ºå¯è§†åŒ–
        self.create_visualizations(results_df, summary_df)
        
        # æ•°æ®æ•ˆç‡åˆ†æ
        print(f"\nğŸ“Š æ•°æ®æ•ˆç‡åˆ†æ:")
        self.analyze_data_efficiency(results_df)
        
        # æ€§èƒ½åˆ†æ
        print(f"\nğŸ† æœ€ä½³æ¨¡å‹ (100%æ•°æ®):")
        best_model = summary_df.iloc[0]
        print(f"  æ¨¡å‹: {best_model['Model']}")
        print(f"  æµ‹è¯•é›†RMSE: {best_model['Final_Test_RMSE']:.2f}")
        print(f"  æµ‹è¯•é›†RÂ²: {best_model['Final_Test_RÂ²']:.4f}")
        print(f"  æ•°æ®æ•ˆç‡: {best_model['Data_Efficiency']:.2f}")
        
        # æ¨èæœ€å°è®­ç»ƒé›†å¤§å°
        print(f"\nğŸ’¡ æ¨èè®­ç»ƒé›†å¤§å°:")
        self.recommend_training_size(results_df)
    
    def calculate_data_efficiency(self, model_name, results_df):
        """è®¡ç®—æ•°æ®æ•ˆç‡æŒ‡æ ‡"""
        model_results = results_df[results_df['Model'] == model_name].sort_values('Sample_Ratio')
        
        if len(model_results) < 2:
            return 0.0
        
        # è®¡ç®—ä»50%åˆ°100%æ•°æ®æ—¶çš„æ€§èƒ½æ”¹è¿›
        result_50 = model_results[model_results['Sample_Ratio'] >= 0.5]
        result_100 = model_results[model_results['Sample_Ratio'] == 1.0]
        
        if len(result_50) > 0 and len(result_100) > 0:
            rmse_50 = result_50.iloc[0]['Test_RMSE']
            rmse_100 = result_100.iloc[0]['Test_RMSE']
            
            # æ•°æ®æ•ˆç‡ = (RMSE_50 - RMSE_100) / RMSE_100 * 100
            # å€¼è¶Šé«˜è¡¨ç¤ºå¢åŠ æ•°æ®çš„è¾¹é™…æ•ˆç›Šè¶Šå¤§
            efficiency = (rmse_50 - rmse_100) / rmse_100 * 100
            return max(0, efficiency)  # ç¡®ä¿éè´Ÿ
        
        return 0.0
    
    def analyze_data_efficiency(self, results_df):
        """åˆ†ææ•°æ®æ•ˆç‡"""
        
        for model_name in results_df['Model'].unique():
            model_results = results_df[results_df['Model'] == model_name].sort_values('Sample_Ratio')
            
            print(f"\n  {model_name}:")
            
            # æ‰¾åˆ°æ€§èƒ½ç¨³å®šç‚¹ï¼ˆRMSEå˜åŒ–<1%çš„ç‚¹ï¼‰
            stable_point = None
            for i in range(1, len(model_results)):
                prev_rmse = model_results.iloc[i-1]['Test_RMSE']
                curr_rmse = model_results.iloc[i]['Test_RMSE']
                
                improvement = (prev_rmse - curr_rmse) / prev_rmse
                if improvement < 0.01:  # æ”¹è¿›å°äº1%
                    stable_point = model_results.iloc[i]['Sample_Ratio']
                    break
            
            if stable_point:
                print(f"    æ€§èƒ½ç¨³å®šç‚¹: {stable_point:.1%} è®­ç»ƒæ•°æ®")
            else:
                print(f"    æ€§èƒ½ç¨³å®šç‚¹: æœªæ‰¾åˆ° (å»ºè®®ä½¿ç”¨æ›´å¤šæ•°æ®)")
            
            # è®¡ç®—è¾¹é™…æ•ˆç›Š
            if len(model_results) >= 5:
                rmse_values = model_results['Test_RMSE'].values
                marginal_benefits = []
                for i in range(1, len(rmse_values)):
                    benefit = (rmse_values[i-1] - rmse_values[i]) / rmse_values[i-1] * 100
                    marginal_benefits.append(benefit)
                
                avg_marginal_benefit = np.mean(marginal_benefits)
                print(f"    å¹³å‡è¾¹é™…æ•ˆç›Š: {avg_marginal_benefit:.2f}%")
    
    def recommend_training_size(self, results_df):
        """æ¨èæœ€ä½³è®­ç»ƒé›†å¤§å°"""
        
        target_rmse = 200  # ç›®æ ‡RMSE
        
        for model_name in results_df['Model'].unique():
            model_results = results_df[results_df['Model'] == model_name].sort_values('Sample_Ratio')
            
            # æ‰¾åˆ°è¾¾åˆ°ç›®æ ‡æ€§èƒ½çš„æœ€å°æ•°æ®é‡
            target_achieved = model_results[model_results['Test_RMSE'] <= target_rmse]
            
            if not target_achieved.empty:
                min_ratio = target_achieved['Sample_Ratio'].min()
                min_samples = target_achieved[target_achieved['Sample_Ratio'] == min_ratio]['Sample_Size'].iloc[0]
                print(f"  {model_name}: æœ€å°‘éœ€è¦ {min_ratio:.1%} æ•°æ® ({min_samples} æ ·æœ¬) è¾¾åˆ°RMSEâ‰¤{target_rmse}")
            else:
                print(f"  {model_name}: æ— æ³•è¾¾åˆ°RMSEâ‰¤{target_rmse}ç›®æ ‡")
    
    def create_visualizations(self, results_df, summary_df):
        """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
        
        plt.style.use('default')
        fig = plt.figure(figsize=(20, 16))
        
        # 1. å­¦ä¹ æ›²çº¿ - æµ‹è¯•é›†RMSE
        plt.subplot(2, 4, 1)
        for model_name in results_df['Model'].unique():
            model_data = results_df[results_df['Model'] == model_name].sort_values('Sample_Ratio')
            plt.plot(model_data['Sample_Ratio'], model_data['Test_RMSE'], 
                    marker='o', label=model_name, linewidth=2, markersize=6)
        
        plt.xlabel('è®­ç»ƒæ ·æœ¬æ¯”ä¾‹')
        plt.ylabel('æµ‹è¯•é›† RMSE')
        plt.title('å­¦ä¹ æ›²çº¿ - æµ‹è¯•é›†RMSE')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.xlim(0.1, 1.0)
        
        # 2. å­¦ä¹ æ›²çº¿ - æµ‹è¯•é›†RÂ²
        plt.subplot(2, 4, 2)
        for model_name in results_df['Model'].unique():
            model_data = results_df[results_df['Model'] == model_name].sort_values('Sample_Ratio')
            plt.plot(model_data['Sample_Ratio'], model_data['Test_RÂ²'], 
                    marker='s', label=model_name, linewidth=2, markersize=6)
        
        plt.xlabel('è®­ç»ƒæ ·æœ¬æ¯”ä¾‹')
        plt.ylabel('æµ‹è¯•é›† RÂ²')
        plt.title('å­¦ä¹ æ›²çº¿ - æµ‹è¯•é›†RÂ²')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.xlim(0.1, 1.0)
        
        # 3. è®­ç»ƒæ—¶é—´ä¸æ ·æœ¬é‡å…³ç³»
        plt.subplot(2, 4, 3)
        for model_name in results_df['Model'].unique():
            model_data = results_df[results_df['Model'] == model_name].sort_values('Sample_Ratio')
            plt.plot(model_data['Sample_Size'], model_data['Training_Time'], 
                    marker='^', label=model_name, linewidth=2, markersize=6)
        
        plt.xlabel('è®­ç»ƒæ ·æœ¬æ•°é‡')
        plt.ylabel('è®­ç»ƒæ—¶é—´ (ç§’)')
        plt.title('è®­ç»ƒæ—¶é—´ vs æ ·æœ¬é‡')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # 4. è¿‡æ‹Ÿåˆåˆ†æ (è®­ç»ƒé›†vsæµ‹è¯•é›†RMSE)
        plt.subplot(2, 4, 4)
        sample_ratios = [0.3, 0.6, 1.0]  # é€‰æ‹©å‡ ä¸ªä»£è¡¨æ€§çš„æ¯”ä¾‹
        colors = ['red', 'blue', 'green']
        
        for i, ratio in enumerate(sample_ratios):
            ratio_data = results_df[results_df['Sample_Ratio'] == ratio]
            plt.scatter(ratio_data['Train_RMSE'], ratio_data['Test_RMSE'], 
                       s=100, alpha=0.7, c=colors[i], label=f'{ratio:.0%} æ•°æ®')
        
        # æ·»åŠ å¯¹è§’çº¿
        min_rmse = min(results_df['Train_RMSE'].min(), results_df['Test_RMSE'].min())
        max_rmse = max(results_df['Train_RMSE'].max(), results_df['Test_RMSE'].max())
        plt.plot([min_rmse, max_rmse], [min_rmse, max_rmse], 'k--', alpha=0.8, label='ç†æƒ³çº¿')
        
        plt.xlabel('è®­ç»ƒé›† RMSE')
        plt.ylabel('æµ‹è¯•é›† RMSE')
        plt.title('è¿‡æ‹Ÿåˆåˆ†æ')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # 5. è¾¹é™…æ•ˆç›Šåˆ†æ
        plt.subplot(2, 4, 5)
        for model_name in results_df['Model'].unique():
            model_data = results_df[results_df['Model'] == model_name].sort_values('Sample_Ratio')
            
            # è®¡ç®—è¾¹é™…æ•ˆç›Š
            rmse_values = model_data['Test_RMSE'].values
            ratios = model_data['Sample_Ratio'].values
            
            marginal_benefits = []
            for i in range(1, len(rmse_values)):
                benefit = (rmse_values[i-1] - rmse_values[i]) / rmse_values[i-1] * 100
                marginal_benefits.append(benefit)
            
            if marginal_benefits:
                plt.plot(ratios[1:], marginal_benefits, marker='d', 
                        label=model_name, linewidth=2, markersize=6)
        
        plt.xlabel('è®­ç»ƒæ ·æœ¬æ¯”ä¾‹')
        plt.ylabel('è¾¹é™…æ•ˆç›Š (%)')
        plt.title('æ•°æ®å¢åŠ çš„è¾¹é™…æ•ˆç›Š')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.xlim(0.2, 1.0)
        
        # 6. æœ€ç»ˆæ€§èƒ½æ¯”è¾ƒ
        plt.subplot(2, 4, 6)
        models = summary_df['Model']
        final_rmse = summary_df['Final_Test_RMSE']
        
        bars = plt.bar(range(len(models)), final_rmse, color='skyblue', alpha=0.7)
        plt.xlabel('æ¨¡å‹')
        plt.ylabel('æœ€ç»ˆæµ‹è¯•é›† RMSE')
        plt.title('æœ€ç»ˆæ¨¡å‹æ€§èƒ½æ¯”è¾ƒ (100%æ•°æ®)')
        plt.xticks(range(len(models)), models, rotation=45, ha='right')
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, v in enumerate(final_rmse):
            plt.text(i, v + 5, f'{v:.1f}', ha='center', va='bottom')
        
        plt.grid(axis='y', alpha=0.3)
        
        # 7. æ•°æ®æ•ˆç‡æ¯”è¾ƒ
        plt.subplot(2, 4, 7)
        efficiency = summary_df['Data_Efficiency']
        
        bars = plt.bar(range(len(models)), efficiency, color='lightgreen', alpha=0.7)
        plt.xlabel('æ¨¡å‹')
        plt.ylabel('æ•°æ®æ•ˆç‡æŒ‡æ ‡')
        plt.title('æ¨¡å‹æ•°æ®æ•ˆç‡æ¯”è¾ƒ')
        plt.xticks(range(len(models)), models, rotation=45, ha='right')
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, v in enumerate(efficiency):
            plt.text(i, v + 0.1, f'{v:.1f}', ha='center', va='bottom')
        
        plt.grid(axis='y', alpha=0.3)
        
        # 8. æ€§èƒ½æ”¶æ•›åˆ†æ
        plt.subplot(2, 4, 8)
        for model_name in results_df['Model'].unique():
            model_data = results_df[results_df['Model'] == model_name].sort_values('Sample_Ratio')
            
            # è®¡ç®—ç›¸å¯¹äºæœ€ç»ˆæ€§èƒ½çš„å·®è·
            final_rmse = model_data['Test_RMSE'].iloc[-1]
            relative_gap = (model_data['Test_RMSE'] - final_rmse) / final_rmse * 100
            
            plt.plot(model_data['Sample_Ratio'], relative_gap, 
                    marker='o', label=model_name, linewidth=2, markersize=6)
        
        plt.xlabel('è®­ç»ƒæ ·æœ¬æ¯”ä¾‹')
        plt.ylabel('ç›¸å¯¹æ€§èƒ½å·®è· (%)')
        plt.title('æ€§èƒ½æ”¶æ•›åˆ†æ')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.xlim(0.1, 1.0)
        plt.axhline(y=5, color='red', linestyle='--', alpha=0.7, label='5%é˜ˆå€¼')
        
        plt.tight_layout()
        plt.savefig('experiment_4_sample_size_analysis.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        print("ğŸ“¸ å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜: experiment_4_sample_size_analysis.png")
    
    def save_results(self):
        """ä¿å­˜å®éªŒç»“æœ"""
        # ä¿å­˜å­¦ä¹ æ›²çº¿æ•°æ®
        learning_curve_summary = {}
        for model_name, results in self.learning_curves.items():
            learning_curve_summary[model_name] = [
                {
                    'sample_ratio': r['sample_ratio'],
                    'sample_size': r['sample_size'],
                    'test_rmse': r['test_metrics']['RMSE'] if r['success'] else None,
                    'test_r2': r['test_metrics']['RÂ²'] if r['success'] else None,
                    'training_time': r['training_time'] if r['success'] else None,
                    'success': r['success']
                }
                for r in results
            ]
        
        # ä¿å­˜ä¸ºJSON
        import json
        with open('experiment_4_learning_curves.json', 'w', encoding='utf-8') as f:
            json.dump(learning_curve_summary, f, indent=2, ensure_ascii=False)
        
        print("ğŸ’¾ å®éªŒç»“æœå·²ä¿å­˜:")
        print("  - experiment_4_detailed_results.csv")
        print("  - experiment_4_summary.csv")
        print("  - experiment_4_learning_curves.json")
        print("  - experiment_4_sample_size_analysis.png")

def main():
    """ä¸»å‡½æ•°"""
    
    # åˆ›å»ºå®éªŒå®ä¾‹
    experiment = SampleSizeAnalysis()
    
    # è¿è¡Œå®éªŒ
    results = experiment.run_experiment()
    
    print("\nğŸ‰ å®éªŒ4å®Œæˆï¼")
    print(f"åˆ†æäº† {len(results)} ä¸ªæ¨¡å‹çš„å­¦ä¹ æ›²çº¿")
    
    # è¾“å‡ºæœ€ç»ˆæ€»ç»“
    print("\nğŸ“‹ å®éªŒæ€»ç»“:")
    print("- å·²å®Œæˆè®­ç»ƒæ ·æœ¬å¤§å°å½±å“åˆ†æ")
    print("- ç”Ÿæˆäº†å®Œæ•´çš„å­¦ä¹ æ›²çº¿")
    print("- åˆ†æäº†æ•°æ®æ•ˆç‡å’Œè¾¹é™…æ•ˆç›Š")
    print("- æä¾›äº†æœ€ä½³è®­ç»ƒé›†å¤§å°å»ºè®®")

if __name__ == "__main__":
    main() 