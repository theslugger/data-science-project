#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é€šç”¨å·¥å…·å‡½æ•°
CDS503 Group Project - é¦–å°”è‡ªè¡Œè½¦éœ€æ±‚é¢„æµ‹
"""

import logging
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from datetime import datetime
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import warnings
import json

from config import config

# é…ç½®è­¦å‘Šå’Œå­—ä½“
warnings.filterwarnings('ignore')
plt.rcParams['font.sans-serif'] = config.VIZ_CONFIG['font_family']
plt.rcParams['axes.unicode_minus'] = False
sns.set_style(config.VIZ_CONFIG['style'])
sns.set_palette(config.VIZ_CONFIG['color_palette'])

class Logger:
    """æ—¥å¿—ç®¡ç†ç±»"""
    
    def __init__(self, name, level=None):
        self.logger = logging.getLogger(name)
        
        if not self.logger.handlers:
            # è®¾ç½®æ—¥å¿—çº§åˆ«
            level = level or config.LOGGING_CONFIG['level']
            self.logger.setLevel(getattr(logging, level))
            
            # åˆ›å»ºæ ¼å¼å™¨
            formatter = logging.Formatter(config.LOGGING_CONFIG['format'])
            
            # æ§åˆ¶å°å¤„ç†å™¨
            console_handler = logging.StreamHandler()
            console_handler.setFormatter(formatter)
            self.logger.addHandler(console_handler)
            
            # æ–‡ä»¶å¤„ç†å™¨
            file_handler = logging.FileHandler(config.LOGGING_CONFIG['log_file'], encoding='utf-8')
            file_handler.setFormatter(formatter)
            self.logger.addHandler(file_handler)
    
    def info(self, message):
        self.logger.info(message)
    
    def warning(self, message):
        self.logger.warning(message)
    
    def error(self, message):
        self.logger.error(message)
    
    def debug(self, message):
        self.logger.debug(message)

class DataValidator:
    """æ•°æ®éªŒè¯ç±»"""
    
    @staticmethod
    def validate_dataframe(df, required_columns=None):
        """éªŒè¯DataFrameçš„åŸºæœ¬å±æ€§"""
        if df is None or df.empty:
            raise ValueError("æ•°æ®æ¡†ä¸ºç©º")
        
        if required_columns:
            missing_cols = set(required_columns) - set(df.columns)
            if missing_cols:
                raise ValueError(f"ç¼ºå°‘å¿…éœ€çš„åˆ—: {missing_cols}")
        
        return True
    
    @staticmethod
    def check_missing_values(df):
        """æ£€æŸ¥ç¼ºå¤±å€¼"""
        missing_summary = df.isnull().sum()
        missing_percent = (missing_summary / len(df)) * 100
        
        if missing_summary.sum() > 0:
            missing_info = pd.DataFrame({
                'ç¼ºå¤±æ•°é‡': missing_summary,
                'ç¼ºå¤±æ¯”ä¾‹(%)': missing_percent
            }).round(2)
            return missing_info[missing_info['ç¼ºå¤±æ•°é‡'] > 0]
        
        return None
    
    @staticmethod
    def check_data_types(df, expected_types=None):
        """æ£€æŸ¥æ•°æ®ç±»å‹"""
        type_info = pd.DataFrame({
            'åˆ—å': df.columns,
            'æ•°æ®ç±»å‹': df.dtypes,
            'éç©ºæ•°é‡': df.count(),
            'å”¯ä¸€å€¼æ•°é‡': [df[col].nunique() for col in df.columns]
        })
        
        if expected_types:
            type_mismatches = []
            for col, expected_type in expected_types.items():
                if col in df.columns and not df[col].dtype == expected_type:
                    type_mismatches.append(f"{col}: æœŸæœ› {expected_type}, å®é™… {df[col].dtype}")
            
            if type_mismatches:
                return type_info, type_mismatches
        
        return type_info, None

class MetricsCalculator:
    """è¯„ä¼°æŒ‡æ ‡è®¡ç®—ç±»"""
    
    @staticmethod
    def calculate_regression_metrics(y_true, y_pred):
        """è®¡ç®—å›å½’è¯„ä¼°æŒ‡æ ‡"""
        try:
            # ç¡®ä¿è¾“å…¥æ˜¯numpyæ•°ç»„
            y_true = np.array(y_true)
            y_pred = np.array(y_pred)
            
            # ç§»é™¤å¯èƒ½çš„nanå€¼
            mask = ~(np.isnan(y_true) | np.isnan(y_pred))
            y_true_clean = y_true[mask]
            y_pred_clean = y_pred[mask]
            
            if len(y_true_clean) == 0:
                raise ValueError("æ‰€æœ‰é¢„æµ‹å€¼æˆ–çœŸå®å€¼éƒ½æ˜¯NaN")
            
            metrics = {
                'RMSE': np.sqrt(mean_squared_error(y_true_clean, y_pred_clean)),
                'MAE': mean_absolute_error(y_true_clean, y_pred_clean),
                'R2': r2_score(y_true_clean, y_pred_clean),
                'MAPE': np.mean(np.abs((y_true_clean - y_pred_clean) / (y_true_clean + 1e-8))) * 100,
                'MSE': mean_squared_error(y_true_clean, y_pred_clean),
                'Max_Error': np.max(np.abs(y_true_clean - y_pred_clean)),
                'Mean_Error': np.mean(y_true_clean - y_pred_clean),
                'Std_Error': np.std(y_true_clean - y_pred_clean)
            }
            
            return metrics
            
        except Exception as e:
            raise ValueError(f"è®¡ç®—æŒ‡æ ‡æ—¶å‡ºé”™: {str(e)}")
    
    @staticmethod
    def format_metrics(metrics, decimal_places=4):
        """æ ¼å¼åŒ–æŒ‡æ ‡è¾“å‡º"""
        formatted = {}
        for metric, value in metrics.items():
            if metric in ['MAPE']:
                formatted[metric] = f"{value:.{decimal_places-2}f}%"
            elif metric in ['R2']:
                formatted[metric] = f"{value:.{decimal_places}f}"
            else:
                formatted[metric] = f"{value:.{decimal_places-2}f}"
        
        return formatted
    
    @staticmethod
    def compare_models(results_dict):
        """æ¯”è¾ƒå¤šä¸ªæ¨¡å‹çš„æ€§èƒ½"""
        comparison_df = pd.DataFrame(results_dict).T
        
        # æŒ‰RMSEæ’åºï¼ˆè¶Šå°è¶Šå¥½ï¼‰
        comparison_df = comparison_df.sort_values('RMSE')
        
        # æ·»åŠ æ’å
        comparison_df['Rank'] = range(1, len(comparison_df) + 1)
        
        return comparison_df

class DataLoader:
    """æ•°æ®åŠ è½½ç±»"""
    
    def __init__(self, logger=None):
        self.logger = logger or Logger(__name__)
    
    def load_data(self, file_path=None):
        """æ™ºèƒ½åŠ è½½æ•°æ®ï¼Œè‡ªåŠ¨å°è¯•ä¸åŒç¼–ç """
        if file_path is None:
            file_path = config.RAW_DATA_FILE
        
        # å°è¯•ä¸åŒç¼–ç 
        for encoding in config.DATA_CONFIG['encoding']:
            try:
                self.logger.info(f"å°è¯•ä½¿ç”¨ {encoding} ç¼–ç åŠ è½½æ•°æ®...")
                df = pd.read_csv(file_path, encoding=encoding)
                self.logger.info(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼ä½¿ç”¨ç¼–ç : {encoding}")
                self.logger.info(f"æ•°æ®å½¢çŠ¶: {df.shape}")
                return df
            except UnicodeDecodeError:
                self.logger.warning(f"âŒ {encoding} ç¼–ç å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ª...")
                continue
            except Exception as e:
                self.logger.error(f"åŠ è½½æ•°æ®æ—¶å‡ºé”™ ({encoding}): {str(e)}")
                continue
        
        raise ValueError("æ‰€æœ‰ç¼–ç æ–¹å¼éƒ½å¤±è´¥ï¼Œæ— æ³•åŠ è½½æ•°æ®")

class ResultSaver:
    """ç»“æœä¿å­˜ç±»"""
    
    def __init__(self, logger=None):
        self.logger = logger or Logger(__name__)
    
    def save_dataframe(self, df, filename, subdir=None, index=False):
        """ä¿å­˜DataFrameåˆ°CSV"""
        try:
            if subdir:
                save_path = config.OUTPUT_DIR / subdir / f"{filename}.csv"
                save_path.parent.mkdir(parents=True, exist_ok=True)
            else:
                save_path = config.OUTPUT_DIR / f"{filename}.csv"
            
            df.to_csv(save_path, index=index, encoding='utf-8-sig')
            self.logger.info(f"âœ… æ•°æ®å·²ä¿å­˜: {save_path}")
            return save_path
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜æ•°æ®æ¡†å¤±è´¥: {str(e)}")
            raise
    
    def save_figure(self, fig, filename, subdir="figures", dpi=None):
        """ä¿å­˜å›¾è¡¨"""
        try:
            dpi = dpi or config.VIZ_CONFIG['dpi']
            save_path = config.OUTPUT_DIR / subdir / f"{filename}.png"
            save_path.parent.mkdir(parents=True, exist_ok=True)
            
            fig.savefig(save_path, dpi=dpi, bbox_inches='tight', 
                       facecolor='white', edgecolor='none')
            self.logger.info(f"âœ… å›¾è¡¨å·²ä¿å­˜: {save_path}")
            return save_path
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜å›¾è¡¨å¤±è´¥: {str(e)}")
            raise
    
    def save_json(self, data, filename, subdir=None):
        """ä¿å­˜JSONæ•°æ®"""
        try:
            if subdir:
                save_path = config.OUTPUT_DIR / subdir / f"{filename}.json"
                save_path.parent.mkdir(parents=True, exist_ok=True)
            else:
                save_path = config.OUTPUT_DIR / f"{filename}.json"
            
            with open(save_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2, default=str)
            
            self.logger.info(f"âœ… JSONæ•°æ®å·²ä¿å­˜: {save_path}")
            return save_path
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜JSONå¤±è´¥: {str(e)}")
            raise
    
    def save_model_results(self, model_name, metrics, predictions=None, 
                          feature_importance=None, hyperparams=None):
        """ä¿å­˜æ¨¡å‹ç»“æœ"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            result_data = {
                'model_name': model_name,
                'timestamp': timestamp,
                'metrics': metrics,
                'hyperparameters': hyperparams
            }
            
            # ä¿å­˜ä¸»è¦ç»“æœ
            save_path = self.save_json(result_data, f"{model_name}_results_{timestamp}", "results")
            
            # ä¿å­˜é¢„æµ‹ç»“æœ
            if predictions is not None:
                pred_df = pd.DataFrame({
                    'predictions': predictions
                })
                self.save_dataframe(pred_df, f"{model_name}_predictions_{timestamp}", "results")
            
            # ä¿å­˜ç‰¹å¾é‡è¦æ€§
            if feature_importance is not None:
                imp_df = pd.DataFrame({
                    'feature': feature_importance.keys() if isinstance(feature_importance, dict) else range(len(feature_importance)),
                    'importance': feature_importance.values() if isinstance(feature_importance, dict) else feature_importance
                }).sort_values('importance', ascending=False)
                self.save_dataframe(imp_df, f"{model_name}_feature_importance_{timestamp}", "results")
            
            return save_path
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜æ¨¡å‹ç»“æœå¤±è´¥: {str(e)}")
            raise

class VisualizationHelper:
    """å¯è§†åŒ–è¾…åŠ©ç±»"""
    
    def __init__(self, logger=None):
        self.logger = logger or Logger(__name__)
        self.result_saver = ResultSaver(logger)
    
    def create_subplots(self, nrows, ncols, figsize=None):
        """åˆ›å»ºå­å›¾"""
        figsize = figsize or config.VIZ_CONFIG['figure_size']
        fig, axes = plt.subplots(nrows, ncols, figsize=figsize)
        return fig, axes
    
    def plot_correlation_matrix(self, df, target_col=None, save_name=None):
        """ç»˜åˆ¶ç›¸å…³æ€§çŸ©é˜µ"""
        numeric_df = df.select_dtypes(include=[np.number])
        corr_matrix = numeric_df.corr()
        
        fig, ax = plt.subplots(figsize=(12, 10))
        
        # åˆ›å»ºé®ç½©ï¼ˆåªæ˜¾ç¤ºä¸‹ä¸‰è§’ï¼‰
        mask = np.triu(np.ones_like(corr_matrix, dtype=bool))
        
        # ç»˜åˆ¶çƒ­åŠ›å›¾
        sns.heatmap(corr_matrix, mask=mask, annot=True, cmap='coolwarm', 
                   center=0, square=True, fmt='.2f', cbar_kws={"shrink": .8}, ax=ax)
        
        ax.set_title('ç‰¹å¾ç›¸å…³æ€§çŸ©é˜µ', fontsize=16, fontweight='bold', pad=20)
        plt.tight_layout()
        
        if save_name:
            self.result_saver.save_figure(fig, save_name)
        
        return fig, ax
    
    def plot_target_distribution(self, y, save_name=None):
        """ç»˜åˆ¶ç›®æ ‡å˜é‡åˆ†å¸ƒ"""
        fig, axes = plt.subplots(1, 3, figsize=(18, 6))
        
        # ç›´æ–¹å›¾
        axes[0].hist(y, bins=50, alpha=0.7, color='skyblue', edgecolor='black')
        axes[0].set_title('ç›®æ ‡å˜é‡åˆ†å¸ƒ', fontweight='bold')
        axes[0].set_xlabel('ç§Ÿå€Ÿæ•°é‡')
        axes[0].set_ylabel('é¢‘æ¬¡')
        
        # ç®±çº¿å›¾
        axes[1].boxplot(y)
        axes[1].set_title('ç›®æ ‡å˜é‡ç®±çº¿å›¾', fontweight='bold')
        axes[1].set_ylabel('ç§Ÿå€Ÿæ•°é‡')
        
        # Q-Qå›¾
        from scipy import stats
        stats.probplot(y, dist="norm", plot=axes[2])
        axes[2].set_title('Q-Q æ­£æ€æ€§æ£€éªŒ', fontweight='bold')
        
        plt.tight_layout()
        
        if save_name:
            self.result_saver.save_figure(fig, save_name)
        
        return fig, axes
    
    def plot_time_series(self, df, date_col, target_col, save_name=None):
        """ç»˜åˆ¶æ—¶é—´åºåˆ—å›¾"""
        # ç¡®ä¿æ—¥æœŸåˆ—æ˜¯datetimeç±»å‹
        if not pd.api.types.is_datetime64_any_dtype(df[date_col]):
            df[date_col] = pd.to_datetime(df[date_col])
        
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        
        # æ¯æ—¥è¶‹åŠ¿
        daily_avg = df.groupby(df[date_col].dt.date)[target_col].mean()
        axes[0, 0].plot(daily_avg.index, daily_avg.values)
        axes[0, 0].set_title('æ¯æ—¥å¹³å‡ç§Ÿå€Ÿé‡è¶‹åŠ¿', fontweight='bold')
        axes[0, 0].tick_params(axis='x', rotation=45)
        
        # æ¯å°æ—¶æ¨¡å¼
        hourly_avg = df.groupby('Hour')[target_col].mean()
        axes[0, 1].plot(hourly_avg.index, hourly_avg.values, marker='o')
        axes[0, 1].set_title('æ¯å°æ—¶å¹³å‡ç§Ÿå€Ÿé‡', fontweight='bold')
        axes[0, 1].set_xlabel('å°æ—¶')
        axes[0, 1].grid(True, alpha=0.3)
        
        # æ¯æœˆæ¨¡å¼
        monthly_avg = df.groupby(df[date_col].dt.month)[target_col].mean()
        axes[1, 0].bar(monthly_avg.index, monthly_avg.values)
        axes[1, 0].set_title('æ¯æœˆå¹³å‡ç§Ÿå€Ÿé‡', fontweight='bold')
        axes[1, 0].set_xlabel('æœˆä»½')
        
        # å·¥ä½œæ—¥vså‘¨æœ«
        df['is_weekend'] = df[date_col].dt.weekday >= 5
        weekend_avg = df.groupby('is_weekend')[target_col].mean()
        axes[1, 1].bar(['å·¥ä½œæ—¥', 'å‘¨æœ«'], weekend_avg.values)
        axes[1, 1].set_title('å·¥ä½œæ—¥ vs å‘¨æœ«', fontweight='bold')
        
        plt.tight_layout()
        
        if save_name:
            self.result_saver.save_figure(fig, save_name)
        
        return fig, axes

def print_section_header(title, level=1):
    """æ‰“å°æ ¼å¼åŒ–çš„ç« èŠ‚æ ‡é¢˜"""
    if level == 1:
        print("\n" + "="*60)
        print(f"ğŸ” {title}")
        print("="*60)
    elif level == 2:
        print(f"\nğŸ“Š {title}")
        print("-"*50)
    elif level == 3:
        print(f"\nğŸ’¡ {title}")
        print("-"*30)

def get_timestamp():
    """è·å–å½“å‰æ—¶é—´æˆ³"""
    return datetime.now().strftime("%Y%m%d_%H%M%S")

def safe_divide(numerator, denominator, default=0):
    """å®‰å…¨é™¤æ³•ï¼Œé¿å…é™¤é›¶é”™è¯¯"""
    try:
        return numerator / denominator if denominator != 0 else default
    except:
        return default 