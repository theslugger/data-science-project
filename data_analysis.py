#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Seoul Bike Data æ·±åº¦åˆ†æ
é‡æ–°è§‚å¯Ÿæ•°æ®ï¼Œå¯»æ‰¾æ–°çš„æ´å¯Ÿ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'PingFang SC', 'Microsoft YaHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

def load_and_explore_data():
    """åŠ è½½å¹¶æ¢ç´¢æ•°æ®"""
    print('ğŸ“Š é‡æ–°åŠ è½½å’Œè§‚å¯ŸSeoul Bikeæ•°æ®...')
    print('='*60)
    
    # åŠ è½½æ•°æ®
    df = pd.read_csv('SeoulBikeData.csv', encoding='unicode_escape')
    
    print(f'\nğŸ” æ•°æ®åŸºæœ¬ä¿¡æ¯:')
    print(f'æ•°æ®å½¢çŠ¶: {df.shape}')
    print(f'æ—¶é—´èŒƒå›´: {df["Date"].min()} åˆ° {df["Date"].max()}')
    print(f'å†…å­˜ä½¿ç”¨: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB')
    
    print(f'\nğŸ“‹ åˆ—ä¿¡æ¯:')
    for i, col in enumerate(df.columns):
        null_count = df[col].isnull().sum()
        print(f'{i+1:2d}. {col:30s} - {str(df[col].dtype):10s} - ç¼ºå¤±å€¼: {null_count}')
    
    return df

def analyze_target_variable(df):
    """åˆ†æç›®æ ‡å˜é‡"""
    target_col = 'Rented Bike Count'
    print(f'\nğŸ“ˆ ç›®æ ‡å˜é‡ "{target_col}" æ·±åº¦åˆ†æ:')
    print('='*50)
    
    # åŸºç¡€ç»Ÿè®¡
    print(f'å¹³å‡å€¼: {df[target_col].mean():.2f}')
    print(f'ä¸­ä½æ•°: {df[target_col].median():.2f}')
    print(f'æ ‡å‡†å·®: {df[target_col].std():.2f}')
    print(f'æœ€å°å€¼: {df[target_col].min()}')
    print(f'æœ€å¤§å€¼: {df[target_col].max()}')
    print(f'é›¶å€¼æ•°é‡: {(df[target_col] == 0).sum()}')
    print(f'é›¶å€¼æ¯”ä¾‹: {(df[target_col] == 0).mean()*100:.2f}%')
    
    # åˆ†ä½æ•°åˆ†æ
    print(f'\nåˆ†ä½æ•°åˆ†æ:')
    for q in [0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99]:
        print(f'Q{q*100:4.0f}: {df[target_col].quantile(q):8.2f}')
    
    # å¼‚å¸¸å€¼åˆ†æ
    Q1 = df[target_col].quantile(0.25)
    Q3 = df[target_col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = df[(df[target_col] < lower_bound) | (df[target_col] > upper_bound)]
    print(f'\nIQRå¼‚å¸¸å€¼åˆ†æ:')
    print(f'ä¸‹ç•Œ: {lower_bound:.2f}, ä¸Šç•Œ: {upper_bound:.2f}')
    print(f'å¼‚å¸¸å€¼æ•°é‡: {len(outliers)} ({len(outliers)/len(df)*100:.2f}%)')
    
    return df[target_col]

def analyze_time_patterns(df):
    """åˆ†ææ—¶é—´æ¨¡å¼"""
    print(f'\nâ° æ—¶é—´æ¨¡å¼åˆ†æ:')
    print('='*40)
    
    # è½¬æ¢æ—¶é—´ï¼ˆå¤„ç†æ··åˆæ—¥æœŸæ ¼å¼ï¼‰
    df['Date'] = pd.to_datetime(df['Date'], format='mixed', dayfirst=True)
    df['Year'] = df['Date'].dt.year
    df['Month'] = df['Date'].dt.month
    df['Day'] = df['Date'].dt.day
    df['Weekday'] = df['Date'].dt.dayofweek
    df['Weekend'] = (df['Weekday'] >= 5).astype(int)
    
    target_col = 'Rented Bike Count'
    
    # æŒ‰å¹´åˆ†æ
    print('\nğŸ“… æŒ‰å¹´ä»½åˆ†æ:')
    yearly_stats = df.groupby('Year')[target_col].agg(['count', 'mean', 'std', 'min', 'max'])
    print(yearly_stats)
    
    # æŒ‰æœˆåˆ†æ
    print('\nğŸ“… æŒ‰æœˆä»½åˆ†æ:')
    monthly_stats = df.groupby('Month')[target_col].agg(['count', 'mean', 'std'])
    print(monthly_stats)
    
    # æŒ‰å°æ—¶åˆ†æ
    print('\nğŸ• æŒ‰å°æ—¶åˆ†æ:')
    hourly_stats = df.groupby('Hour')[target_col].agg(['mean', 'std'])
    print(hourly_stats)
    
    # å·¥ä½œæ—¥vså‘¨æœ«
    print('\nğŸ“Š å·¥ä½œæ—¥ vs å‘¨æœ«:')
    weekend_stats = df.groupby('Weekend')[target_col].agg(['count', 'mean', 'std'])
    weekend_stats.index = ['å·¥ä½œæ—¥', 'å‘¨æœ«']
    print(weekend_stats)
    
    return df

def analyze_weather_impact(df):
    """åˆ†æå¤©æ°”å½±å“"""
    print(f'\nğŸŒ¤ï¸ å¤©æ°”å› ç´ å½±å“åˆ†æ:')
    print('='*45)
    
    target_col = 'Rented Bike Count'
    
    # æ¸©åº¦å½±å“
    print('\nğŸŒ¡ï¸ æ¸©åº¦åˆ†æ:')
    temp_col = 'Temperature(Â°C)'
    print(f'æ¸©åº¦èŒƒå›´: {df[temp_col].min():.1f}Â°C åˆ° {df[temp_col].max():.1f}Â°C')
    
    # æ¸©åº¦åˆ†æ®µåˆ†æ
    df['Temp_Range'] = pd.cut(df[temp_col], bins=[-50, 0, 10, 20, 30, 50], 
                             labels=['ä¸¥å¯’(<0Â°C)', 'å¯’å†·(0-10Â°C)', 'å‡‰çˆ½(10-20Â°C)', 'æ¸©æš–(20-30Â°C)', 'ç‚çƒ­(>30Â°C)'])
    temp_impact = df.groupby('Temp_Range')[target_col].agg(['count', 'mean', 'std'])
    print(temp_impact)
    
    # æ¹¿åº¦å½±å“
    print('\nğŸ’§ æ¹¿åº¦åˆ†æ:')
    humidity_col = 'Humidity(%)'
    df['Humidity_Range'] = pd.cut(df[humidity_col], bins=[0, 30, 50, 70, 100], 
                                 labels=['ä½æ¹¿åº¦(<30%)', 'ä¸­ç­‰æ¹¿åº¦(30-50%)', 'é«˜æ¹¿åº¦(50-70%)', 'æé«˜æ¹¿åº¦(>70%)'])
    humidity_impact = df.groupby('Humidity_Range')[target_col].agg(['count', 'mean', 'std'])
    print(humidity_impact)
    
    # é£é€Ÿå½±å“
    print('\nğŸ’¨ é£é€Ÿåˆ†æ:')
    wind_col = 'Wind speed (m/s)'
    print(f'é£é€ŸèŒƒå›´: {df[wind_col].min():.1f} åˆ° {df[wind_col].max():.1f} m/s')
    df['Wind_Range'] = pd.cut(df[wind_col], bins=[0, 2, 4, 6, 20], 
                             labels=['å¾®é£(<2m/s)', 'è½»é£(2-4m/s)', 'å’Œé£(4-6m/s)', 'å¼ºé£(>6m/s)'])
    wind_impact = df.groupby('Wind_Range')[target_col].agg(['count', 'mean', 'std'])
    print(wind_impact)
    
    # é™é›¨å½±å“
    print('\nğŸŒ§ï¸ é™é›¨åˆ†æ:')
    rain_col = 'Rainfall(mm)'
    rain_stats = df.groupby(df[rain_col] > 0)[target_col].agg(['count', 'mean', 'std'])
    rain_stats.index = ['æ— é›¨', 'æœ‰é›¨']
    print(rain_stats)
    print(f'é™é›¨å¤©æ•°: {(df[rain_col] > 0).sum()} ({(df[rain_col] > 0).mean()*100:.1f}%)')
    
    # é™é›ªå½±å“
    print('\nâ„ï¸ é™é›ªåˆ†æ:')
    snow_col = 'Snowfall (cm)'
    snow_stats = df.groupby(df[snow_col] > 0)[target_col].agg(['count', 'mean', 'std'])
    snow_stats.index = ['æ— é›ª', 'æœ‰é›ª']
    print(snow_stats)
    print(f'é™é›ªå¤©æ•°: {(df[snow_col] > 0).sum()} ({(df[snow_col] > 0).mean()*100:.1f}%)')
    
    return df

def analyze_special_conditions(df):
    """åˆ†æç‰¹æ®Šæ¡ä»¶"""
    print(f'\nğŸ·ï¸ ç‰¹æ®Šæ¡ä»¶åˆ†æ:')
    print('='*35)
    
    target_col = 'Rented Bike Count'
    
    # å­£èŠ‚åˆ†æ
    print('\nğŸƒ å­£èŠ‚åˆ†æ:')
    seasonal_stats = df.groupby('Seasons')[target_col].agg(['count', 'mean', 'std'])
    print(seasonal_stats)
    
    # å‡æœŸåˆ†æ
    print('\nğŸ–ï¸ å‡æœŸåˆ†æ:')
    holiday_stats = df.groupby('Holiday')[target_col].agg(['count', 'mean', 'std'])
    print(holiday_stats)
    
    # è¿è¥çŠ¶æ€åˆ†æ
    print('\nğŸš´ è¿è¥çŠ¶æ€åˆ†æ:')
    functioning_stats = df.groupby('Functioning Day')[target_col].agg(['count', 'mean', 'std'])
    print(functioning_stats)
    
    # é›¶å€¼åˆ†æ
    print('\nğŸ” é›¶å€¼æ·±åº¦åˆ†æ:')
    zero_mask = df[target_col] == 0
    zero_data = df[zero_mask]
    print(f'é›¶å€¼æ€»æ•°: {zero_mask.sum()}')
    
    if len(zero_data) > 0:
        print('\né›¶å€¼æ¡ä»¶åˆ†æ:')
        print(f'è¿è¥çŠ¶æ€: {zero_data["Functioning Day"].value_counts()}')
        print(f'å­£èŠ‚åˆ†å¸ƒ: {zero_data["Seasons"].value_counts()}')
        print(f'å‡æœŸåˆ†å¸ƒ: {zero_data["Holiday"].value_counts()}')
        
        print(f'\né›¶å€¼æ—¶é—´åˆ†å¸ƒ:')
        print(f'å°æ—¶åˆ†å¸ƒ: {zero_data["Hour"].value_counts().sort_index()}')
        
        print(f'\né›¶å€¼å¤©æ°”æ¡ä»¶:')
        print(f'å¹³å‡æ¸©åº¦: {zero_data["Temperature(Â°C)"].mean():.2f}Â°C')
        print(f'å¹³å‡æ¹¿åº¦: {zero_data["Humidity(%)"].mean():.2f}%')
        print(f'å¹³å‡é£é€Ÿ: {zero_data["Wind speed (m/s)"].mean():.2f} m/s')
        print(f'é™é›¨å¤©æ•°: {(zero_data["Rainfall(mm)"] > 0).sum()}')
        print(f'é™é›ªå¤©æ•°: {(zero_data["Snowfall (cm)"] > 0).sum()}')
    
    return df

def correlation_analysis(df):
    """ç›¸å…³æ€§åˆ†æ"""
    print(f'\nğŸ“Š ç‰¹å¾ç›¸å…³æ€§åˆ†æ:')
    print('='*40)
    
    # é€‰æ‹©æ•°å€¼å‹ç‰¹å¾
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    target_col = 'Rented Bike Count'
    
    if target_col in numeric_cols:
        # è®¡ç®—ä¸ç›®æ ‡å˜é‡çš„ç›¸å…³æ€§
        correlations = df[numeric_cols].corr()[target_col].abs().sort_values(ascending=False)
        
        print(f'\nä¸ç›®æ ‡å˜é‡çš„ç›¸å…³æ€§æ’åº:')
        for col, corr in correlations.items():
            if col != target_col:
                print(f'{col:30s}: {corr:.4f}')
        
        # å¼ºç›¸å…³ç‰¹å¾ï¼ˆ|r| > 0.3ï¼‰
        strong_corr = correlations[correlations > 0.3]
        strong_corr = strong_corr[strong_corr.index != target_col]
        print(f'\nå¼ºç›¸å…³ç‰¹å¾ (|r| > 0.3):')
        for col, corr in strong_corr.items():
            print(f'{col:30s}: {corr:.4f}')
    
    return correlations

def identify_peak_patterns(df):
    """è¯†åˆ«å³°å€¼æ¨¡å¼"""
    print(f'\nğŸ“ˆ å³°å€¼æ¨¡å¼è¯†åˆ«:')
    print('='*35)
    
    target_col = 'Rented Bike Count'
    
    # é«˜å³°æ—¶æ®µè¯†åˆ«
    top_90_percentile = df[target_col].quantile(0.9)
    peak_data = df[df[target_col] >= top_90_percentile]
    
    print(f'é«˜å³°é˜ˆå€¼ï¼ˆ90åˆ†ä½æ•°ï¼‰: {top_90_percentile:.0f}')
    print(f'é«˜å³°è®°å½•æ•°: {len(peak_data)} ({len(peak_data)/len(df)*100:.2f}%)')
    
    print(f'\né«˜å³°æ—¶æ®µç‰¹å¾:')
    print(f'å°æ—¶åˆ†å¸ƒ:')
    peak_hours = peak_data['Hour'].value_counts().sort_index()
    for hour, count in peak_hours.items():
        print(f'  {hour:2d}æ—¶: {count:3d}æ¬¡ ({count/len(peak_data)*100:.1f}%)')
    
    print(f'\nå­£èŠ‚åˆ†å¸ƒ:')
    peak_seasons = peak_data['Seasons'].value_counts()
    for season, count in peak_seasons.items():
        print(f'  {season}: {count:3d}æ¬¡ ({count/len(peak_data)*100:.1f}%)')
    
    print(f'\nå¤©æ°”æ¡ä»¶:')
    print(f'å¹³å‡æ¸©åº¦: {peak_data["Temperature(Â°C)"].mean():.2f}Â°C')
    print(f'å¹³å‡æ¹¿åº¦: {peak_data["Humidity(%)"].mean():.2f}%')
    print(f'å¹³å‡é£é€Ÿ: {peak_data["Wind speed (m/s)"].mean():.2f} m/s')
    
    # ä½è°·æ—¶æ®µè¯†åˆ«ï¼ˆæ’é™¤é›¶å€¼ï¼‰
    non_zero_data = df[df[target_col] > 0]
    bottom_10_percentile = non_zero_data[target_col].quantile(0.1)
    low_data = non_zero_data[non_zero_data[target_col] <= bottom_10_percentile]
    
    print(f'\nä½è°·æ—¶æ®µç‰¹å¾:')
    print(f'ä½è°·é˜ˆå€¼ï¼ˆéé›¶10åˆ†ä½æ•°ï¼‰: {bottom_10_percentile:.0f}')
    print(f'ä½è°·è®°å½•æ•°: {len(low_data)} ({len(low_data)/len(non_zero_data)*100:.2f}%)')
    
    print(f'å°æ—¶åˆ†å¸ƒ:')
    low_hours = low_data['Hour'].value_counts().sort_index()
    for hour, count in low_hours.items():
        print(f'  {hour:2d}æ—¶: {count:3d}æ¬¡ ({count/len(low_data)*100:.1f}%)')
    
    return peak_data, low_data

def main():
    """ä¸»å‡½æ•°"""
    # åŠ è½½æ•°æ®
    df = load_and_explore_data()
    
    # åˆ†æç›®æ ‡å˜é‡
    target_values = analyze_target_variable(df)
    
    # æ—¶é—´æ¨¡å¼åˆ†æ
    df = analyze_time_patterns(df)
    
    # å¤©æ°”å½±å“åˆ†æ
    df = analyze_weather_impact(df)
    
    # ç‰¹æ®Šæ¡ä»¶åˆ†æ
    df = analyze_special_conditions(df)
    
    # ç›¸å…³æ€§åˆ†æ
    correlations = correlation_analysis(df)
    
    # å³°å€¼æ¨¡å¼è¯†åˆ«
    peak_data, low_data = identify_peak_patterns(df)
    
    print(f'\nğŸ¯ æ•°æ®æ´å¯Ÿæ€»ç»“:')
    print('='*40)
    print('âœ… æ•°æ®é‡æ–°åˆ†æå®Œæˆï¼')
    print('ğŸ“ å‘ç°çš„å…³é”®æ¨¡å¼å°†æœ‰åŠ©äºç‰¹å¾å·¥ç¨‹å’Œæ¨¡å‹ä¼˜åŒ–')

if __name__ == "__main__":
    main() 